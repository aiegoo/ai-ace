{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb1e736",
   "metadata": {},
   "source": [
    "# 🌡️ 온습도 관측 데이터 분석 (Temperature & Humidity Sensor Data Analysis)\n",
    "\n",
    "**WebEx 강의 실습 - Scikit-Learn Data Splitting 중심**\n",
    "\n",
    "## 📋 **학습 목표:**\n",
    "1. **온습도 센서 데이터** 로드 및 탐색\n",
    "2. **Scikit-Learn train_test_split** 활용한 데이터 분할\n",
    "3. **Stratified Splitting** 으로 데이터 분포 유지\n",
    "4. **Time Series Splitting** 으로 시계열 데이터 처리\n",
    "5. **데이터 분할 품질 검증** 및 모델 학습\n",
    "\n",
    "## 🎯 **핵심 개념:**\n",
    "- **Train/Validation/Test Split** - 모델 학습/검증/평가용 데이터 분리\n",
    "- **Stratified Sampling** - 클래스 비율 유지한 분할\n",
    "- **Time Series Cross-Validation** - 시간 순서 고려한 검증\n",
    "- **Data Leakage 방지** - 미래 정보가 과거로 유출되지 않도록 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c144b503",
   "metadata": {},
   "source": [
    "## 📚 **Section 1: Import Required Libraries**\n",
    "필요한 라이브러리들을 import하고 환경을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 필수 라이브러리 Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-Learn 데이터 분할 관련 모듈들\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,      # 기본 train/test 분할\n",
    "    StratifiedShuffleSplit, # 계층화 분할\n",
    "    TimeSeriesSplit,       # 시계열 분할\n",
    "    cross_val_score,       # 교차검증\n",
    "    validation_curve       # 검증 곡선\n",
    ")\n",
    "\n",
    "# 모델링 관련\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# 한글 폰트 설정 (matplotlib)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"✅ 모든 라이브러리가 성공적으로 로드되었습니다!\")\n",
    "print(f\"📊 Pandas Version: {pd.__version__}\")\n",
    "print(f\"🔢 NumPy Version: {np.__version__}\")\n",
    "print(f\"🤖 Scikit-Learn 분할 모듈들이 준비되었습니다!\")\n",
    "print(f\"📈 Matplotlib & Seaborn 시각화 준비완료!\")\n",
    "print(\"\\n🎯 온습도 센서 데이터 분석을 시작하겠습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b20e9",
   "metadata": {},
   "source": [
    "## 📊 **Section 2: Load Temperature and Humidity Data**\n",
    "온습도 센서 데이터를 생성하고 로드하여 구조를 파악합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdb078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌡️ 온습도 센서 데이터 생성 (실제 센서 데이터 시뮬레이션)\n",
    "print(\"🔄 온습도 센서 데이터를 생성하고 있습니다...\")\n",
    "\n",
    "# 시간 범위 설정 (최근 1년간의 시간당 데이터)\n",
    "np.random.seed(42)  # 재현 가능한 결과를 위한 시드 설정\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# 실제와 유사한 온습도 패턴 생성\n",
    "n_samples = len(date_range)\n",
    "\n",
    "# 계절별 온도 패턴 (한국 기후 반영)\n",
    "day_of_year = date_range.dayofyear\n",
    "hour_of_day = date_range.hour\n",
    "\n",
    "# 기본 온도 패턴 (계절성 + 일일 주기)\n",
    "base_temp = 15 + 10 * np.sin(2 * np.pi * day_of_year / 365.25)  # 계절 패턴\n",
    "daily_temp = 5 * np.sin(2 * np.pi * hour_of_day / 24)  # 일일 패턴\n",
    "noise_temp = np.random.normal(0, 2, n_samples)  # 노이즈\n",
    "temperature = base_temp + daily_temp + noise_temp\n",
    "\n",
    "# 습도 패턴 (온도와 반비례 관계 + 계절성)\n",
    "base_humidity = 60 + 20 * np.sin(2 * np.pi * (day_of_year + 90) / 365.25)  # 계절 패턴\n",
    "temp_humidity = -0.5 * (temperature - 20)  # 온도와 반비례\n",
    "noise_humidity = np.random.normal(0, 5, n_samples)  # 노이즈\n",
    "humidity = np.clip(base_humidity + temp_humidity + noise_humidity, 10, 95)\n",
    "\n",
    "# 기상 조건 분류 (온습도 기반)\n",
    "conditions = []\n",
    "for temp, hum in zip(temperature, humidity):\n",
    "    if temp < 5:\n",
    "        condition = \"추위\" if hum < 60 else \"습한추위\"\n",
    "    elif temp < 20:\n",
    "        condition = \"서늘함\" if hum < 60 else \"습한서늘함\"\n",
    "    elif temp < 30:\n",
    "        condition = \"적정\" if hum < 70 else \"습함\"\n",
    "    else:\n",
    "        condition = \"더위\" if hum < 80 else \"무더위\"\n",
    "    conditions.append(condition)\n",
    "\n",
    "# 센서 위치 (실내/실외 구분)\n",
    "sensor_locations = np.random.choice(['실내', '실외'], n_samples, p=[0.6, 0.4])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "sensor_data = pd.DataFrame({\n",
    "    'timestamp': date_range,\n",
    "    'temperature': np.round(temperature, 1),\n",
    "    'humidity': np.round(humidity, 1),\n",
    "    'condition': conditions,\n",
    "    'location': sensor_locations,\n",
    "    'day_of_week': date_range.day_name(),\n",
    "    'hour': date_range.hour,\n",
    "    'month': date_range.month,\n",
    "    'season': pd.cut(date_range.month, \n",
    "                     bins=[0, 3, 6, 9, 12], \n",
    "                     labels=['겨울', '봄', '여름', '가을'])\n",
    "})\n",
    "\n",
    "print(f\"✅ 온습도 센서 데이터 생성 완료!\")\n",
    "print(f\"📏 데이터 크기: {sensor_data.shape}\")\n",
    "print(f\"📅 기간: {sensor_data['timestamp'].min()} ~ {sensor_data['timestamp'].max()}\")\n",
    "print(f\"🌡️  온도 범위: {sensor_data['temperature'].min():.1f}°C ~ {sensor_data['temperature'].max():.1f}°C\")\n",
    "print(f\"💧 습도 범위: {sensor_data['humidity'].min():.1f}% ~ {sensor_data['humidity'].max():.1f}%\")\n",
    "\n",
    "# 데이터 구조 확인\n",
    "print(f\"\\n📊 데이터 구조:\")\n",
    "print(sensor_data.info())\n",
    "\n",
    "print(f\"\\n📈 첫 10개 레코드:\")\n",
    "display(sensor_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7b06b",
   "metadata": {},
   "source": [
    "## 🔍 **Section 3: Data Exploration and Preprocessing**\n",
    "데이터 특성을 탐색하고 결측값을 처리하며 분할을 위한 피처를 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b317b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 데이터 탐색적 분석 (EDA)\n",
    "print(\"🔍 온습도 데이터 탐색적 분석을 시작합니다...\")\n",
    "\n",
    "# 1. 기술통계량\n",
    "print(\"\\n📊 기술통계량:\")\n",
    "print(sensor_data[['temperature', 'humidity']].describe())\n",
    "\n",
    "# 2. 결측값 확인\n",
    "print(f\"\\n❓ 결측값 확인:\")\n",
    "missing_values = sensor_data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"✅ 결측값이 없습니다!\")\n",
    "else:\n",
    "    print(f\"⚠️ 총 {missing_values.sum()}개의 결측값이 발견되었습니다.\")\n",
    "\n",
    "# 3. 범주형 변수 분포\n",
    "print(f\"\\n📈 기상 조건 분포:\")\n",
    "condition_counts = sensor_data['condition'].value_counts()\n",
    "print(condition_counts)\n",
    "\n",
    "print(f\"\\n📍 센서 위치 분포:\")\n",
    "location_counts = sensor_data['location'].value_counts()\n",
    "print(location_counts)\n",
    "\n",
    "# 4. 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 온도 분포\n",
    "axes[0, 0].hist(sensor_data['temperature'], bins=50, alpha=0.7, color='red')\n",
    "axes[0, 0].set_title('온도 분포')\n",
    "axes[0, 0].set_xlabel('온도 (°C)')\n",
    "axes[0, 0].set_ylabel('빈도')\n",
    "\n",
    "# 습도 분포\n",
    "axes[0, 1].hist(sensor_data['humidity'], bins=50, alpha=0.7, color='blue')\n",
    "axes[0, 1].set_title('습도 분포')\n",
    "axes[0, 1].set_xlabel('습도 (%)')\n",
    "axes[0, 1].set_ylabel('빈도')\n",
    "\n",
    "# 온도-습도 관계\n",
    "scatter = axes[1, 0].scatter(sensor_data['temperature'], sensor_data['humidity'], \n",
    "                             alpha=0.5, c=sensor_data['month'], cmap='viridis')\n",
    "axes[1, 0].set_title('온도-습도 관계 (월별 색상)')\n",
    "axes[1, 0].set_xlabel('온도 (°C)')\n",
    "axes[1, 0].set_ylabel('습도 (%)')\n",
    "plt.colorbar(scatter, ax=axes[1, 0], label='월')\n",
    "\n",
    "# 기상 조건별 분포\n",
    "condition_counts.plot(kind='bar', ax=axes[1, 1], color='green', alpha=0.7)\n",
    "axes[1, 1].set_title('기상 조건별 분포')\n",
    "axes[1, 1].set_xlabel('기상 조건')\n",
    "axes[1, 1].set_ylabel('빈도')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ 데이터 탐색 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd5776",
   "metadata": {},
   "source": [
    "## 🔪 **Section 4: Train-Test Split with Scikit-Learn**\n",
    "**WebEx 강의 핵심**: Scikit-Learn의 train_test_split을 활용한 기본적인 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔪 Scikit-Learn train_test_split 활용\n",
    "print(\"🔪 SCIKIT-LEARN TRAIN_TEST_SPLIT 실습\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 피처와 타겟 변수 준비\n",
    "print(\"\\n1️⃣ 피처와 타겟 변수 설정:\")\n",
    "\n",
    "# 예제 1: 회귀 문제 (온도 예측)\n",
    "# 피처: 습도, 시간, 월, 센서위치\n",
    "feature_columns = ['humidity', 'hour', 'month']\n",
    "\n",
    "# 범주형 변수 인코딩\n",
    "le_location = LabelEncoder()\n",
    "sensor_data['location_encoded'] = le_location.fit_transform(sensor_data['location'])\n",
    "\n",
    "# 피처 행렬 X 구성\n",
    "X_regression = sensor_data[feature_columns + ['location_encoded']].copy()\n",
    "y_regression = sensor_data['temperature'].copy()  # 온도 예측\n",
    "\n",
    "print(f\"📊 회귀 문제 설정:\")\n",
    "print(f\"   • 피처 (X): {X_regression.columns.tolist()}\")\n",
    "print(f\"   • 타겟 (y): 온도 예측\")\n",
    "print(f\"   • 데이터 크기: {X_regression.shape}\")\n",
    "\n",
    "# 예제 2: 분류 문제 (기상 조건 예측)\n",
    "X_classification = X_regression.copy()\n",
    "y_classification = sensor_data['condition'].copy()  # 기상 조건 분류\n",
    "\n",
    "print(f\"\\n📊 분류 문제 설정:\")\n",
    "print(f\"   • 피처 (X): {X_classification.columns.tolist()}\")\n",
    "print(f\"   • 타겟 (y): 기상 조건 분류\")\n",
    "print(f\"   • 클래스 수: {y_classification.nunique()}개\")\n",
    "print(f\"   • 클래스: {y_classification.unique()}\")\n",
    "\n",
    "print(f\"\\n2️⃣ 기본 Train-Test Split (70:30 비율):\")\n",
    "\n",
    "# 회귀 문제 분할\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_regression, y_regression, \n",
    "    test_size=0.3,           # 30%를 테스트 세트로\n",
    "    random_state=42,         # 재현 가능한 결과\n",
    "    shuffle=True             # 데이터 셔플\n",
    ")\n",
    "\n",
    "print(f\"📈 회귀 문제 분할 결과:\")\n",
    "print(f\"   • 훈련 세트: {X_train_reg.shape[0]:,}개 ({X_train_reg.shape[0]/len(X_regression)*100:.1f}%)\")\n",
    "print(f\"   • 테스트 세트: {X_test_reg.shape[0]:,}개 ({X_test_reg.shape[0]/len(X_regression)*100:.1f}%)\")\n",
    "print(f\"   • 훈련 온도 범위: {y_train_reg.min():.1f}°C ~ {y_train_reg.max():.1f}°C\")\n",
    "print(f\"   • 테스트 온도 범위: {y_test_reg.min():.1f}°C ~ {y_test_reg.max():.1f}°C\")\n",
    "\n",
    "# 분류 문제 분할\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_classification, y_classification,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 분류 문제 분할 결과:\")\n",
    "print(f\"   • 훈련 세트: {X_train_clf.shape[0]:,}개\")\n",
    "print(f\"   • 테스트 세트: {X_test_clf.shape[0]:,}개\")\n",
    "\n",
    "# 훈련/테스트 세트의 클래스 분포 확인\n",
    "train_dist = y_train_clf.value_counts(normalize=True).sort_index()\n",
    "test_dist = y_test_clf.value_counts(normalize=True).sort_index()\n",
    "\n",
    "print(f\"\\n📈 클래스 분포 비교:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    '훈련세트': train_dist,\n",
    "    '테스트세트': test_dist\n",
    "})\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "print(f\"\\n3️⃣ 다양한 분할 비율 실험:\")\n",
    "\n",
    "# 다양한 test_size로 실험\n",
    "test_sizes = [0.2, 0.25, 0.3, 0.4]\n",
    "split_results = []\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X_regression, y_regression,\n",
    "        test_size=test_size,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    split_results.append({\n",
    "        'test_size': f\"{test_size*100:.0f}%\",\n",
    "        'train_samples': len(X_tr),\n",
    "        'test_samples': len(X_te),\n",
    "        'train_ratio': f\"{(1-test_size)*100:.0f}%\",\n",
    "        'test_ratio': f\"{test_size*100:.0f}%\"\n",
    "    })\n",
    "\n",
    "split_df = pd.DataFrame(split_results)\n",
    "print(\"다양한 분할 비율 결과:\")\n",
    "print(split_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n✅ Train-Test Split 완료!\")\n",
    "print(f\"🎯 다음 단계: Stratified Split으로 클래스 분포 유지하기\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e21b84",
   "metadata": {},
   "source": [
    "## 🎯 **Section 5: Stratified Splitting for Sensor Data**\n",
    "계층화 분할로 클래스 분포를 유지하면서 데이터를 나누는 고급 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64160145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Stratified Splitting - 클래스 분포 유지\n",
    "print(\"🎯 STRATIFIED SPLITTING 실습\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1️⃣ 일반 분할 vs 계층화 분할 비교:\")\n",
    "\n",
    "# 일반 분할\n",
    "X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(\n",
    "    X_classification, y_classification,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 계층화 분할 (stratify 매개변수 사용)\n",
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(\n",
    "    X_classification, y_classification,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=y_classification  # 🔑 핵심: 클래스 분포 유지\n",
    ")\n",
    "\n",
    "print(\"📊 클래스 분포 비교:\")\n",
    "\n",
    "# 원본 데이터 분포\n",
    "original_dist = y_classification.value_counts(normalize=True).sort_index()\n",
    "\n",
    "# 일반 분할 결과\n",
    "normal_train_dist = y_train_normal.value_counts(normalize=True).sort_index()\n",
    "normal_test_dist = y_test_normal.value_counts(normalize=True).sort_index()\n",
    "\n",
    "# 계층화 분할 결과\n",
    "strat_train_dist = y_train_strat.value_counts(normalize=True).sort_index()\n",
    "strat_test_dist = y_test_strat.value_counts(normalize=True).sort_index()\n",
    "\n",
    "# 결과 정리\n",
    "comparison_df = pd.DataFrame({\n",
    "    '원본데이터': original_dist,\n",
    "    '일반분할_훈련': normal_train_dist,\n",
    "    '일반분할_테스트': normal_test_dist,\n",
    "    '계층분할_훈련': strat_train_dist,\n",
    "    '계층분할_테스트': strat_test_dist\n",
    "})\n",
    "\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# 분포 차이 계산\n",
    "print(f\"\\n📈 원본 데이터와의 분포 차이 (절댓값 평균):\")\n",
    "normal_train_diff = np.mean(np.abs(normal_train_dist - original_dist))\n",
    "normal_test_diff = np.mean(np.abs(normal_test_dist - original_dist))\n",
    "strat_train_diff = np.mean(np.abs(strat_train_dist - original_dist))\n",
    "strat_test_diff = np.mean(np.abs(strat_test_dist - original_dist))\n",
    "\n",
    "print(f\"   • 일반 분할 - 훈련세트: {normal_train_diff:.4f}\")\n",
    "print(f\"   • 일반 분할 - 테스트세트: {normal_test_diff:.4f}\")\n",
    "print(f\"   • 계층 분할 - 훈련세트: {strat_train_diff:.4f}\")\n",
    "print(f\"   • 계층 분할 - 테스트세트: {strat_test_diff:.4f}\")\n",
    "\n",
    "print(f\"\\n2️⃣ StratifiedShuffleSplit 활용:\")\n",
    "\n",
    "# StratifiedShuffleSplit 사용\n",
    "sss = StratifiedShuffleSplit(\n",
    "    n_splits=5,        # 5번 분할\n",
    "    test_size=0.3,     # 30% 테스트\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"📊 여러 번의 계층화 분할 결과:\")\n",
    "\n",
    "split_results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(X_classification, y_classification)):\n",
    "    y_train_split = y_classification.iloc[train_idx]\n",
    "    y_test_split = y_classification.iloc[test_idx]\n",
    "    \n",
    "    train_dist = y_train_split.value_counts(normalize=True).sort_index()\n",
    "    test_dist = y_test_split.value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    # 원본과의 차이 계산\n",
    "    train_diff = np.mean(np.abs(train_dist - original_dist))\n",
    "    test_diff = np.mean(np.abs(test_dist - original_dist))\n",
    "    \n",
    "    split_results.append({\n",
    "        'Split': f\"분할_{i+1}\",\n",
    "        '훈련세트_차이': train_diff,\n",
    "        '테스트세트_차이': test_diff,\n",
    "        '전체_차이': (train_diff + test_diff) / 2\n",
    "    })\n",
    "\n",
    "split_df = pd.DataFrame(split_results)\n",
    "print(split_df.round(4))\n",
    "\n",
    "print(f\"\\n3️⃣ 계층화 분할의 시각화:\")\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 원본 데이터 분포\n",
    "original_dist.plot(kind='bar', ax=axes[0], title='원본 데이터 분포', color='gray')\n",
    "axes[0].set_ylabel('비율')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 일반 분할 결과\n",
    "normal_comparison = pd.DataFrame({\n",
    "    '훈련세트': normal_train_dist,\n",
    "    '테스트세트': normal_test_dist\n",
    "})\n",
    "normal_comparison.plot(kind='bar', ax=axes[1], title='일반 분할 결과')\n",
    "axes[1].set_ylabel('비율')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 계층화 분할 결과\n",
    "strat_comparison = pd.DataFrame({\n",
    "    '훈련세트': strat_train_dist,\n",
    "    '테스트세트': strat_test_dist\n",
    "})\n",
    "strat_comparison.plot(kind='bar', ax=axes[2], title='계층화 분할 결과')\n",
    "axes[2].set_ylabel('비율')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Stratified Splitting 완료!\")\n",
    "print(f\"🎯 핵심: 계층화 분할이 클래스 분포를 더 잘 유지합니다!\")\n",
    "print(f\"📚 WebEx 강의 포인트: stratify 매개변수 사용법 숙지!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae310c4e",
   "metadata": {},
   "source": [
    "## ⏰ **Section 6: Time Series Splitting for Sequential Data**\n",
    "시계열 데이터에서 시간 순서를 고려한 분할 기법 (매우 중요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⏰ Time Series Splitting - 시간 순서 고려\n",
    "print(\"⏰ TIME SERIES SPLITTING 실습\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n🚨 중요: 시계열 데이터에서는 미래 정보가 과거로 유출되면 안됩니다!\")\n",
    "print(\"   → Data Leakage 방지를 위해 시간 순서를 반드시 유지해야 합니다.\")\n",
    "\n",
    "print(\"\\n1️⃣ 시간 순서 기반 분할:\")\n",
    "\n",
    "# 데이터를 시간 순서대로 정렬\n",
    "sensor_data_sorted = sensor_data.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# 시간 기반 분할 (처음 70%는 훈련, 나머지 30%는 테스트)\n",
    "split_point = int(len(sensor_data_sorted) * 0.7)\n",
    "\n",
    "train_data = sensor_data_sorted[:split_point]\n",
    "test_data = sensor_data_sorted[split_point:]\n",
    "\n",
    "print(f\"📅 시간 기반 분할 결과:\")\n",
    "print(f\"   • 훈련 기간: {train_data['timestamp'].min()} ~ {train_data['timestamp'].max()}\")\n",
    "print(f\"   • 테스트 기간: {test_data['timestamp'].min()} ~ {test_data['timestamp'].max()}\")\n",
    "print(f\"   • 훈련 데이터: {len(train_data):,}개 ({len(train_data)/len(sensor_data_sorted)*100:.1f}%)\")\n",
    "print(f\"   • 테스트 데이터: {len(test_data):,}개 ({len(test_data)/len(sensor_data_sorted)*100:.1f}%)\")\n",
    "\n",
    "# 특징과 타겟 분리\n",
    "X_train_ts = train_data[['humidity', 'hour', 'month', 'location_encoded']]\n",
    "y_train_ts = train_data['temperature']\n",
    "X_test_ts = test_data[['humidity', 'hour', 'month', 'location_encoded']]\n",
    "y_test_ts = test_data['temperature']\n",
    "\n",
    "print(f\"\\n2️⃣ TimeSeriesSplit을 활용한 교차검증:\")\n",
    "\n",
    "# TimeSeriesSplit 설정\n",
    "tscv = TimeSeriesSplit(n_splits=5)  # 5-fold 시계열 교차검증\n",
    "\n",
    "print(\"📊 TimeSeriesSplit 분할 시각화:\")\n",
    "\n",
    "# 분할 정보 저장\n",
    "split_info = []\n",
    "for i, (train_idx, test_idx) in enumerate(tscv.split(X_train_ts)):\n",
    "    train_start = train_data.iloc[train_idx[0]]['timestamp']\n",
    "    train_end = train_data.iloc[train_idx[-1]]['timestamp']\n",
    "    test_start = train_data.iloc[test_idx[0]]['timestamp']\n",
    "    test_end = train_data.iloc[test_idx[-1]]['timestamp']\n",
    "    \n",
    "    split_info.append({\n",
    "        'Fold': f'Fold {i+1}',\n",
    "        '훈련시작': train_start.strftime('%Y-%m-%d'),\n",
    "        '훈련종료': train_end.strftime('%Y-%m-%d'),\n",
    "        '검증시작': test_start.strftime('%Y-%m-%d'),\n",
    "        '검증종료': test_end.strftime('%Y-%m-%d'),\n",
    "        '훈련크기': len(train_idx),\n",
    "        '검증크기': len(test_idx)\n",
    "    })\n",
    "\n",
    "split_df = pd.DataFrame(split_info)\n",
    "print(split_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n3️⃣ 시계열 분할 vs 랜덤 분할 성능 비교:\")\n",
    "\n",
    "# 간단한 모델로 성능 비교\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 1) 시계열 분할로 학습/평가\n",
    "model_ts = LinearRegression()\n",
    "model_ts.fit(X_train_ts, y_train_ts)\n",
    "y_pred_ts = model_ts.predict(X_test_ts)\n",
    "\n",
    "mse_ts = mean_squared_error(y_test_ts, y_pred_ts)\n",
    "mae_ts = mean_absolute_error(y_test_ts, y_pred_ts)\n",
    "\n",
    "# 2) 랜덤 분할로 학습/평가\n",
    "X_train_random, X_test_random, y_train_random, y_test_random = train_test_split(\n",
    "    X_regression, y_regression, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "model_random = LinearRegression()\n",
    "model_random.fit(X_train_random, y_train_random)\n",
    "y_pred_random = model_random.predict(X_test_random)\n",
    "\n",
    "mse_random = mean_squared_error(y_test_random, y_pred_random)\n",
    "mae_random = mean_absolute_error(y_test_random, y_pred_random)\n",
    "\n",
    "print(\"📈 성능 비교 결과:\")\n",
    "performance_df = pd.DataFrame({\n",
    "    '분할방법': ['시계열 분할', '랜덤 분할'],\n",
    "    'MSE': [mse_ts, mse_random],\n",
    "    'MAE': [mae_ts, mae_random],\n",
    "    '설명': [\n",
    "        '시간 순서 유지 (현실적)',\n",
    "        '랜덤 셔플 (비현실적)'\n",
    "    ]\n",
    "})\n",
    "print(performance_df.round(4))\n",
    "\n",
    "print(f\"\\n4️⃣ 교차검증 성능 평가:\")\n",
    "\n",
    "# TimeSeriesSplit으로 교차검증\n",
    "ts_scores = cross_val_score(LinearRegression(), X_train_ts, y_train_ts, \n",
    "                           cv=tscv, scoring='neg_mean_squared_error')\n",
    "\n",
    "# 일반 교차검증 (비교용)\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "normal_scores = cross_val_score(LinearRegression(), X_train_ts, y_train_ts,\n",
    "                               cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"📊 교차검증 성능 비교:\")\n",
    "cv_comparison = pd.DataFrame({\n",
    "    'TimeSeriesSplit': -ts_scores,\n",
    "    'KFold(shuffle=True)': -normal_scores\n",
    "})\n",
    "print(\"MSE 점수:\")\n",
    "print(cv_comparison.round(4))\n",
    "print(f\"\\nTimeSeriesSplit 평균 MSE: {-ts_scores.mean():.4f} (±{ts_scores.std():.4f})\")\n",
    "print(f\"KFold 평균 MSE: {-normal_scores.mean():.4f} (±{normal_scores.std():.4f})\")\n",
    "\n",
    "print(f\"\\n5️⃣ 시계열 분할 시각화:\")\n",
    "\n",
    "# 시계열 분할 시각화\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# 전체 데이터 시계열 플롯\n",
    "sample_data = sensor_data_sorted[::24]  # 하루마다 샘플링\n",
    "axes[0].plot(sample_data['timestamp'], sample_data['temperature'], alpha=0.7)\n",
    "axes[0].axvline(x=train_data['timestamp'].max(), color='red', linestyle='--', \n",
    "                label=f'분할점 ({train_data[\"timestamp\"].max().strftime(\"%Y-%m-%d\")})')\n",
    "axes[0].set_title('시계열 데이터 분할')\n",
    "axes[0].set_xlabel('시간')\n",
    "axes[0].set_ylabel('온도 (°C)')\n",
    "axes[0].legend()\n",
    "\n",
    "# 훈련/테스트 세트 분포 비교\n",
    "axes[1].hist(y_train_ts, bins=50, alpha=0.7, label='훈련세트', color='blue')\n",
    "axes[1].hist(y_test_ts, bins=50, alpha=0.7, label='테스트세트', color='red')\n",
    "axes[1].set_title('훈련/테스트 세트 온도 분포')\n",
    "axes[1].set_xlabel('온도 (°C)')\n",
    "axes[1].set_ylabel('빈도')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Time Series Splitting 완료!\")\n",
    "print(f\"🎯 핵심: 시계열 데이터에서는 시간 순서를 반드시 유지해야 합니다!\")\n",
    "print(f\"⚠️  Data Leakage 방지가 가장 중요한 포인트입니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1429d64",
   "metadata": {},
   "source": [
    "## ✅ **Section 7: Validate Split Quality**\n",
    "데이터 분할의 품질을 검증하고 최종 모델 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 데이터 분할 품질 검증\n",
    "print(\"✅ 데이터 분할 품질 검증\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1️⃣ 분할 품질 체크리스트:\")\n",
    "\n",
    "def validate_split_quality(X_train, X_test, y_train, y_test, split_name):\n",
    "    \"\"\"데이터 분할 품질을 종합적으로 검증하는 함수\"\"\"\n",
    "    \n",
    "    print(f\"\\n📊 {split_name} 품질 검증:\")\n",
    "    \n",
    "    # 1. 데이터 크기 검증\n",
    "    total_size = len(X_train) + len(X_test)\n",
    "    train_ratio = len(X_train) / total_size\n",
    "    test_ratio = len(X_test) / total_size\n",
    "    \n",
    "    print(f\"   📏 데이터 크기:\")\n",
    "    print(f\"      • 훈련세트: {len(X_train):,}개 ({train_ratio:.1%})\")\n",
    "    print(f\"      • 테스트세트: {len(X_test):,}개 ({test_ratio:.1%})\")\n",
    "    \n",
    "    # 2. 피처 분포 검증\n",
    "    feature_similarity = []\n",
    "    for col in X_train.columns:\n",
    "        train_mean = X_train[col].mean()\n",
    "        test_mean = X_test[col].mean()\n",
    "        train_std = X_train[col].std()\n",
    "        test_std = X_test[col].std()\n",
    "        \n",
    "        mean_diff = abs(train_mean - test_mean)\n",
    "        std_diff = abs(train_std - test_std)\n",
    "        \n",
    "        feature_similarity.append({\n",
    "            'feature': col,\n",
    "            'train_mean': train_mean,\n",
    "            'test_mean': test_mean,\n",
    "            'mean_diff': mean_diff,\n",
    "            'train_std': train_std,\n",
    "            'test_std': test_std,\n",
    "            'std_diff': std_diff\n",
    "        })\n",
    "    \n",
    "    feature_df = pd.DataFrame(feature_similarity)\n",
    "    print(f\"   📈 피처 분포 유사성:\")\n",
    "    print(feature_df[['feature', 'mean_diff', 'std_diff']].round(3).to_string(index=False))\n",
    "    \n",
    "    # 3. 타겟 분포 검증\n",
    "    train_target_mean = y_train.mean()\n",
    "    test_target_mean = y_test.mean()\n",
    "    train_target_std = y_train.std()\n",
    "    test_target_std = y_test.std()\n",
    "    \n",
    "    target_mean_diff = abs(train_target_mean - test_target_mean)\n",
    "    target_std_diff = abs(train_target_std - test_target_std)\n",
    "    \n",
    "    print(f\"   🎯 타겟 분포:\")\n",
    "    print(f\"      • 훈련 평균: {train_target_mean:.2f}, 표준편차: {train_target_std:.2f}\")\n",
    "    print(f\"      • 테스트 평균: {test_target_mean:.2f}, 표준편차: {test_target_std:.2f}\")\n",
    "    print(f\"      • 평균 차이: {target_mean_diff:.2f}, 표준편차 차이: {target_std_diff:.2f}\")\n",
    "    \n",
    "    # 4. 품질 점수 계산\n",
    "    avg_mean_diff = feature_df['mean_diff'].mean()\n",
    "    avg_std_diff = feature_df['std_diff'].mean()\n",
    "    \n",
    "    # 점수 (차이가 적을수록 좋음)\n",
    "    quality_score = 100 - (avg_mean_diff + avg_std_diff + target_mean_diff + target_std_diff)\n",
    "    \n",
    "    print(f\"   ⭐ 품질 점수: {quality_score:.1f}/100\")\n",
    "    \n",
    "    return quality_score\n",
    "\n",
    "# 다양한 분할 방법의 품질 검증\n",
    "quality_results = []\n",
    "\n",
    "# 1) 일반 분할\n",
    "score1 = validate_split_quality(X_train_reg, X_test_reg, y_train_reg, y_test_reg, \n",
    "                                \"일반 Train-Test Split\")\n",
    "quality_results.append((\"일반 분할\", score1))\n",
    "\n",
    "# 2) 시계열 분할\n",
    "score2 = validate_split_quality(X_train_ts, X_test_ts, y_train_ts, y_test_ts, \n",
    "                                \"시계열 기반 Split\")\n",
    "quality_results.append((\"시계열 분할\", score2))\n",
    "\n",
    "print(f\"\\n2️⃣ 모델 성능으로 분할 품질 검증:\")\n",
    "\n",
    "# 다양한 모델로 성능 비교\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "performance_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # 일반 분할 성능\n",
    "    model.fit(X_train_reg, y_train_reg)\n",
    "    y_pred_normal = model.predict(X_test_reg)\n",
    "    r2_normal = r2_score(y_test_reg, y_pred_normal)\n",
    "    \n",
    "    # 시계열 분할 성능\n",
    "    model.fit(X_train_ts, y_train_ts)\n",
    "    y_pred_ts = model.predict(X_test_ts)\n",
    "    r2_ts = r2_score(y_test_ts, y_pred_ts)\n",
    "    \n",
    "    performance_results.append({\n",
    "        '모델': model_name,\n",
    "        '일반분할_R2': r2_normal,\n",
    "        '시계열분할_R2': r2_ts,\n",
    "        '성능차이': abs(r2_normal - r2_ts)\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_results)\n",
    "print(\"📊 모델별 성능 비교:\")\n",
    "print(performance_df.round(4))\n",
    "\n",
    "print(f\"\\n3️⃣ 데이터 누수(Data Leakage) 검사:\")\n",
    "\n",
    "# 시간 기반 데이터 누수 검사\n",
    "def check_temporal_leakage(train_data, test_data):\n",
    "    \"\"\"시간 기반 데이터 누수를 검사하는 함수\"\"\"\n",
    "    \n",
    "    train_max_time = train_data['timestamp'].max()\n",
    "    test_min_time = test_data['timestamp'].min()\n",
    "    \n",
    "    leakage_detected = test_min_time <= train_max_time\n",
    "    \n",
    "    print(f\"   📅 훈련 데이터 최대 시간: {train_max_time}\")\n",
    "    print(f\"   📅 테스트 데이터 최소 시간: {test_min_time}\")\n",
    "    \n",
    "    if leakage_detected:\n",
    "        print(f\"   🚨 데이터 누수 발견! 미래 정보가 과거로 유출됨\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"   ✅ 데이터 누수 없음! 시간 순서 정상 유지\")\n",
    "        return True\n",
    "\n",
    "# 시계열 분할 데이터 누수 검사\n",
    "print(\"🔍 시계열 분할 데이터 누수 검사:\")\n",
    "leakage_free = check_temporal_leakage(train_data, test_data)\n",
    "\n",
    "print(f\"\\n4️⃣ 최종 권장사항:\")\n",
    "\n",
    "print(f\"\\n📋 분할 방법별 요약:\")\n",
    "summary_df = pd.DataFrame({\n",
    "    '분할방법': ['일반 랜덤분할', '시계열 분할', '계층화 분할'],\n",
    "    '적용상황': [\n",
    "        '일반적인 ML 문제',\n",
    "        '시계열/센서 데이터',\n",
    "        '불균형 분류 문제'\n",
    "    ],\n",
    "    '장점': [\n",
    "        '간단하고 빠름',\n",
    "        '현실적이고 안전함',\n",
    "        '클래스 분포 유지'\n",
    "    ],\n",
    "    '주의사항': [\n",
    "        '데이터 특성 고려',\n",
    "        '시간 순서 반드시 유지',\n",
    "        '회귀문제 적용 제한'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n🎯 온습도 센서 데이터 분석 결론:\")\n",
    "print(f\"   ✅ 시계열 데이터이므로 TimeSeriesSplit 사용 권장\")\n",
    "print(f\"   ✅ 데이터 누수 방지를 위한 시간 순서 유지 필수\")\n",
    "print(f\"   ✅ 교차검증시 TimeSeriesSplit 활용\")\n",
    "print(f\"   ✅ 모델 성능은 현실적 시나리오에서 평가\")\n",
    "\n",
    "print(f\"\\n🚀 WebEx 강의 핵심 포인트 정리:\")\n",
    "print(f\"   1️⃣ train_test_split의 다양한 매개변수 활용\")\n",
    "print(f\"   2️⃣ stratify 매개변수로 클래스 분포 유지\")\n",
    "print(f\"   3️⃣ 시계열 데이터에서 TimeSeriesSplit 필수 사용\")\n",
    "print(f\"   4️⃣ 데이터 누수 방지가 최우선 고려사항\")\n",
    "print(f\"   5️⃣ 분할 품질 검증을 통한 신뢰성 확보\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"🎉 온습도 관측 데이터 분석 완료!\")\n",
    "print(\"📚 WebEx 강의 내용을 따라잡으셨습니다!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
