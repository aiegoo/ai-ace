{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0f7111",
   "metadata": {},
   "source": [
    "# 🌡️ 온습도 관측 데이터 분석 - AWS S3 Enhanced Version\n",
    "(Temperature & Humidity Sensor Data Analysis - AWS S3 Integration)\n",
    "\n",
    "**WebEx 강의 실습 - Scikit-Learn Data Splitting + AWS S3 Data Pipeline**\n",
    "\n",
    "## 📋 **학습 목표:**\n",
    "1. **AWS S3에서 온습도 센서 데이터** 로드 및 탐색\n",
    "2. **Boto3를 활용한 클라우드 데이터 파이프라인** 구축\n",
    "3. **Scikit-Learn train_test_split** 활용한 데이터 분할\n",
    "4. **Stratified Splitting** 으로 데이터 분포 유지\n",
    "5. **Time Series Splitting** 으로 시계열 데이터 처리\n",
    "6. **데이터 분할 품질 검증** 및 모델 학습\n",
    "7. **결과를 S3로 업로드** 하는 완전한 클라우드 워크플로우\n",
    "\n",
    "## 🎯 **핵심 개념:**\n",
    "- **AWS S3 Data Pipeline** - 클라우드 기반 데이터 수집 및 저장\n",
    "- **Train/Validation/Test Split** - 모델 학습/검증/평가용 데이터 분리\n",
    "- **Stratified Sampling** - 클래스 비율 유지한 분할\n",
    "- **Time Series Cross-Validation** - 시간 순서 고려한 검증\n",
    "- **Data Leakage 방지** - 미래 정보가 과거로 유출되지 않도록 방지\n",
    "- **Cloud-to-Cloud Workflow** - 입력부터 출력까지 완전한 클라우드 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198c4a5",
   "metadata": {},
   "source": [
    "## 📚 **Section 1: Import Required Libraries + AWS SDK Setup**\n",
    "필요한 라이브러리들과 AWS SDK를 import하고 환경을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04010ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔐 AWS Credentials Setup and Verification\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "print(\"🔍 AWS Credentials Detection:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Method 1: Check for IAM Role (EC2/ECS/Lambda environment)\n",
    "def check_iam_role():\n",
    "    \"\"\"Check if we're running with an IAM role (preferred method)\"\"\"\n",
    "    try:\n",
    "        # Try to access instance metadata (works on EC2)\n",
    "        import urllib.request\n",
    "        import json\n",
    "        \n",
    "        # EC2 Instance Metadata Service v2 (IMDSv2)\n",
    "        try:\n",
    "            # Get session token first\n",
    "            token_request = urllib.request.Request(\n",
    "                'http://169.254.169.254/latest/api/token',\n",
    "                headers={'X-aws-ec2-metadata-token-ttl-seconds': '21600'}\n",
    "            )\n",
    "            token_request.get_method = lambda: 'PUT'\n",
    "            token_response = urllib.request.urlopen(token_request, timeout=2)\n",
    "            token = token_response.read().decode('utf-8')\n",
    "            \n",
    "            # Get IAM role info\n",
    "            role_request = urllib.request.Request(\n",
    "                'http://169.254.169.254/latest/meta-data/iam/security-credentials/',\n",
    "                headers={'X-aws-ec2-metadata-token': token}\n",
    "            )\n",
    "            role_response = urllib.request.urlopen(role_request, timeout=2)\n",
    "            role_name = role_response.read().decode('utf-8').strip()\n",
    "            \n",
    "            if role_name:\n",
    "                print(f\"✅ IAM Role detected: {role_name}\")\n",
    "                \n",
    "                # Get role details\n",
    "                creds_request = urllib.request.Request(\n",
    "                    f'http://169.254.169.254/latest/meta-data/iam/security-credentials/{role_name}',\n",
    "                    headers={'X-aws-ec2-metadata-token': token}\n",
    "                )\n",
    "                creds_response = urllib.request.urlopen(creds_request, timeout=2)\n",
    "                creds_data = json.loads(creds_response.read().decode('utf-8'))\n",
    "                \n",
    "                print(f\"🔑 Access Key: {creds_data.get('AccessKeyId', 'N/A')}\")\n",
    "                print(f\"⏰ Expires: {creds_data.get('Expiration', 'N/A')}\")\n",
    "                return True, role_name\n",
    "            \n",
    "        except Exception:\n",
    "            # Fallback to IMDSv1\n",
    "            role_response = urllib.request.urlopen(\n",
    "                'http://169.254.169.254/latest/meta-data/iam/security-credentials/', \n",
    "                timeout=2\n",
    "            )\n",
    "            role_name = role_response.read().decode('utf-8').strip()\n",
    "            if role_name:\n",
    "                print(f\"✅ IAM Role detected (IMDSv1): {role_name}\")\n",
    "                return True, role_name\n",
    "                \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Check for other IAM role indicators\n",
    "    if os.getenv('AWS_ROLE_ARN') or os.getenv('AWS_WEB_IDENTITY_TOKEN_FILE'):\n",
    "        print(\"✅ IAM Role detected (ECS/EKS/Lambda environment)\")\n",
    "        return True, \"Service Role\"\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "# Check IAM Role first\n",
    "iam_role_available, role_name = check_iam_role()\n",
    "\n",
    "# Method 2: Check AWS CLI configuration\n",
    "try:\n",
    "    result = subprocess.run(['aws', 'configure', 'list'], \n",
    "                          capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ AWS CLI configured successfully!\")\n",
    "        print(\"📋 AWS CLI Configuration:\")\n",
    "        \n",
    "        # Parse AWS CLI output to check source\n",
    "        cli_lines = result.stdout.strip().split('\\n')\n",
    "        for line in cli_lines:\n",
    "            if 'access_key' in line and 'iam-role' in line:\n",
    "                print(\"🎯 AWS CLI using IAM role credentials!\")\n",
    "            elif 'access_key' in line:\n",
    "                print(f\"🔧 {line}\")\n",
    "        \n",
    "        aws_cli_configured = True\n",
    "    else:\n",
    "        print(\"⚠️ AWS CLI not configured properly\")\n",
    "        aws_cli_configured = False\n",
    "except (subprocess.TimeoutExpired, FileNotFoundError):\n",
    "    print(\"⚠️ AWS CLI not found or not responding\")\n",
    "    aws_cli_configured = False\n",
    "\n",
    "# Method 3: Check environment variables\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_region = os.getenv('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "\n",
    "print(f\"\\n🔧 Environment Variables:\")\n",
    "if aws_access_key:\n",
    "    print(f\"🔑 AWS_ACCESS_KEY_ID: {aws_access_key}\")\n",
    "    print(f\"🔐 AWS_SECRET_ACCESS_KEY: {'*' * (len(aws_secret_key) - 4) + aws_secret_key[-4:] if aws_secret_key else 'NOT SET'}\")\n",
    "    print(f\"🌍 AWS_DEFAULT_REGION: {aws_region}\")\n",
    "    env_vars_configured = True\n",
    "else:\n",
    "    print(\"❌ No AWS environment variables found\")\n",
    "    env_vars_configured = False\n",
    "\n",
    "# Method 4: Try to load from .env file (optional)\n",
    "env_file_configured = False\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    if os.path.exists('.env'):\n",
    "        load_dotenv()\n",
    "        print(f\"\\n📄 .env file found and loaded\")\n",
    "        # Re-check environment variables after loading .env\n",
    "        aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "        if aws_access_key:\n",
    "            env_file_configured = True\n",
    "            print(f\"🔑 Loaded AWS_ACCESS_KEY_ID from .env: {aws_access_key}\")\n",
    "    else:\n",
    "        print(f\"\\n📄 No .env file found (this is OK if AWS CLI or IAM role is configured)\")\n",
    "except ImportError:\n",
    "    print(f\"\\n📄 python-dotenv not installed (this is OK if AWS CLI or IAM role is configured)\")\n",
    "\n",
    "# Summary and Test Connection\n",
    "print(f\"\\n🎯 Credentials Summary:\")\n",
    "print(f\"✅ IAM Role: {iam_role_available} {'(' + role_name + ')' if role_name else ''}\")\n",
    "print(f\"✅ AWS CLI Configured: {aws_cli_configured}\")\n",
    "print(f\"✅ Environment Variables: {env_vars_configured}\")\n",
    "print(f\"✅ .env File: {env_file_configured}\")\n",
    "\n",
    "credentials_available = iam_role_available or aws_cli_configured or env_vars_configured or env_file_configured\n",
    "\n",
    "if credentials_available:\n",
    "    print(f\"\\n🚀 Testing S3 Connection...\")\n",
    "    \n",
    "    # Test S3 access\n",
    "    try:\n",
    "        import boto3\n",
    "        from botocore.exceptions import NoCredentialsError, ClientError\n",
    "        \n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # Test basic S3 access\n",
    "        response = s3_client.list_buckets()\n",
    "        print(\"✅ S3 connection successful!\")\n",
    "        \n",
    "        # Check if elbee-ai bucket is accessible\n",
    "        try:\n",
    "            s3_client.head_bucket(Bucket='elbee-ai')\n",
    "            print(\"✅ elbee-ai bucket accessible!\")\n",
    "            \n",
    "            # Test your IAM role permissions\n",
    "            if iam_role_available:\n",
    "                print(f\"\\n🎯 Testing IAM Role Permissions ({role_name}):\")\n",
    "                \n",
    "                # Test ListBucket permission\n",
    "                try:\n",
    "                    response = s3_client.list_objects_v2(\n",
    "                        Bucket='elbee-ai', \n",
    "                        Prefix='project-data/',\n",
    "                        MaxKeys=5\n",
    "                    )\n",
    "                    print(\"✅ s3:ListBucket permission working\")\n",
    "                    \n",
    "                    if 'Contents' in response:\n",
    "                        print(f\"📁 Files in elbee-ai/project-data/:\")\n",
    "                        for obj in response['Contents']:\n",
    "                            file_size_mb = obj['Size'] / (1024 * 1024)\n",
    "                            print(f\"  📄 {obj['Key']} ({file_size_mb:.2f} MB)\")\n",
    "                            \n",
    "                        # Test GetObject permission on first file\n",
    "                        first_file = response['Contents'][0]['Key']\n",
    "                        try:\n",
    "                            s3_client.head_object(Bucket='elbee-ai', Key=first_file)\n",
    "                            print(\"✅ s3:GetObject permission working\")\n",
    "                        except ClientError as e:\n",
    "                            print(f\"❌ s3:GetObject permission issue: {e}\")\n",
    "                    else:\n",
    "                        print(f\"📁 project-data/ folder is empty or doesn't exist\")\n",
    "                        \n",
    "                except ClientError as e:\n",
    "                    error_code = e.response['Error']['Code']\n",
    "                    if error_code == 'AccessDenied':\n",
    "                        print(\"❌ s3:ListBucket permission denied - check IAM policy\")\n",
    "                    else:\n",
    "                        print(f\"❌ ListBucket error: {error_code}\")\n",
    "            else:\n",
    "                # List files for non-IAM role authentication\n",
    "                try:\n",
    "                    response = s3_client.list_objects_v2(\n",
    "                        Bucket='elbee-ai', \n",
    "                        Prefix='project-data/',\n",
    "                        MaxKeys=5\n",
    "                    )\n",
    "                    if 'Contents' in response:\n",
    "                        print(f\"📁 Files in elbee-ai/project-data/:\")\n",
    "                        for obj in response['Contents']:\n",
    "                            file_size_mb = obj['Size'] / (1024 * 1024)\n",
    "                            print(f\"  📄 {obj['Key']} ({file_size_mb:.2f} MB)\")\n",
    "                    else:\n",
    "                        print(f\"📁 project-data/ folder is empty or doesn't exist\")\n",
    "                except ClientError as e:\n",
    "                    print(f\"⚠️ Could not list files in project-data/: {e}\")\n",
    "                \n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == '403':\n",
    "                print(\"❌ Access denied to elbee-ai bucket - check permissions\")\n",
    "            elif error_code == '404':\n",
    "                print(\"❌ elbee-ai bucket not found\")\n",
    "            else:\n",
    "                print(f\"❌ Error accessing elbee-ai bucket: {error_code}\")\n",
    "        \n",
    "    except NoCredentialsError:\n",
    "        print(\"❌ AWS credentials not properly configured\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error testing S3 connection: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n❌ No AWS credentials found!\")\n",
    "    print(f\"💡 Options:\")\n",
    "    print(f\"   1. Use IAM role (recommended for EC2/ECS/Lambda)\")\n",
    "    print(f\"   2. Configure AWS CLI: aws configure\")\n",
    "    print(f\"   3. Set environment variables\")\n",
    "    print(f\"   4. Create .env file\")\n",
    "\n",
    "print(f\"\\n📁 Working Directory: {os.getcwd()}\")\n",
    "\n",
    "if iam_role_available:\n",
    "    print(f\"🎯 Using IAM Role authentication - Most secure! 🔒\")\n",
    "else:\n",
    "    print(f\"🎯 Using traditional credential authentication\")\n",
    "    \n",
    "print(f\"🎯 Ready to proceed with S3 data loading!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b57465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Quick AWS Setup Verification\n",
      "========================================\n",
      "✅ All required libraries installed\n",
      "✅ AWS Identity: arn:aws:iam::819556863188:root\n",
      "✅ S3 Access: Found 1 buckets\n",
      "✅ elbee-ai bucket accessible\n",
      "\n",
      "🎉 READY TO GO!\n",
      "✅ All systems operational\n",
      "✅ You can now run the rest of the notebook\n",
      "\n",
      "📁 Current directory: Unknown\n",
      "🎯 Notebook ready for temperature/humidity analysis!\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Quick AWS Setup Test\n",
    "# Run this cell first to verify everything is working\n",
    "\n",
    "print(\"🔍 Quick AWS Setup Verification\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"✅ All required libraries installed\")\n",
    "    \n",
    "    # Test AWS credentials\n",
    "    try:\n",
    "        s3 = boto3.client('s3')\n",
    "        sts = boto3.client('sts')\n",
    "        \n",
    "        # Get identity\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"✅ AWS Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "        \n",
    "        # Test S3 access\n",
    "        buckets = s3.list_buckets()\n",
    "        print(f\"✅ S3 Access: Found {len(buckets['Buckets'])} buckets\")\n",
    "        \n",
    "        # Test target bucket\n",
    "        s3.head_bucket(Bucket='elbee-ai')\n",
    "        print(\"✅ elbee-ai bucket accessible\")\n",
    "        \n",
    "        print(\"\\n🎉 READY TO GO!\")\n",
    "        print(\"✅ All systems operational\")\n",
    "        print(\"✅ You can now run the rest of the notebook\")\n",
    "        \n",
    "    except Exception as aws_error:\n",
    "        print(f\"❌ AWS Error: {aws_error}\")\n",
    "        print(\"\\n💡 To fix AWS issues:\")\n",
    "        print(\"1. Export credentials: export AWS_ACCESS_KEY_ID='your_key'\")\n",
    "        print(\"2. Export secret: export AWS_SECRET_ACCESS_KEY='your_secret'\")\n",
    "        print(\"3. Export region: export AWS_DEFAULT_REGION='us-east-1'\")\n",
    "        print(\"4. Re-run this cell\")\n",
    "        \n",
    "except ImportError as import_error:\n",
    "    print(f\"❌ Import Error: {import_error}\")\n",
    "    print(\"💡 Install missing packages: pip install boto3 pandas numpy matplotlib\")\n",
    "\n",
    "print(f\"\\n📁 Current directory: {os.getcwd() if 'os' in locals() else 'Unknown'}\")\n",
    "print(f\"🎯 Notebook ready for temperature/humidity analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11dc519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Installing required packages for AWS S3 integration...\n",
      "==================================================\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.40.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.64 (from boto3)\n",
      "  Using cached botocore-1.40.64-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3)\n",
      "  Using cached s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from botocore<1.41.0,>=1.40.64->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from botocore<1.41.0,>=1.40.64->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.64->boto3) (1.17.0)\n",
      "Using cached boto3-1.40.64-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.40.64-py3-none-any.whl (14.1 MB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [boto3]32m1/4\u001b[0m [botocore]\n",
      "\u001b[1A\u001b[2KSuccessfully installed boto3-1.40.64 botocore-1.40.64 jmespath-1.0.1 s3transfer-0.14.0\n",
      "✅ boto3 installed successfully\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n",
      "✅ python-dotenv installed successfully\n",
      "Requirement already satisfied: pandas in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "✅ pandas installed successfully\n",
      "Requirement already satisfied: numpy in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (2.3.4)\n",
      "✅ numpy installed successfully\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "✅ matplotlib installed successfully\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "✅ seaborn installed successfully\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from scikit-learn) (2.3.4)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n",
      "✅ scikit-learn installed successfully\n",
      "\n",
      "📊 Installation Summary:\n",
      "✅ Successfully installed: 7/7 packages\n",
      "🎉 All packages installed! You can proceed to the next cell.\n",
      "\n",
      "🔄 Please restart the notebook kernel after installation if needed.\n"
     ]
    }
   ],
   "source": [
    "# 📦 Install Required Packages\n",
    "# Run this cell first to install necessary packages\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ {package} installed successfully\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"📦 Installing required packages for AWS S3 integration...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"boto3\",\n",
    "    \"python-dotenv\",\n",
    "    \"pandas\",\n",
    "    \"numpy\", \n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "installed_count = 0\n",
    "for package in required_packages:\n",
    "    if install_package(package):\n",
    "        installed_count += 1\n",
    "\n",
    "print(f\"\\n📊 Installation Summary:\")\n",
    "print(f\"✅ Successfully installed: {installed_count}/{len(required_packages)} packages\")\n",
    "\n",
    "if installed_count == len(required_packages):\n",
    "    print(\"🎉 All packages installed! You can proceed to the next cell.\")\n",
    "else:\n",
    "    print(\"⚠️ Some packages failed to install. You may need to install them manually.\")\n",
    "    print(\"💡 Try running: pip install boto3 python-dotenv\")\n",
    "\n",
    "print(\"\\n🔄 Please restart the notebook kernel after installation if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Advanced AWS Environment Diagnostic\n",
    "# Run this cell to diagnose AWS configuration issues\n",
    "\n",
    "print(\"🔍 Advanced AWS Environment Diagnostic\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "# 1. Check Python environment\n",
    "print(\"🐍 Python Environment:\")\n",
    "print(f\"   Python version: {sys.version}\")\n",
    "print(f\"   Python executable: {sys.executable}\")\n",
    "print(f\"   Current working directory: {os.getcwd()}\")\n",
    "print()\n",
    "\n",
    "# 2. Check if running on Windows host vs WSL/container - Fixed for Windows compatibility\n",
    "print(\"💻 System Environment:\")\n",
    "print(f\"   Platform: {sys.platform}\")\n",
    "print(f\"   OS name: {os.name}\")\n",
    "system_platform = platform.system()\n",
    "print(f\"   System: {system_platform}\")\n",
    "\n",
    "if os.name == 'nt' or system_platform == 'Windows':\n",
    "    print(\"   🪟 Running on Windows\")\n",
    "    \n",
    "    # Check if in WSL by looking for WSL-specific environment variables\n",
    "    is_wsl = 'WSL_DISTRO_NAME' in os.environ or 'WSL_INTEROP' in os.environ\n",
    "    if is_wsl:\n",
    "        print(\"   🐧 WSL detected within Windows\")\n",
    "else:\n",
    "    print(\"   🐧 Running on Unix-like system\")\n",
    "    \n",
    "    # Safe WSL detection for Linux systems\n",
    "    try:\n",
    "        platform_info = subprocess.run(['uname', '-a'], capture_output=True, text=True, timeout=5)\n",
    "        if platform_info.returncode == 0 and 'microsoft' in platform_info.stdout.lower():\n",
    "            print(\"   🐧 WSL (Windows Subsystem for Linux) detected\")\n",
    "    except Exception:\n",
    "        pass  # Ignore if uname fails\n",
    "print()\n",
    "\n",
    "# 3. Check AWS CLI configuration\n",
    "print(\"⚙️ AWS CLI Configuration:\")\n",
    "try:\n",
    "    # Check if AWS CLI is available - using 'where' on Windows, 'which' on Unix\n",
    "    if system_platform == 'Windows':\n",
    "        aws_check_cmd = ['where', 'aws']\n",
    "    else:\n",
    "        aws_check_cmd = ['which', 'aws']\n",
    "    \n",
    "    aws_location = subprocess.run(aws_check_cmd, capture_output=True, text=True, timeout=10)\n",
    "    \n",
    "    if aws_location.returncode == 0:\n",
    "        print(f\"   ✅ AWS CLI found at: {aws_location.stdout.strip()}\")\n",
    "        \n",
    "        # Check AWS version\n",
    "        aws_version = subprocess.run(['aws', '--version'], capture_output=True, text=True, timeout=10)\n",
    "        if aws_version.returncode == 0:\n",
    "            print(f\"   ✅ AWS CLI version: {aws_version.stdout.strip()}\")\n",
    "        \n",
    "        # Check AWS configuration\n",
    "        aws_config = subprocess.run(['aws', 'configure', 'list'], capture_output=True, text=True, timeout=10)\n",
    "        if aws_config.returncode == 0:\n",
    "            print(\"   ✅ AWS CLI configuration:\")\n",
    "            for line in aws_config.stdout.split('\\n'):\n",
    "                if line.strip():\n",
    "                    print(f\"      {line}\")\n",
    "        else:\n",
    "            print(\"   ❌ AWS CLI not configured\")\n",
    "            print(f\"   Error output: {aws_config.stderr}\")\n",
    "    else:\n",
    "        print(\"   ❌ AWS CLI not found in PATH\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"   ❌ AWS CLI command not found\")\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"   ❌ AWS CLI command timed out\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Error checking AWS CLI: {e}\")\n",
    "print()\n",
    "\n",
    "# 4. Check environment variables\n",
    "print(\"🌍 Environment Variables:\")\n",
    "aws_env_vars = ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'AWS_DEFAULT_REGION', 'AWS_REGION', 'AWS_PROFILE']\n",
    "for var in aws_env_vars:\n",
    "    value = os.environ.get(var)\n",
    "    if value:\n",
    "        if 'SECRET' in var:\n",
    "            print(f\"   ✅ {var}: ***[HIDDEN]***\")\n",
    "        else:\n",
    "            print(f\"   ✅ {var}: {value}\")\n",
    "    else:\n",
    "        print(f\"   ❌ {var}: Not set\")\n",
    "print()\n",
    "\n",
    "# 5. Check boto3 configuration\n",
    "print(\"🔄 Boto3 Configuration:\")\n",
    "try:\n",
    "    import boto3\n",
    "    print(\"   ✅ boto3 imported successfully\")\n",
    "    \n",
    "    # Check current session\n",
    "    session = boto3.Session()\n",
    "    credentials = session.get_credentials()\n",
    "    \n",
    "    if credentials:\n",
    "        print(\"   ✅ Credentials found\")\n",
    "        print(f\"      Access Key: {credentials.access_key[:8]}***[HIDDEN]***\")\n",
    "        if hasattr(credentials, 'method'):\n",
    "            print(f\"      Method: {credentials.method}\")\n",
    "    else:\n",
    "        print(\"   ❌ No credentials found\")\n",
    "    \n",
    "    # Check region\n",
    "    region = session.region_name\n",
    "    if region:\n",
    "        print(f\"   ✅ Region: {region}\")\n",
    "    else:\n",
    "        print(\"   ❌ No region configured\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"   ❌ boto3 not installed\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ boto3 error: {e}\")\n",
    "print()\n",
    "\n",
    "# 6. Test AWS connectivity\n",
    "print(\"🌐 AWS Connectivity Test:\")\n",
    "try:\n",
    "    import boto3\n",
    "    \n",
    "    # Test STS (most basic AWS service)\n",
    "    print(\"   Testing STS (Identity service)...\")\n",
    "    sts = boto3.client('sts')\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(f\"   ✅ Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "    print(f\"   ✅ Account: {identity.get('Account', 'Unknown')}\")\n",
    "    print(f\"   ✅ User ID: {identity.get('UserId', 'Unknown')}\")\n",
    "    \n",
    "    # Test S3 access\n",
    "    print(\"   Testing S3 access...\")\n",
    "    s3 = boto3.client('s3')\n",
    "    buckets = s3.list_buckets()\n",
    "    print(f\"   ✅ S3 Access: Found {len(buckets['Buckets'])} buckets\")\n",
    "    \n",
    "    # Test specific bucket\n",
    "    print(\"   Testing elbee-ai bucket...\")\n",
    "    try:\n",
    "        s3.head_bucket(Bucket='elbee-ai')\n",
    "        print(\"   ✅ elbee-ai bucket accessible\")\n",
    "    except Exception as bucket_error:\n",
    "        print(f\"   ❌ elbee-ai bucket error: {bucket_error}\")\n",
    "    \n",
    "    print(\"\\n🎉 AWS CONNECTION SUCCESSFUL!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ AWS connection failed: {e}\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    \n",
    "    print(\"\\n🔧 Troubleshooting Steps:\")\n",
    "    if system_platform == 'Windows':\n",
    "        print(\"1. Since you're on Windows:\")\n",
    "        print(\"   - Open Command Prompt or PowerShell as Administrator\")\n",
    "        print(\"   - Run: aws configure\")\n",
    "        print(\"   - Enter your AWS Access Key ID and Secret\")\n",
    "        print(\"   - Set region to: us-east-1\")\n",
    "        print()\n",
    "        print(\"2. Alternative for Jupyter:\")\n",
    "        print(\"   - Set environment variables in a cell:\")\n",
    "        print(\"   import os\")\n",
    "        print(\"   os.environ['AWS_ACCESS_KEY_ID'] = 'your_key_here'\")\n",
    "        print(\"   os.environ['AWS_SECRET_ACCESS_KEY'] = 'your_secret_here'\")\n",
    "        print(\"   os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\")\n",
    "    else:\n",
    "        print(\"1. If on Unix/Linux system:\")\n",
    "        print(\"   - Open terminal\")\n",
    "        print(\"   - Run: aws configure\")\n",
    "        print(\"   - Enter your AWS Access Key ID and Secret\")\n",
    "        print(\"   - Set region to: us-east-1\")\n",
    "    print()\n",
    "    print(\"3. If credentials are set but still failing:\")\n",
    "    print(\"   - Restart Jupyter server\")\n",
    "    print(\"   - Restart kernel: Kernel > Restart Kernel\")\n",
    "    print(\"   - Check if credentials are correctly typed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🎯 Diagnostic Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f19714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ AWS Credentials Quick Fix\n",
    "# Run this cell if the diagnostic shows missing credentials\n",
    "\n",
    "print(\"🛠️ AWS Credentials Quick Fix\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import os\n",
    "\n",
    "# Option 1: Set credentials directly (temporary fix)\n",
    "print(\"Option 1: Set credentials directly in this session\")\n",
    "print(\"⚠️ WARNING: Only use this for testing, not for production!\")\n",
    "print()\n",
    "\n",
    "# Get credentials from user input or environment\n",
    "access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "if not access_key:\n",
    "    print(\"💡 AWS Access Key ID not found in environment\")\n",
    "    print(\"   Please set it using one of these methods:\")\n",
    "    print(\"   1. aws configure\")\n",
    "    print(\"   2. export AWS_ACCESS_KEY_ID='your-access-key'\")\n",
    "    print(\"   3. Uncomment and edit the lines below:\")\n",
    "    print()\n",
    "    print(\"# Uncomment and fill in your credentials if needed:\")\n",
    "    print(\"# os.environ['AWS_ACCESS_KEY_ID'] = 'your-access-key-here'\")\n",
    "    print(\"# os.environ['AWS_SECRET_ACCESS_KEY'] = 'your-secret-key-here'\")\n",
    "    print(\"# os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\")\n",
    "\n",
    "# Check if credentials are now set\n",
    "aws_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "if aws_key:\n",
    "    print(f\"✅ AWS_ACCESS_KEY_ID: {aws_key[:8]}***[HIDDEN]***\")\n",
    "else:\n",
    "    print(\"❌ AWS_ACCESS_KEY_ID: Not set\")\n",
    "\n",
    "aws_secret = os.environ.get('AWS_SECRET_ACCESS_KEY') \n",
    "if aws_secret:\n",
    "    print(\"✅ AWS_SECRET_ACCESS_KEY: ***[HIDDEN]***\")\n",
    "else:\n",
    "    print(\"❌ AWS_SECRET_ACCESS_KEY: Not set\")\n",
    "\n",
    "aws_region = os.environ.get('AWS_DEFAULT_REGION')\n",
    "if aws_region:\n",
    "    print(f\"✅ AWS_DEFAULT_REGION: {aws_region}\")\n",
    "else:\n",
    "    print(\"❌ AWS_DEFAULT_REGION: Not set\")\n",
    "\n",
    "print()\n",
    "print(\"💡 Recommended setup methods:\")\n",
    "print(\"1. AWS CLI configuration:\")\n",
    "print(\"   - Open Command Prompt or Terminal\")\n",
    "print(\"   - Run: aws configure\")\n",
    "print(\"   - Enter your credentials when prompted\")\n",
    "print(\"2. Environment variables (temporary):\")\n",
    "print(\"   - Windows: Use setup_aws_credentials.ps1\")\n",
    "print(\"   - Linux/WSL: Use source export_aws_credentials.sh\")\n",
    "print(\"3. Restart Jupyter server after AWS CLI configuration\")\n",
    "\n",
    "# Test if credentials work now\n",
    "if aws_key and aws_secret:\n",
    "    print(\"\\n🧪 Testing credentials...\")\n",
    "    try:\n",
    "        import boto3\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"✅ SUCCESS! Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Still having issues: {e}\")\n",
    "else:\n",
    "    print(\"\\n⏭️ Set credentials above and re-run this cell to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Generate AWS Export Scripts for Different Environments\n",
    "# This cell creates export scripts for various shell environments\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"🚀 AWS Credentials Export Script Generator\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get AWS credentials from environment or AWS CLI\n",
    "AWS_ACCESS_KEY_ID = os.environ.get('AWS_ACCESS_KEY_ID', '')\n",
    "AWS_SECRET_ACCESS_KEY = os.environ.get('AWS_SECRET_ACCESS_KEY', '')\n",
    "AWS_DEFAULT_REGION = os.environ.get('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "\n",
    "# Try to get credentials from AWS CLI if not in environment\n",
    "if not AWS_ACCESS_KEY_ID:\n",
    "    try:\n",
    "        import boto3\n",
    "        session = boto3.Session()\n",
    "        credentials = session.get_credentials()\n",
    "        if credentials:\n",
    "            AWS_ACCESS_KEY_ID = credentials.access_key\n",
    "            AWS_SECRET_ACCESS_KEY = credentials.secret_key\n",
    "            print(\"📋 Retrieved credentials from AWS CLI configuration\")\n",
    "        else:\n",
    "            print(\"⚠️ No credentials found in AWS CLI configuration\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not retrieve AWS CLI credentials: {e}\")\n",
    "\n",
    "# Check current environment - Fixed for Windows compatibility\n",
    "current_os = os.name\n",
    "system_platform = platform.system()\n",
    "is_wsl = False\n",
    "\n",
    "# Safe way to check for WSL without using uname on Windows\n",
    "try:\n",
    "    if system_platform == \"Linux\":\n",
    "        # Only run uname on Linux systems\n",
    "        platform_info = subprocess.run(['uname', '-a'], capture_output=True, text=True, errors='ignore')\n",
    "        is_wsl = 'microsoft' in platform_info.stdout.lower() if platform_info.returncode == 0 else False\n",
    "    elif system_platform == \"Windows\":\n",
    "        # Check for WSL environment variables on Windows\n",
    "        is_wsl = 'WSL_DISTRO_NAME' in os.environ or 'WSL_INTEROP' in os.environ\n",
    "except Exception:\n",
    "    # If any command fails, assume native environment\n",
    "    pass\n",
    "\n",
    "print(f\"💻 Environment Detection:\")\n",
    "print(f\"   OS Type: {current_os}\")\n",
    "print(f\"   Platform: {system_platform}\")\n",
    "print(f\"   WSL Status: {'WSL' if is_wsl else 'Native'}\")\n",
    "\n",
    "# Get secret key if not set\n",
    "if not AWS_SECRET_ACCESS_KEY:\n",
    "    print(\"\\n🔐 AWS Secret Key Required:\")\n",
    "    print(\"⚠️  No AWS credentials found in environment or AWS CLI\")\n",
    "    print(\"💡 Please set up credentials using one of these methods:\")\n",
    "    print(\"   1. Run: aws configure\")\n",
    "    print(\"   2. Use the credential setup scripts\")\n",
    "    print(\"   3. Set environment variables manually\")\n",
    "    \n",
    "    # Use placeholder for template generation\n",
    "    AWS_ACCESS_KEY_ID = AWS_ACCESS_KEY_ID or \"YOUR_ACCESS_KEY_HERE\"\n",
    "    AWS_SECRET_ACCESS_KEY = \"YOUR_SECRET_KEY_HERE\"\n",
    "\n",
    "print(f\"\\n📋 Current AWS Configuration:\")\n",
    "if AWS_ACCESS_KEY_ID and AWS_ACCESS_KEY_ID != \"YOUR_ACCESS_KEY_HERE\":\n",
    "    print(f\"✅ AWS_ACCESS_KEY_ID: {AWS_ACCESS_KEY_ID[:8]}***\")\n",
    "else:\n",
    "    print(f\"❌ AWS_ACCESS_KEY_ID: Not configured\")\n",
    "\n",
    "if AWS_SECRET_ACCESS_KEY and AWS_SECRET_ACCESS_KEY != \"YOUR_SECRET_KEY_HERE\":\n",
    "    print(f\"✅ AWS_SECRET_ACCESS_KEY: ***[CONFIGURED]***\")\n",
    "else:\n",
    "    print(f\"❌ AWS_SECRET_ACCESS_KEY: Not configured\")\n",
    "\n",
    "print(f\"✅ AWS_DEFAULT_REGION: {AWS_DEFAULT_REGION}\")\n",
    "\n",
    "# Generate export commands for different environments\n",
    "print(f\"\\n📋 Export Commands for Different Environments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n🪟 Windows Command Prompt:\")\n",
    "print(f\"set AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\")\n",
    "print(f\"set AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\")\n",
    "print(f\"set AWS_DEFAULT_REGION={AWS_DEFAULT_REGION}\")\n",
    "\n",
    "print(f\"\\n💙 PowerShell:\")\n",
    "print(f\"$env:AWS_ACCESS_KEY_ID = '{AWS_ACCESS_KEY_ID}'\")\n",
    "print(f\"$env:AWS_SECRET_ACCESS_KEY = '{AWS_SECRET_ACCESS_KEY}'\")\n",
    "print(f\"$env:AWS_DEFAULT_REGION = '{AWS_DEFAULT_REGION}'\")\n",
    "\n",
    "print(f\"\\n🐧 Bash/WSL/Linux:\")\n",
    "print(f\"export AWS_ACCESS_KEY_ID='{AWS_ACCESS_KEY_ID}'\")\n",
    "print(f\"export AWS_SECRET_ACCESS_KEY='{AWS_SECRET_ACCESS_KEY}'\")\n",
    "print(f\"export AWS_DEFAULT_REGION='{AWS_DEFAULT_REGION}'\")\n",
    "\n",
    "print(f\"\\n🐍 Python/Jupyter (this session):\")\n",
    "print(f\"os.environ['AWS_ACCESS_KEY_ID'] = '{AWS_ACCESS_KEY_ID}'\")\n",
    "print(f\"os.environ['AWS_SECRET_ACCESS_KEY'] = '{AWS_SECRET_ACCESS_KEY}'\")\n",
    "print(f\"os.environ['AWS_DEFAULT_REGION'] = '{AWS_DEFAULT_REGION}'\")\n",
    "\n",
    "# Set for current Python session if credentials are valid\n",
    "if (AWS_ACCESS_KEY_ID and AWS_ACCESS_KEY_ID != \"YOUR_ACCESS_KEY_HERE\" and \n",
    "    AWS_SECRET_ACCESS_KEY and AWS_SECRET_ACCESS_KEY != \"YOUR_SECRET_KEY_HERE\"):\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = AWS_ACCESS_KEY_ID\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_ACCESS_KEY\n",
    "    os.environ['AWS_DEFAULT_REGION'] = AWS_DEFAULT_REGION\n",
    "    print(f\"\\n✅ Environment variables set for current Python session!\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Skipping Python session setup - credentials not configured\")\n",
    "    print(f\"💡 Please run 'aws configure' or set credentials manually\")\n",
    "\n",
    "# Check available export scripts\n",
    "script_files = [\n",
    "    'export_aws_credentials.ps1',\n",
    "    'export_aws_credentials.bat', \n",
    "    'export_aws_credentials.sh'\n",
    "]\n",
    "\n",
    "print(f\"\\n📂 Available Export Scripts:\")\n",
    "for script in script_files:\n",
    "    script_path = Path(script)\n",
    "    if script_path.exists():\n",
    "        print(f\"✅ {script} - Ready to use\")\n",
    "    else:\n",
    "        print(f\"❌ {script} - Not found\")\n",
    "\n",
    "print(f\"\\n💡 How to Use the Export Scripts:\")\n",
    "if system_platform == \"Windows\":\n",
    "    print(\"🪟 Since you're on Windows:\")\n",
    "    print(\"1. Command Prompt: Run export_aws_credentials.bat\")\n",
    "    print(\"2. PowerShell: Run ./export_aws_credentials.ps1\")\n",
    "    print(\"3. For WSL: Run source export_aws_credentials.sh (inside WSL)\")\n",
    "    print(\"4. Jupyter (current): Run the Python commands above\")\n",
    "else:\n",
    "    print(\"1. 🪟 Windows Command Prompt: Run export_aws_credentials.bat\")\n",
    "    print(\"2. 💙 PowerShell: Run ./export_aws_credentials.ps1\")\n",
    "    print(\"3. 🐧 Bash/WSL: Run source export_aws_credentials.sh\")\n",
    "    print(\"4. 🐍 Jupyter: Run the Python commands above in a cell\")\n",
    "\n",
    "# Test current environment\n",
    "print(f\"\\n🧪 Testing Current Environment:\")\n",
    "current_access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "current_secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "current_region = os.environ.get('AWS_DEFAULT_REGION')\n",
    "\n",
    "if current_access_key:\n",
    "    print(f\"✅ AWS_ACCESS_KEY_ID: {current_access_key[:8]}***\")\n",
    "else:\n",
    "    print(f\"❌ AWS_ACCESS_KEY_ID: Not set\")\n",
    "\n",
    "if current_secret_key:\n",
    "    print(f\"✅ AWS_SECRET_ACCESS_KEY: ***[HIDDEN]***\")\n",
    "else:\n",
    "    print(f\"❌ AWS_SECRET_ACCESS_KEY: Not set\")\n",
    "\n",
    "if current_region:\n",
    "    print(f\"✅ AWS_DEFAULT_REGION: {current_region}\")\n",
    "else:\n",
    "    print(f\"❌ AWS_DEFAULT_REGION: Not set\")\n",
    "\n",
    "if current_access_key and current_secret_key:\n",
    "    print(f\"\\n🎉 AWS credentials are configured for this session!\")\n",
    "    try:\n",
    "        import boto3\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"✅ AWS Identity verified: {identity.get('Arn', 'Unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ AWS test failed: {e}\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ AWS credentials need to be set up\")\n",
    "\n",
    "print(f\"\\n🎯 Next Steps:\")\n",
    "print(\"1. Configure AWS credentials using 'aws configure'\")\n",
    "print(\"2. Re-run this cell to generate proper export commands\")\n",
    "print(\"3. Use one of the export scripts for persistent setup\")\n",
    "print(\"4. Run the diagnostic cell to verify setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📤 S3 Data Preparation (Optional)\n",
    "# This cell creates and uploads sample data if it doesn't exist in S3\n",
    "\n",
    "def create_and_upload_sample_data():\n",
    "    \"\"\"Create sample temperature/humidity data and upload to S3 if original file doesn't exist\"\"\"\n",
    "    \n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime, timedelta\n",
    "    from io import StringIO\n",
    "    \n",
    "    print(\"📤 Preparing sample data for S3...\")\n",
    "    \n",
    "    # Create realistic temperature/humidity data\n",
    "    np.random.seed(42)\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    end_date = datetime(2024, 12, 31)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "    \n",
    "    n_samples = len(date_range)\n",
    "    day_of_year = date_range.dayofyear\n",
    "    hour_of_day = date_range.hour\n",
    "    \n",
    "    # Temperature with seasonal and daily patterns\n",
    "    base_temp = 15 + 10 * np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "    daily_temp = 5 * np.sin(2 * np.pi * hour_of_day / 24)\n",
    "    noise_temp = np.random.normal(0, 2, n_samples)\n",
    "    temperature = base_temp + daily_temp + noise_temp\n",
    "    \n",
    "    # Humidity with inverse temperature relationship\n",
    "    base_humidity = 60 + 20 * np.sin(2 * np.pi * (day_of_year + 90) / 365.25)\n",
    "    temp_humidity = -0.5 * (temperature - 20)\n",
    "    noise_humidity = np.random.normal(0, 5, n_samples)\n",
    "    humidity = np.clip(base_humidity + temp_humidity + noise_humidity, 10, 95)\n",
    "    \n",
    "    # Absolute humidity calculation\n",
    "    absolute_humidity = (humidity / 100) * 6.112 * np.exp(17.67 * temperature / (243.5 + temperature))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': date_range,\n",
    "        'temperature': np.round(temperature, 1),\n",
    "        'humidity': np.round(humidity, 1),\n",
    "        'absolute_humidity': np.round(absolute_humidity, 2),\n",
    "        'location': np.random.choice(['실내', '실외'], n_samples, p=[0.6, 0.4])\n",
    "    })\n",
    "    \n",
    "    # Convert to CSV string\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False, encoding='utf-8')\n",
    "    csv_content = csv_buffer.getvalue()\n",
    "    \n",
    "    # Upload to S3\n",
    "    try:\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_client.put_object(\n",
    "            Bucket='elbee-ai',\n",
    "            Key='project-data/온습도_관측_데이터.csv',\n",
    "            Body=csv_content.encode('utf-8'),\n",
    "            ContentType='text/csv'\n",
    "        )\n",
    "        print(f\"✅ Sample data uploaded to s3://elbee-ai/project-data/온습도_관측_데이터.csv\")\n",
    "        print(f\"📊 Data shape: {df.shape}\")\n",
    "        print(f\"📅 Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to upload sample data: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check if data exists, if not create and upload sample data\n",
    "try:\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.head_object(Bucket='elbee-ai', Key='project-data/온습도_관측_데이터.csv')\n",
    "    print(\"✅ Data file already exists in S3!\")\n",
    "    \n",
    "except s3_client.exceptions.NoSuchKey:\n",
    "    print(\"⚠️ Data file not found in S3. Creating sample data...\")\n",
    "    success = create_and_upload_sample_data()\n",
    "    if success:\n",
    "        print(\"🎯 Ready to proceed with data analysis!\")\n",
    "    else:\n",
    "        print(\"⚠️ Will proceed with local simulation data\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not check S3 file: {e}\")\n",
    "    print(\"💡 Will attempt to create sample data...\")\n",
    "    create_and_upload_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec121e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 필수 라이브러리 Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ☁️ AWS 관련 라이브러리\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError, NoCredentialsError\n",
    "import io\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Scikit-Learn 데이터 분할 관련 모듈들\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,      # 기본 train/test 분할\n",
    "    StratifiedShuffleSplit, # 계층화 분할\n",
    "    TimeSeriesSplit,       # 시계열 분할\n",
    "    cross_val_score,       # 교차검증\n",
    "    validation_curve       # 검증 곡선\n",
    ")\n",
    "\n",
    "# 모델링 관련\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# 🔤 한글 폰트 설정 (matplotlib) - 개선된 버전\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "\n",
    "def setup_korean_fonts():\n",
    "    \"\"\"한글 폰트를 자동으로 감지하고 설정하는 함수\"\"\"\n",
    "    \n",
    "    print(\"🔤 한글 폰트 설정 중...\")\n",
    "    \n",
    "        \"    # 운영체제별 한글 폰트 리스트 (우선순위 순)\\\\n\",\n",
    "    \"    if platform.system() == 'Windows':\\\\n\",\n",
    "    \"        korean_fonts = ['Gulim', 'Malgun Gothic', 'Microsoft YaHei', 'SimHei']\\\\n\",\n",
    "    \"    elif platform.system() == 'Darwin':  # macOS\\\\n\",\n",
    "    \"        korean_fonts = ['Gulim', 'Apple SD Gothic Neo', 'AppleGothic']\\\\n\",\n",
    "    \"    else:  # Linux\\\\n\",\n",
    "    \"        korean_fonts = ['Gulim', 'Noto Sans CJK KR', 'Nanum Gothic', 'DejaVu Sans']\"\n",
    "    \n",
    "    # 사용 가능한 폰트 검색\n",
    "    available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "    print(f\"📝 시스템 폰트 수: {len(available_fonts)}개\")\n",
    "    \n",
    "    selected_font = None\n",
    "    for font in korean_fonts:\n",
    "        if font in available_fonts:\n",
    "            selected_font = font\n",
    "            print(f\"✅ 선택된 한글 폰트: {selected_font}\")\n",
    "            break\n",
    "    \n",
    "    if selected_font:\n",
    "        plt.rcParams['font.family'] = selected_font\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        \n",
    "        # 간단한 폰트 테스트 (시각화 없이)\n",
    "        print(f\"✅ 한글 폰트 설정 완료: {selected_font}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ 한글 폰트를 찾을 수 없습니다. 기본 설정을 사용합니다.\")\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        selected_font = 'DejaVu Sans'\n",
    "    \n",
    "    return selected_font\n",
    "\n",
    "# 한글 폰트 설정 실행\n",
    "font_name = setup_korean_fonts()\n",
    "\n",
    "print(\"✅ 모든 라이브러리가 성공적으로 로드되었습니다!\")\n",
    "print(f\"📊 Pandas Version: {pd.__version__}\")\n",
    "print(f\"🔢 NumPy Version: {np.__version__}\")\n",
    "print(f\"☁️ Boto3 Version: {boto3.__version__}\")\n",
    "print(f\"🤖 Scikit-Learn 분할 모듈들이 준비되었습니다!\")\n",
    "print(f\"📈 Matplotlib & Seaborn 시각화 준비완료!\")\n",
    "print(f\"🔤 한글 폰트: {font_name}\")\n",
    "print(\"\\n🎯 AWS S3 기반 온습도 센서 데이터 분석을 시작하겠습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8a7ea",
   "metadata": {},
   "source": [
    "## ☁️ **Section 2: AWS S3 Configuration and Data Loading**\n",
    "AWS S3 설정 및 온습도 센서 데이터를 클라우드에서 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cf550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ☁️ AWS S3 클라이언트 설정\n",
    "print(\"☁️ AWS S3 클라이언트를 설정하고 있습니다...\")\n",
    "\n",
    "# S3 버킷 및 경로 설정\n",
    "S3_BUCKET = 'elbee-ai'\n",
    "S3_PREFIX = 'project-data/'\n",
    "DATA_FILE_NAME = '온습도_관측_데이터.csv'  # 원본 파일명과 동일\n",
    "S3_DATA_KEY = f\"{S3_PREFIX}{DATA_FILE_NAME}\"\n",
    "\n",
    "def setup_s3_client():\n",
    "    \"\"\"AWS S3 클라이언트를 설정하고 연결을 테스트하는 함수\"\"\"\n",
    "    try:\n",
    "        # AWS 자격 증명 방법 (우선순위 순):\n",
    "        # 1. 환경변수 (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "        # 2. AWS CLI 설정 (~/.aws/credentials)\n",
    "        # 3. IAM 역할 (EC2/Lambda에서 실행 시)\n",
    "        \n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # 연결 테스트 - 버킷 존재 여부 확인\n",
    "        try:\n",
    "            s3_client.head_bucket(Bucket=S3_BUCKET)\n",
    "            print(f\"✅ S3 버킷 '{S3_BUCKET}' 연결 성공!\")\n",
    "            \n",
    "            # 버킷 내 파일 목록 확인 (프리픽스 기준)\n",
    "            response = s3_client.list_objects_v2(\n",
    "                Bucket=S3_BUCKET, \n",
    "                Prefix=S3_PREFIX,\n",
    "                MaxKeys=10\n",
    "            )\n",
    "            \n",
    "            if 'Contents' in response:\n",
    "                print(f\"📁 '{S3_PREFIX}' 경로의 파일 목록:\")\n",
    "                for obj in response['Contents']:\n",
    "                    file_size_mb = obj['Size'] / (1024 * 1024)\n",
    "                    print(f\"  📄 {obj['Key']} ({file_size_mb:.2f} MB)\")\n",
    "            else:\n",
    "                print(f\"📁 '{S3_PREFIX}' 경로에 파일이 없습니다.\")\n",
    "                \n",
    "            return s3_client\n",
    "            \n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == '404':\n",
    "                print(f\"❌ S3 버킷 '{S3_BUCKET}'을 찾을 수 없습니다.\")\n",
    "            else:\n",
    "                print(f\"❌ S3 버킷 액세스 오류: {error_code}\")\n",
    "            return None\n",
    "            \n",
    "    except NoCredentialsError:\n",
    "        print(\"❌ AWS 자격 증명을 찾을 수 없습니다.\")\n",
    "        print(\"💡 다음 중 하나를 설정하세요:\")\n",
    "        print(\"   1. 환경변수: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\")\n",
    "        print(\"   2. AWS CLI: aws configure\")\n",
    "        print(\"   3. IAM 역할 (클라우드 환경)\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ S3 클라이언트 설정 중 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_data_from_s3(s3_client, bucket, key):\n",
    "    \"\"\"S3에서 CSV 데이터를 로드하는 함수\"\"\"\n",
    "    try:\n",
    "        print(f\"📥 S3에서 데이터를 다운로드 중: s3://{bucket}/{key}\")\n",
    "        \n",
    "        # S3 객체 다운로드\n",
    "        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        \n",
    "        # CSV 데이터 읽기\n",
    "        csv_content = response['Body'].read()\n",
    "        \n",
    "        # 인코딩 시도 (한글 파일명 고려)\n",
    "        encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "        df = None\n",
    "        \n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                df = pd.read_csv(io.BytesIO(csv_content), encoding=encoding)\n",
    "                print(f\"✅ 인코딩 '{encoding}'으로 데이터 로드 성공!\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if df is None:\n",
    "            print(\"❌ 모든 인코딩 시도 실패. UTF-8로 강제 로드합니다.\")\n",
    "            df = pd.read_csv(io.BytesIO(csv_content), encoding='utf-8', errors='ignore')\n",
    "        \n",
    "        print(f\"✅ S3 데이터 로드 완료! 크기: {df.shape}\")\n",
    "        return df\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == 'NoSuchKey':\n",
    "            print(f\"❌ 파일을 찾을 수 없습니다: s3://{bucket}/{key}\")\n",
    "        else:\n",
    "            print(f\"❌ S3 다운로드 오류: {error_code}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터 로드 중 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_simulation_data():\n",
    "    \"\"\"S3 데이터를 로드할 수 없을 때 시뮬레이션 데이터를 생성하는 함수\"\"\"\n",
    "    print(\"🔄 시뮬레이션 온습도 데이터를 생성 중...\")\n",
    "    \n",
    "    # 시간 범위 설정 (최근 1년간의 시간당 데이터)\n",
    "    np.random.seed(42)  # 재현 가능한 결과를 위한 시드 설정\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    end_date = datetime(2024, 12, 31)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "    # 실제와 유사한 온습도 패턴 생성\n",
    "    n_samples = len(date_range)\n",
    "\n",
    "    # 계절별 온도 패턴 (한국 기후 반영)\n",
    "    day_of_year = date_range.dayofyear\n",
    "    hour_of_day = date_range.hour\n",
    "\n",
    "    # 기본 온도 패턴 (계절성 + 일일 주기)\n",
    "    base_temp = 15 + 10 * np.sin(2 * np.pi * day_of_year / 365.25)  # 계절 패턴\n",
    "    daily_temp = 5 * np.sin(2 * np.pi * hour_of_day / 24)  # 일일 패턴\n",
    "    noise_temp = np.random.normal(0, 2, n_samples)  # 노이즈\n",
    "    temperature = base_temp + daily_temp + noise_temp\n",
    "\n",
    "    # 습도 패턴 (온도와 반비례 관계 + 계절성)\n",
    "    base_humidity = 60 + 20 * np.sin(2 * np.pi * (day_of_year + 90) / 365.25)  # 계절 패턴\n",
    "    temp_humidity = -0.5 * (temperature - 20)  # 온도와 반비례\n",
    "    noise_humidity = np.random.normal(0, 5, n_samples)  # 노이즈\n",
    "    humidity = np.clip(base_humidity + temp_humidity + noise_humidity, 10, 95)\n",
    "\n",
    "    # 절대습도 계산 (온도와 상대습도로부터)\n",
    "    absolute_humidity = (humidity / 100) * 6.112 * np.exp(17.67 * temperature / (243.5 + temperature))\n",
    "\n",
    "    # 기상 조건 분류 (온습도 기반)\n",
    "    conditions = []\n",
    "    for temp, hum in zip(temperature, humidity):\n",
    "        if temp < 5:\n",
    "            condition = \"추위\" if hum < 60 else \"습한추위\"\n",
    "        elif temp < 20:\n",
    "            condition = \"서늘함\" if hum < 60 else \"습한서늘함\"\n",
    "        elif temp < 30:\n",
    "            condition = \"적정\" if hum < 70 else \"습함\"\n",
    "        else:\n",
    "            condition = \"더위\" if hum < 80 else \"무더위\"\n",
    "        conditions.append(condition)\n",
    "\n",
    "    # 센서 위치 (실내/실외 구분)\n",
    "    sensor_locations = np.random.choice(['실내', '실외'], n_samples, p=[0.6, 0.4])\n",
    "\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': date_range,\n",
    "        'temperature': np.round(temperature, 1),\n",
    "        'humidity': np.round(humidity, 1),\n",
    "        'absolute_humidity': np.round(absolute_humidity, 2),\n",
    "        'condition': conditions,\n",
    "        'location': sensor_locations,\n",
    "        'day_of_week': date_range.day_name(),\n",
    "        'hour': date_range.hour,\n",
    "        'month': date_range.month,\n",
    "        'season': pd.cut(date_range.month, \n",
    "                         bins=[0, 3, 6, 9, 12], \n",
    "                         labels=['겨울', '봄', '여름', '가을'])\n",
    "    })\n",
    "    \n",
    "    print(f\"✅ 시뮬레이션 데이터 생성 완료! 크기: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# S3 클라이언트 설정 및 데이터 로드 실행\n",
    "s3_client = setup_s3_client()\n",
    "sensor_data = None\n",
    "\n",
    "if s3_client:\n",
    "    # S3에서 데이터 로드 시도\n",
    "    sensor_data = load_data_from_s3(s3_client, S3_BUCKET, S3_DATA_KEY)\n",
    "\n",
    "if sensor_data is None:\n",
    "    # S3 로드 실패 시 시뮬레이션 데이터 생성\n",
    "    print(\"\\n⚠️ S3에서 데이터를 로드할 수 없어 시뮬레이션 데이터를 사용합니다.\")\n",
    "    sensor_data = create_simulation_data()\n",
    "else:\n",
    "    print(\"\\n✅ S3에서 실제 온습도 데이터를 성공적으로 로드했습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ead92",
   "metadata": {},
   "source": [
    "## 🔄 **Section 3: Data Preprocessing and Standardization**\n",
    "S3에서 로드한 데이터를 전처리하고 표준화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92203912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 S3 데이터 전처리 및 표준화\n",
    "print(\"🔄 S3 데이터 전처리 및 표준화를 시작합니다...\")\n",
    "\n",
    "def standardize_s3_data(df):\n",
    "    \"\"\"S3에서 로드한 데이터를 표준 형식으로 변환하는 함수\"\"\"\n",
    "    print(f\"📋 원본 데이터 정보: {df.shape}, 컬럼: {list(df.columns)}\")\n",
    "    \n",
    "    # 데이터프레임 복사\n",
    "    standardized_df = df.copy()\n",
    "    \n",
    "    # 1. 타임스탬프 컬럼 처리\n",
    "    timestamp_columns = ['timestamp', 'datetime', 'date', 'time', 'Date', 'Time']\n",
    "    timestamp_col = None\n",
    "    \n",
    "    for col in timestamp_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            timestamp_col = col\n",
    "            break\n",
    "    \n",
    "    if timestamp_col:\n",
    "        print(f\"📅 타임스탬프 컬럼 '{timestamp_col}' 발견\")\n",
    "        if standardized_df[timestamp_col].dtype == 'object':\n",
    "            standardized_df[timestamp_col] = pd.to_datetime(standardized_df[timestamp_col])\n",
    "        if timestamp_col != 'timestamp':\n",
    "            standardized_df['timestamp'] = standardized_df[timestamp_col]\n",
    "    else:\n",
    "        print(\"📅 타임스탬프 컬럼이 없어 인덱스 기반으로 생성합니다.\")\n",
    "        standardized_df['timestamp'] = pd.date_range(start='2024-01-01', periods=len(standardized_df), freq='H')\n",
    "    \n",
    "    # 2. 온도 컬럼 매핑\n",
    "    temp_columns = ['temperature', 'temp', 'T', 'Temperature', 'TEMP']\n",
    "    temp_col = None\n",
    "    \n",
    "    for col in temp_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            temp_col = col\n",
    "            break\n",
    "    \n",
    "    if temp_col and temp_col != 'temperature':\n",
    "        standardized_df['temperature'] = standardized_df[temp_col]\n",
    "        print(f\"🌡️ 온도 컬럼 '{temp_col}' → 'temperature'로 매핑\")\n",
    "    elif not temp_col:\n",
    "        print(\"⚠️ 온도 컬럼을 찾을 수 없습니다. 첫 번째 숫자 컬럼을 사용합니다.\")\n",
    "        numeric_cols = standardized_df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            standardized_df['temperature'] = standardized_df[numeric_cols[0]]\n",
    "    \n",
    "    # 3. 습도 컬럼 매핑\n",
    "    humidity_columns = ['humidity', 'rh', 'RH', 'Humidity', 'HUMIDITY']\n",
    "    humidity_col = None\n",
    "    \n",
    "    for col in humidity_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            humidity_col = col\n",
    "            break\n",
    "    \n",
    "    if humidity_col and humidity_col != 'humidity':\n",
    "        standardized_df['humidity'] = standardized_df[humidity_col]\n",
    "        print(f\"💧 습도 컬럼 '{humidity_col}' → 'humidity'로 매핑\")\n",
    "    elif not humidity_col:\n",
    "        print(\"⚠️ 습도 컬럼을 찾을 수 없습니다. 두 번째 숫자 컬럼을 사용합니다.\")\n",
    "        numeric_cols = standardized_df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            standardized_df['humidity'] = standardized_df[numeric_cols[1]]\n",
    "    \n",
    "    # 4. 절대습도 컬럼 처리\n",
    "    abs_humidity_columns = ['absolute_humidity', 'ah', 'AH', 'AbsoluteHumidity']\n",
    "    abs_humidity_col = None\n",
    "    \n",
    "    for col in abs_humidity_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            abs_humidity_col = col\n",
    "            break\n",
    "    \n",
    "    if abs_humidity_col and abs_humidity_col != 'absolute_humidity':\n",
    "        standardized_df['absolute_humidity'] = standardized_df[abs_humidity_col]\n",
    "        print(f\"💨 절대습도 컬럼 '{abs_humidity_col}' → 'absolute_humidity'로 매핑\")\n",
    "    elif not abs_humidity_col:\n",
    "        # 절대습도가 없으면 온도와 상대습도로부터 계산\n",
    "        if 'temperature' in standardized_df.columns and 'humidity' in standardized_df.columns:\n",
    "            print(\"💨 절대습도를 온도와 상대습도로부터 계산합니다.\")\n",
    "            temp = standardized_df['temperature']\n",
    "            rh = standardized_df['humidity']\n",
    "            # Magnus 공식을 사용한 절대습도 계산\n",
    "            standardized_df['absolute_humidity'] = (rh / 100) * 6.112 * np.exp(17.67 * temp / (243.5 + temp))\n",
    "    \n",
    "    # 5. 파생 변수 생성\n",
    "    if 'timestamp' in standardized_df.columns:\n",
    "        ts = standardized_df['timestamp']\n",
    "        standardized_df['hour'] = ts.dt.hour\n",
    "        standardized_df['day_of_week'] = ts.dt.day_name()\n",
    "        standardized_df['month'] = ts.dt.month\n",
    "        standardized_df['season'] = pd.cut(ts.dt.month, \n",
    "                                         bins=[0, 3, 6, 9, 12], \n",
    "                                         labels=['겨울', '봄', '여름', '가을'])\n",
    "        print(\"📅 시간 기반 파생 변수 생성 완료\")\n",
    "    \n",
    "    # 6. 기상 조건 분류 (온습도가 있는 경우)\n",
    "    if 'temperature' in standardized_df.columns and 'humidity' in standardized_df.columns:\n",
    "        conditions = []\n",
    "        for temp, hum in zip(standardized_df['temperature'], standardized_df['humidity']):\n",
    "            if pd.isna(temp) or pd.isna(hum):\n",
    "                conditions.append('알수없음')\n",
    "            elif temp < 5:\n",
    "                condition = \"추위\" if hum < 60 else \"습한추위\"\n",
    "                conditions.append(condition)\n",
    "            elif temp < 20:\n",
    "                condition = \"서늘함\" if hum < 60 else \"습한서늘함\"\n",
    "                conditions.append(condition)\n",
    "            elif temp < 30:\n",
    "                condition = \"적정\" if hum < 70 else \"습함\"\n",
    "                conditions.append(condition)\n",
    "            else:\n",
    "                condition = \"더위\" if hum < 80 else \"무더위\"\n",
    "                conditions.append(condition)\n",
    "        \n",
    "        standardized_df['condition'] = conditions\n",
    "        print(\"🌤️ 기상 조건 분류 완료\")\n",
    "    \n",
    "    # 7. 센서 위치 정보 (없으면 랜덤 생성)\n",
    "    if 'location' not in standardized_df.columns:\n",
    "        np.random.seed(42)\n",
    "        standardized_df['location'] = np.random.choice(['실내', '실외'], len(standardized_df), p=[0.6, 0.4])\n",
    "        print(\"📍 센서 위치 정보 생성 완료\")\n",
    "    \n",
    "    print(f\"✅ 데이터 표준화 완료! 최종 크기: {standardized_df.shape}\")\n",
    "    return standardized_df\n",
    "\n",
    "# 데이터 표준화 실행\n",
    "sensor_data = standardize_s3_data(sensor_data)\n",
    "\n",
    "# 표준화된 데이터 정보 출력\n",
    "print(f\"\\n📊 표준화된 데이터 정보:\")\n",
    "print(f\"📏 데이터 크기: {sensor_data.shape}\")\n",
    "print(f\"📊 컬럼 목록: {list(sensor_data.columns)}\")\n",
    "\n",
    "if 'timestamp' in sensor_data.columns:\n",
    "    print(f\"📅 기간: {sensor_data['timestamp'].min()} ~ {sensor_data['timestamp'].max()}\")\n",
    "if 'temperature' in sensor_data.columns:\n",
    "    print(f\"🌡️ 온도 범위: {sensor_data['temperature'].min():.1f}°C ~ {sensor_data['temperature'].max():.1f}°C\")\n",
    "if 'humidity' in sensor_data.columns:\n",
    "    print(f\"💧 습도 범위: {sensor_data['humidity'].min():.1f}% ~ {sensor_data['humidity'].max():.1f}%\")\n",
    "if 'absolute_humidity' in sensor_data.columns:\n",
    "    print(f\"💨 절대습도 범위: {sensor_data['absolute_humidity'].min():.2f} ~ {sensor_data['absolute_humidity'].max():.2f} g/m³\")\n",
    "\n",
    "# 데이터 구조 확인\n",
    "print(f\"\\n📊 데이터 구조:\")\n",
    "print(sensor_data.info())\n",
    "\n",
    "print(f\"\\n📈 첫 10개 레코드:\")\n",
    "display(sensor_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25814a",
   "metadata": {},
   "source": [
    "## 🔍 **Section 4: Enhanced Data Exploration and Quality Assessment**\n",
    "S3 데이터의 품질을 평가하고 탐색적 분석을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0139825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 S3 데이터 품질 평가 및 탐색적 분석\n",
    "print(\"🔍 S3 온습도 데이터 품질 평가 및 탐색적 분석을 시작합니다...\")\n",
    "\n",
    "# 1. 데이터 품질 평가\n",
    "print(\"\\n📊 === 데이터 품질 평가 ===\")\n",
    "\n",
    "# 기술통계량\n",
    "numeric_cols = sensor_data.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\n📈 숫자형 컬럼 기술통계량:\")\n",
    "print(sensor_data[numeric_cols].describe())\n",
    "\n",
    "# 결측값 확인\n",
    "print(f\"\\n❓ 결측값 확인:\")\n",
    "missing_values = sensor_data.isnull().sum()\n",
    "missing_percent = (missing_values / len(sensor_data)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    '결측값 개수': missing_values,\n",
    "    '결측값 비율(%)': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['결측값 개수'] > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"✅ 결측값이 없습니다!\")\n",
    "\n",
    "# 중복값 확인\n",
    "duplicate_count = sensor_data.duplicated().sum()\n",
    "print(f\"\\n🔄 중복 레코드: {duplicate_count}개 ({duplicate_count/len(sensor_data)*100:.1f}%)\")\n",
    "\n",
    "# 2. 데이터 분포 시각화\n",
    "print(\"\\n📊 === 데이터 분포 시각화 ===\")\n",
    "\n",
    "if 'temperature' in sensor_data.columns and 'humidity' in sensor_data.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('🌡️💧 온습도 데이터 분포 분석 (S3 소스)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 온도 분포\n",
    "    axes[0, 0].hist(sensor_data['temperature'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[0, 0].set_title('온도 분포')\n",
    "    axes[0, 0].set_xlabel('온도 (°C)')\n",
    "    axes[0, 0].set_ylabel('빈도')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 습도 분포\n",
    "    axes[0, 1].hist(sensor_data['humidity'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 1].set_title('습도 분포')\n",
    "    axes[0, 1].set_xlabel('습도 (%)')\n",
    "    axes[0, 1].set_ylabel('빈도')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 온도-습도 산점도\n",
    "    axes[1, 0].scatter(sensor_data['temperature'], sensor_data['humidity'], \n",
    "                      alpha=0.5, s=10, c='green')\n",
    "    axes[1, 0].set_title('온도-습도 상관관계')\n",
    "    axes[1, 0].set_xlabel('온도 (°C)')\n",
    "    axes[1, 0].set_ylabel('습도 (%)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 기상 조건 분포\n",
    "    if 'condition' in sensor_data.columns:\n",
    "        condition_counts = sensor_data['condition'].value_counts()\n",
    "        axes[1, 1].pie(condition_counts.values, labels=condition_counts.index, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('기상 조건 분포')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. 시계열 패턴 분석\n",
    "if 'timestamp' in sensor_data.columns:\n",
    "    print(\"\\n📅 === 시계열 패턴 분석 ===\")\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    fig.suptitle('📈 시계열 패턴 분석 (S3 데이터)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 시간별 온도 변화\n",
    "    if 'temperature' in sensor_data.columns:\n",
    "        axes[0].plot(sensor_data['timestamp'], sensor_data['temperature'], \n",
    "                    alpha=0.7, color='red', linewidth=0.5)\n",
    "        axes[0].set_title('시간별 온도 변화')\n",
    "        axes[0].set_ylabel('온도 (°C)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 시간별 습도 변화\n",
    "    if 'humidity' in sensor_data.columns:\n",
    "        axes[1].plot(sensor_data['timestamp'], sensor_data['humidity'], \n",
    "                    alpha=0.7, color='blue', linewidth=0.5)\n",
    "        axes[1].set_title('시간별 습도 변화')\n",
    "        axes[1].set_ylabel('습도 (%)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 일별 평균 패턴\n",
    "    if 'hour' in sensor_data.columns and 'temperature' in sensor_data.columns:\n",
    "        hourly_avg = sensor_data.groupby('hour')[['temperature', 'humidity']].mean()\n",
    "        axes[2].plot(hourly_avg.index, hourly_avg['temperature'], \n",
    "                    'o-', color='red', label='온도', linewidth=2)\n",
    "        if 'humidity' in hourly_avg.columns:\n",
    "            ax2 = axes[2].twinx()\n",
    "            ax2.plot(hourly_avg.index, hourly_avg['humidity'], \n",
    "                    's-', color='blue', label='습도', linewidth=2)\n",
    "            ax2.set_ylabel('습도 (%)', color='blue')\n",
    "            ax2.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        axes[2].set_title('시간대별 평균 온습도 패턴')\n",
    "        axes[2].set_xlabel('시간 (0-23)')\n",
    "        axes[2].set_ylabel('온도 (°C)', color='red')\n",
    "        axes[2].tick_params(axis='y', labelcolor='red')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. 상관관계 분석\n",
    "print(\"\\n🔗 === 상관관계 분석 ===\")\n",
    "correlation_matrix = sensor_data[numeric_cols].corr()\n",
    "print(\"📊 숫자형 변수 간 상관관계:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# 상관관계 히트맵\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('🔗 변수 간 상관관계 히트맵 (S3 데이터)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. 데이터 품질 요약\n",
    "print(\"\\n✅ === S3 데이터 품질 요약 ===\")\n",
    "print(f\"📏 전체 레코드 수: {len(sensor_data):,}개\")\n",
    "print(f\"📊 전체 컬럼 수: {len(sensor_data.columns)}개\")\n",
    "print(f\"🔢 숫자형 컬럼: {len(numeric_cols)}개\")\n",
    "print(f\"❓ 결측값 비율: {(missing_values.sum() / (len(sensor_data) * len(sensor_data.columns)) * 100):.2f}%\")\n",
    "print(f\"🔄 중복값 비율: {(duplicate_count / len(sensor_data) * 100):.2f}%\")\n",
    "\n",
    "if 'timestamp' in sensor_data.columns:\n",
    "    time_span = sensor_data['timestamp'].max() - sensor_data['timestamp'].min()\n",
    "    print(f\"📅 데이터 기간: {time_span.days}일 ({time_span.total_seconds()/3600:.1f}시간)\")\n",
    "\n",
    "print(\"\\n🎯 S3 데이터 탐색이 완료되었습니다. 이제 Scikit-Learn 분할 분석을 진행하겠습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d34614",
   "metadata": {},
   "source": [
    "## 📖 **Section 5: Scikit-Learn Data Splitting with AWS S3**\n",
    "이제 S3에서 로드한 온습도 데이터를 사용하여 Scikit-Learn의 다양한 데이터 분할 기법을 실습합니다.\n",
    "\n",
    "### 🎯 **학습 목표:**\n",
    "1. **Basic Train/Test Split** - 기본적인 데이터 분할\n",
    "2. **Stratified Split** - 클래스 비율을 유지하는 분할\n",
    "3. **Time Series Split** - 시계열 데이터에 적합한 분할\n",
    "4. **Cross-Validation** - 교차 검증을 통한 모델 성능 평가\n",
    "5. **결과를 S3에 저장** - 분할된 데이터와 모델 결과를 클라우드에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Cross-Platform AWS Environment Detection and Auto-Setup\n",
    "# This cell automatically detects your environment and provides setup guidance\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def detect_execution_environment():\n",
    "    \"\"\"Comprehensive environment detection for AWS S3 integration\"\"\"\n",
    "    \n",
    "    env_info = {\n",
    "        'platform_system': platform.system(),\n",
    "        'platform_machine': platform.machine(),\n",
    "        'python_version': sys.version,\n",
    "        'python_executable': sys.executable,\n",
    "        'working_directory': os.getcwd(),\n",
    "        'is_wsl': False,\n",
    "        'is_jupyter': False,\n",
    "        'aws_cli_available': False,\n",
    "        'aws_cli_path': None,\n",
    "        'conda_environment': None,\n",
    "        'venv_active': False\n",
    "    }\n",
    "    \n",
    "    print(\"🔍 Environment Detection and Setup Guidance\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Detect WSL\n",
    "    try:\n",
    "        if env_info['platform_system'] == 'Linux':\n",
    "            with open('/proc/version', 'r') as f:\n",
    "                if 'microsoft' in f.read().lower():\n",
    "                    env_info['is_wsl'] = True\n",
    "        elif env_info['platform_system'] == 'Windows':\n",
    "            env_info['is_wsl'] = any(var in os.environ for var in ['WSL_DISTRO_NAME', 'WSL_INTEROP'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Detect Jupyter environment\n",
    "    env_info['is_jupyter'] = any(module in sys.modules for module in ['ipykernel', 'IPython'])\n",
    "    \n",
    "    # Detect virtual environment\n",
    "    env_info['venv_active'] = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "    \n",
    "    # Detect conda environment\n",
    "    if 'CONDA_DEFAULT_ENV' in os.environ:\n",
    "        env_info['conda_environment'] = os.environ['CONDA_DEFAULT_ENV']\n",
    "    \n",
    "    # Check AWS CLI availability\n",
    "    try:\n",
    "        if env_info['platform_system'] == 'Windows':\n",
    "            cmd = ['where', 'aws']\n",
    "        else:\n",
    "            cmd = ['which', 'aws']\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            env_info['aws_cli_available'] = True\n",
    "            env_info['aws_cli_path'] = result.stdout.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return env_info\n",
    "\n",
    "def check_aws_credentials():\n",
    "    \"\"\"Check AWS credentials availability\"\"\"\n",
    "    print(\"\\n🔐 AWS Credentials Check:\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    # Check environment variables\n",
    "    aws_vars = ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'AWS_DEFAULT_REGION']\n",
    "    env_creds = all(os.environ.get(var) for var in aws_vars)\n",
    "    \n",
    "    for var in aws_vars:\n",
    "        value = os.environ.get(var)\n",
    "        if value:\n",
    "            if 'SECRET' in var:\n",
    "                print(f\"   ✅ {var}: ***[HIDDEN]***\")\n",
    "            else:\n",
    "                print(f\"   ✅ {var}: {value}\")\n",
    "        else:\n",
    "            print(f\"   ❌ {var}: Not set\")\n",
    "    \n",
    "    # Test boto3 credentials\n",
    "    try:\n",
    "        import boto3\n",
    "        session = boto3.Session()\n",
    "        credentials = session.get_credentials()\n",
    "        \n",
    "        if credentials:\n",
    "            print(f\"   ✅ Boto3 session: Available\")\n",
    "            print(f\"   ✅ Access key: {credentials.access_key[:8]}***\")\n",
    "        else:\n",
    "            print(f\"   ❌ Boto3 session: No credentials found\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(f\"   ⚠️ Boto3 not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Boto3 error: {e}\")\n",
    "    \n",
    "    return env_creds\n",
    "\n",
    "def provide_setup_guidance(env_info, has_credentials):\n",
    "    \"\"\"Provide environment-specific setup guidance\"\"\"\n",
    "    print(f\"\\n🎯 Setup Guidance for Your Environment:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"💻 Platform: {env_info['platform_system']}\")\n",
    "    print(f\"🐍 Python: {env_info['python_executable']}\")\n",
    "    \n",
    "    if env_info['conda_environment']:\n",
    "        print(f\"🐍 Conda Env: {env_info['conda_environment']}\")\n",
    "    elif env_info['venv_active']:\n",
    "        print(f\"🐍 Virtual Env: Active\")\n",
    "    \n",
    "    print(f\"📓 Jupyter: {'Yes' if env_info['is_jupyter'] else 'No'}\")\n",
    "    print(f\"🐧 WSL: {'Yes' if env_info['is_wsl'] else 'No'}\")\n",
    "    print(f\"⚙️ AWS CLI: {'Available' if env_info['aws_cli_available'] else 'Not found'}\")\n",
    "    \n",
    "    if env_info['aws_cli_path']:\n",
    "        print(f\"📍 AWS CLI Path: {env_info['aws_cli_path']}\")\n",
    "    \n",
    "    # Provide specific guidance\n",
    "    print(f\"\\n💡 Recommended Setup Steps:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    step = 1\n",
    "    \n",
    "    # AWS CLI installation\n",
    "    if not env_info['aws_cli_available']:\n",
    "        print(f\"{step}. 📥 Install AWS CLI:\")\n",
    "        if env_info['platform_system'] == 'Windows':\n",
    "            print(f\"   Windows: Run install_aws_windows.bat\")\n",
    "            print(f\"   Or: Download from https://aws.amazon.com/cli/\")\n",
    "        else:\n",
    "            print(f\"   Linux/WSL: Run bash install_aws_linux.sh\")\n",
    "            print(f\"   Or: curl https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\")\n",
    "        step += 1\n",
    "    \n",
    "    # Credentials setup\n",
    "    if not has_credentials:\n",
    "        print(f\"{step}. 🔐 Configure AWS Credentials:\")\n",
    "        if env_info['platform_system'] == 'Windows':\n",
    "            print(f\"   PowerShell: .\\\\setup_aws_credentials.ps1 -Persistent\")\n",
    "            print(f\"   Command Prompt: aws configure\")\n",
    "        else:\n",
    "            print(f\"   Terminal: aws configure\")\n",
    "            print(f\"   Or: export AWS_ACCESS_KEY_ID='your-key'\")\n",
    "        step += 1\n",
    "    \n",
    "    # Package installation\n",
    "    print(f\"{step}. 📦 Install Required Packages:\")\n",
    "    print(f\"   pip install boto3 pandas numpy matplotlib scikit-learn\")\n",
    "    step += 1\n",
    "    \n",
    "    # Test setup\n",
    "    print(f\"{step}. 🧪 Test Your Setup:\")\n",
    "    print(f\"   python test_aws_integration.py\")\n",
    "    \n",
    "    print(f\"\\n📚 Documentation:\")\n",
    "    print(f\"   📖 Full Guide: AWS_S3_INTEGRATION_GUIDE.md\")\n",
    "    print(f\"   🔧 Windows Script: install_aws_windows.bat\")\n",
    "    print(f\"   🐧 Linux Script: install_aws_linux.sh\")\n",
    "    print(f\"   💙 PowerShell: setup_aws_credentials.ps1\")\n",
    "\n",
    "def check_required_packages():\n",
    "    \"\"\"Check if required packages are installed\"\"\"\n",
    "    print(f\"\\n📦 Required Packages Check:\")\n",
    "    print(\"-\" * 28)\n",
    "    \n",
    "    required_packages = {\n",
    "        'boto3': 'AWS SDK for Python',\n",
    "        'pandas': 'Data manipulation and analysis',\n",
    "        'numpy': 'Numerical computing',\n",
    "        'matplotlib': 'Data visualization',\n",
    "        'scikit-learn': 'Machine learning library'\n",
    "    }\n",
    "    \n",
    "    missing_packages = []\n",
    "    \n",
    "    for package, description in required_packages.items():\n",
    "        try:\n",
    "            if package == 'scikit-learn':\n",
    "                __import__('sklearn')\n",
    "            else:\n",
    "                __import__(package)\n",
    "            print(f\"   ✅ {package}: {description}\")\n",
    "        except ImportError:\n",
    "            print(f\"   ❌ {package}: Not installed - {description}\")\n",
    "            missing_packages.append(package)\n",
    "    \n",
    "    if missing_packages:\n",
    "        print(f\"\\n💡 Install missing packages:\")\n",
    "        print(f\"   pip install {' '.join(missing_packages)}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"\\n✅ All required packages are installed!\")\n",
    "        return True\n",
    "\n",
    "def create_quick_setup_scripts():\n",
    "    \"\"\"Create platform-specific quick setup scripts in current directory\"\"\"\n",
    "    print(f\"\\n📝 Creating Quick Setup Scripts:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Check if scripts already exist\n",
    "    scripts = {\n",
    "        'quick_aws_setup.py': 'Python setup script',\n",
    "        'setup_env.bat': 'Windows batch script',\n",
    "        'setup_env.sh': 'Linux/WSL shell script'\n",
    "    }\n",
    "    \n",
    "    for script, description in scripts.items():\n",
    "        script_path = Path(script)\n",
    "        if script_path.exists():\n",
    "            print(f\"   ✅ {script}: Already exists - {description}\")\n",
    "        else:\n",
    "            print(f\"   📝 {script}: Will be created - {description}\")\n",
    "    \n",
    "    # Python setup script\n",
    "    python_script = '''#!/usr/bin/env python3\n",
    "\"\"\"Quick AWS S3 setup verification and troubleshooting\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def quick_aws_test():\n",
    "    print(\"🧪 Quick AWS S3 Integration Test\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Test imports\n",
    "    try:\n",
    "        import boto3\n",
    "        print(\"✅ boto3 imported successfully\")\n",
    "    except ImportError:\n",
    "        print(\"❌ boto3 not installed: pip install boto3\")\n",
    "        return False\n",
    "    \n",
    "    # Test credentials\n",
    "    try:\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"✅ AWS Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "        \n",
    "        # Test S3\n",
    "        s3 = boto3.client('s3')\n",
    "        buckets = s3.list_buckets()\n",
    "        print(f\"✅ S3 Access: {len(buckets['Buckets'])} buckets found\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ AWS Error: {e}\")\n",
    "        print(\"💡 Fix: Run 'aws configure' or set environment variables\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = quick_aws_test()\n",
    "    sys.exit(0 if success else 1)\n",
    "'''\n",
    "    \n",
    "    with open('quick_aws_setup.py', 'w') as f:\n",
    "        f.write(python_script)\n",
    "    \n",
    "    print(f\"   ✅ quick_aws_setup.py created\")\n",
    "    print(f\"\\n💡 Run: python quick_aws_setup.py\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    \"\"\"Main environment detection and setup function\"\"\"\n",
    "    \n",
    "    # Detect environment\n",
    "    env_info = detect_execution_environment()\n",
    "    \n",
    "    # Check AWS credentials\n",
    "    has_credentials = check_aws_credentials()\n",
    "    \n",
    "    # Check required packages\n",
    "    packages_ok = check_required_packages()\n",
    "    \n",
    "    # Provide setup guidance\n",
    "    provide_setup_guidance(env_info, has_credentials)\n",
    "    \n",
    "    # Create quick setup scripts\n",
    "    create_quick_setup_scripts()\n",
    "    \n",
    "    # Final status\n",
    "    print(f\"\\n🎯 Environment Status Summary:\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"   Platform: {env_info['platform_system']}\")\n",
    "    print(f\"   AWS CLI: {'✅ Available' if env_info['aws_cli_available'] else '❌ Missing'}\")\n",
    "    print(f\"   Credentials: {'✅ Configured' if has_credentials else '❌ Missing'}\")\n",
    "    print(f\"   Packages: {'✅ Complete' if packages_ok else '❌ Missing'}\")\n",
    "    \n",
    "    all_ready = env_info['aws_cli_available'] and has_credentials and packages_ok\n",
    "    \n",
    "    if all_ready:\n",
    "        print(f\"\\n🎉 Your environment is ready for AWS S3 integration!\")\n",
    "        print(f\"✅ You can proceed with the notebook analysis\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ Setup required before proceeding\")\n",
    "        print(f\"💡 Follow the guidance above to complete setup\")\n",
    "    \n",
    "    return all_ready\n",
    "\n",
    "# Run the environment detection\n",
    "environment_ready = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Track - NLP Advanced",
   "language": "python",
   "name": "ai-track-nlp-advanced"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
