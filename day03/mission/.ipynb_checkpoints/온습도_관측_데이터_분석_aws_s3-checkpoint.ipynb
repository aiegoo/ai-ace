{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0f7111",
   "metadata": {},
   "source": [
    "# ğŸŒ¡ï¸ ì˜¨ìŠµë„ ê´€ì¸¡ ë°ì´í„° ë¶„ì„ - AWS S3 Enhanced Version\n",
    "(Temperature & Humidity Sensor Data Analysis - AWS S3 Integration)\n",
    "\n",
    "**WebEx ê°•ì˜ ì‹¤ìŠµ - Scikit-Learn Data Splitting + AWS S3 Data Pipeline**\n",
    "\n",
    "## ğŸ“‹ **í•™ìŠµ ëª©í‘œ:**\n",
    "1. **AWS S3ì—ì„œ ì˜¨ìŠµë„ ì„¼ì„œ ë°ì´í„°** ë¡œë“œ ë° íƒìƒ‰\n",
    "2. **Boto3ë¥¼ í™œìš©í•œ í´ë¼ìš°ë“œ ë°ì´í„° íŒŒì´í”„ë¼ì¸** êµ¬ì¶•\n",
    "3. **Scikit-Learn train_test_split** í™œìš©í•œ ë°ì´í„° ë¶„í• \n",
    "4. **Stratified Splitting** ìœ¼ë¡œ ë°ì´í„° ë¶„í¬ ìœ ì§€\n",
    "5. **Time Series Splitting** ìœ¼ë¡œ ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬\n",
    "6. **ë°ì´í„° ë¶„í•  í’ˆì§ˆ ê²€ì¦** ë° ëª¨ë¸ í•™ìŠµ\n",
    "7. **ê²°ê³¼ë¥¼ S3ë¡œ ì—…ë¡œë“œ** í•˜ëŠ” ì™„ì „í•œ í´ë¼ìš°ë“œ ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "## ğŸ¯ **í•µì‹¬ ê°œë…:**\n",
    "- **AWS S3 Data Pipeline** - í´ë¼ìš°ë“œ ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥\n",
    "- **Train/Validation/Test Split** - ëª¨ë¸ í•™ìŠµ/ê²€ì¦/í‰ê°€ìš© ë°ì´í„° ë¶„ë¦¬\n",
    "- **Stratified Sampling** - í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•œ ë¶„í• \n",
    "- **Time Series Cross-Validation** - ì‹œê°„ ìˆœì„œ ê³ ë ¤í•œ ê²€ì¦\n",
    "- **Data Leakage ë°©ì§€** - ë¯¸ë˜ ì •ë³´ê°€ ê³¼ê±°ë¡œ ìœ ì¶œë˜ì§€ ì•Šë„ë¡ ë°©ì§€\n",
    "- **Cloud-to-Cloud Workflow** - ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ ì™„ì „í•œ í´ë¼ìš°ë“œ íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198c4a5",
   "metadata": {},
   "source": [
    "## ğŸ“š **Section 1: Import Required Libraries + AWS SDK Setup**\n",
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ê³¼ AWS SDKë¥¼ importí•˜ê³  í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04010ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” AWS Credentials Setup and Verification\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "print(\"ğŸ” AWS Credentials Detection:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Method 1: Check for IAM Role (EC2/ECS/Lambda environment)\n",
    "def check_iam_role():\n",
    "    \"\"\"Check if we're running with an IAM role (preferred method)\"\"\"\n",
    "    try:\n",
    "        # Try to access instance metadata (works on EC2)\n",
    "        import urllib.request\n",
    "        import json\n",
    "        \n",
    "        # EC2 Instance Metadata Service v2 (IMDSv2)\n",
    "        try:\n",
    "            # Get session token first\n",
    "            token_request = urllib.request.Request(\n",
    "                'http://169.254.169.254/latest/api/token',\n",
    "                headers={'X-aws-ec2-metadata-token-ttl-seconds': '21600'}\n",
    "            )\n",
    "            token_request.get_method = lambda: 'PUT'\n",
    "            token_response = urllib.request.urlopen(token_request, timeout=2)\n",
    "            token = token_response.read().decode('utf-8')\n",
    "            \n",
    "            # Get IAM role info\n",
    "            role_request = urllib.request.Request(\n",
    "                'http://169.254.169.254/latest/meta-data/iam/security-credentials/',\n",
    "                headers={'X-aws-ec2-metadata-token': token}\n",
    "            )\n",
    "            role_response = urllib.request.urlopen(role_request, timeout=2)\n",
    "            role_name = role_response.read().decode('utf-8').strip()\n",
    "            \n",
    "            if role_name:\n",
    "                print(f\"âœ… IAM Role detected: {role_name}\")\n",
    "                \n",
    "                # Get role details\n",
    "                creds_request = urllib.request.Request(\n",
    "                    f'http://169.254.169.254/latest/meta-data/iam/security-credentials/{role_name}',\n",
    "                    headers={'X-aws-ec2-metadata-token': token}\n",
    "                )\n",
    "                creds_response = urllib.request.urlopen(creds_request, timeout=2)\n",
    "                creds_data = json.loads(creds_response.read().decode('utf-8'))\n",
    "                \n",
    "                print(f\"ğŸ”‘ Access Key: {creds_data.get('AccessKeyId', 'N/A')}\")\n",
    "                print(f\"â° Expires: {creds_data.get('Expiration', 'N/A')}\")\n",
    "                return True, role_name\n",
    "            \n",
    "        except Exception:\n",
    "            # Fallback to IMDSv1\n",
    "            role_response = urllib.request.urlopen(\n",
    "                'http://169.254.169.254/latest/meta-data/iam/security-credentials/', \n",
    "                timeout=2\n",
    "            )\n",
    "            role_name = role_response.read().decode('utf-8').strip()\n",
    "            if role_name:\n",
    "                print(f\"âœ… IAM Role detected (IMDSv1): {role_name}\")\n",
    "                return True, role_name\n",
    "                \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Check for other IAM role indicators\n",
    "    if os.getenv('AWS_ROLE_ARN') or os.getenv('AWS_WEB_IDENTITY_TOKEN_FILE'):\n",
    "        print(\"âœ… IAM Role detected (ECS/EKS/Lambda environment)\")\n",
    "        return True, \"Service Role\"\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "# Check IAM Role first\n",
    "iam_role_available, role_name = check_iam_role()\n",
    "\n",
    "# Method 2: Check AWS CLI configuration\n",
    "try:\n",
    "    result = subprocess.run(['aws', 'configure', 'list'], \n",
    "                          capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… AWS CLI configured successfully!\")\n",
    "        print(\"ğŸ“‹ AWS CLI Configuration:\")\n",
    "        \n",
    "        # Parse AWS CLI output to check source\n",
    "        cli_lines = result.stdout.strip().split('\\n')\n",
    "        for line in cli_lines:\n",
    "            if 'access_key' in line and 'iam-role' in line:\n",
    "                print(\"ğŸ¯ AWS CLI using IAM role credentials!\")\n",
    "            elif 'access_key' in line:\n",
    "                print(f\"ğŸ”§ {line}\")\n",
    "        \n",
    "        aws_cli_configured = True\n",
    "    else:\n",
    "        print(\"âš ï¸ AWS CLI not configured properly\")\n",
    "        aws_cli_configured = False\n",
    "except (subprocess.TimeoutExpired, FileNotFoundError):\n",
    "    print(\"âš ï¸ AWS CLI not found or not responding\")\n",
    "    aws_cli_configured = False\n",
    "\n",
    "# Method 3: Check environment variables\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_region = os.getenv('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "\n",
    "print(f\"\\nğŸ”§ Environment Variables:\")\n",
    "if aws_access_key:\n",
    "    print(f\"ğŸ”‘ AWS_ACCESS_KEY_ID: {aws_access_key}\")\n",
    "    print(f\"ğŸ” AWS_SECRET_ACCESS_KEY: {'*' * (len(aws_secret_key) - 4) + aws_secret_key[-4:] if aws_secret_key else 'NOT SET'}\")\n",
    "    print(f\"ğŸŒ AWS_DEFAULT_REGION: {aws_region}\")\n",
    "    env_vars_configured = True\n",
    "else:\n",
    "    print(\"âŒ No AWS environment variables found\")\n",
    "    env_vars_configured = False\n",
    "\n",
    "# Method 4: Try to load from .env file (optional)\n",
    "env_file_configured = False\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    if os.path.exists('.env'):\n",
    "        load_dotenv()\n",
    "        print(f\"\\nğŸ“„ .env file found and loaded\")\n",
    "        # Re-check environment variables after loading .env\n",
    "        aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "        if aws_access_key:\n",
    "            env_file_configured = True\n",
    "            print(f\"ğŸ”‘ Loaded AWS_ACCESS_KEY_ID from .env: {aws_access_key}\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ“„ No .env file found (this is OK if AWS CLI or IAM role is configured)\")\n",
    "except ImportError:\n",
    "    print(f\"\\nğŸ“„ python-dotenv not installed (this is OK if AWS CLI or IAM role is configured)\")\n",
    "\n",
    "# Summary and Test Connection\n",
    "print(f\"\\nğŸ¯ Credentials Summary:\")\n",
    "print(f\"âœ… IAM Role: {iam_role_available} {'(' + role_name + ')' if role_name else ''}\")\n",
    "print(f\"âœ… AWS CLI Configured: {aws_cli_configured}\")\n",
    "print(f\"âœ… Environment Variables: {env_vars_configured}\")\n",
    "print(f\"âœ… .env File: {env_file_configured}\")\n",
    "\n",
    "credentials_available = iam_role_available or aws_cli_configured or env_vars_configured or env_file_configured\n",
    "\n",
    "if credentials_available:\n",
    "    print(f\"\\nğŸš€ Testing S3 Connection...\")\n",
    "    \n",
    "    # Test S3 access\n",
    "    try:\n",
    "        import boto3\n",
    "        from botocore.exceptions import NoCredentialsError, ClientError\n",
    "        \n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # Test basic S3 access\n",
    "        response = s3_client.list_buckets()\n",
    "        print(\"âœ… S3 connection successful!\")\n",
    "        \n",
    "        # Check if elbee-ai bucket is accessible\n",
    "        try:\n",
    "            s3_client.head_bucket(Bucket='elbee-ai')\n",
    "            print(\"âœ… elbee-ai bucket accessible!\")\n",
    "            \n",
    "            # Test your IAM role permissions\n",
    "            if iam_role_available:\n",
    "                print(f\"\\nğŸ¯ Testing IAM Role Permissions ({role_name}):\")\n",
    "                \n",
    "                # Test ListBucket permission\n",
    "                try:\n",
    "                    response = s3_client.list_objects_v2(\n",
    "                        Bucket='elbee-ai', \n",
    "                        Prefix='project-data/',\n",
    "                        MaxKeys=5\n",
    "                    )\n",
    "                    print(\"âœ… s3:ListBucket permission working\")\n",
    "                    \n",
    "                    if 'Contents' in response:\n",
    "                        print(f\"ğŸ“ Files in elbee-ai/project-data/:\")\n",
    "                        for obj in response['Contents']:\n",
    "                            file_size_mb = obj['Size'] / (1024 * 1024)\n",
    "                            print(f\"  ğŸ“„ {obj['Key']} ({file_size_mb:.2f} MB)\")\n",
    "                            \n",
    "                        # Test GetObject permission on first file\n",
    "                        first_file = response['Contents'][0]['Key']\n",
    "                        try:\n",
    "                            s3_client.head_object(Bucket='elbee-ai', Key=first_file)\n",
    "                            print(\"âœ… s3:GetObject permission working\")\n",
    "                        except ClientError as e:\n",
    "                            print(f\"âŒ s3:GetObject permission issue: {e}\")\n",
    "                    else:\n",
    "                        print(f\"ğŸ“ project-data/ folder is empty or doesn't exist\")\n",
    "                        \n",
    "                except ClientError as e:\n",
    "                    error_code = e.response['Error']['Code']\n",
    "                    if error_code == 'AccessDenied':\n",
    "                        print(\"âŒ s3:ListBucket permission denied - check IAM policy\")\n",
    "                    else:\n",
    "                        print(f\"âŒ ListBucket error: {error_code}\")\n",
    "            else:\n",
    "                # List files for non-IAM role authentication\n",
    "                try:\n",
    "                    response = s3_client.list_objects_v2(\n",
    "                        Bucket='elbee-ai', \n",
    "                        Prefix='project-data/',\n",
    "                        MaxKeys=5\n",
    "                    )\n",
    "                    if 'Contents' in response:\n",
    "                        print(f\"ğŸ“ Files in elbee-ai/project-data/:\")\n",
    "                        for obj in response['Contents']:\n",
    "                            file_size_mb = obj['Size'] / (1024 * 1024)\n",
    "                            print(f\"  ğŸ“„ {obj['Key']} ({file_size_mb:.2f} MB)\")\n",
    "                    else:\n",
    "                        print(f\"ğŸ“ project-data/ folder is empty or doesn't exist\")\n",
    "                except ClientError as e:\n",
    "                    print(f\"âš ï¸ Could not list files in project-data/: {e}\")\n",
    "                \n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == '403':\n",
    "                print(\"âŒ Access denied to elbee-ai bucket - check permissions\")\n",
    "            elif error_code == '404':\n",
    "                print(\"âŒ elbee-ai bucket not found\")\n",
    "            else:\n",
    "                print(f\"âŒ Error accessing elbee-ai bucket: {error_code}\")\n",
    "        \n",
    "    except NoCredentialsError:\n",
    "        print(\"âŒ AWS credentials not properly configured\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error testing S3 connection: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\nâŒ No AWS credentials found!\")\n",
    "    print(f\"ğŸ’¡ Options:\")\n",
    "    print(f\"   1. Use IAM role (recommended for EC2/ECS/Lambda)\")\n",
    "    print(f\"   2. Configure AWS CLI: aws configure\")\n",
    "    print(f\"   3. Set environment variables\")\n",
    "    print(f\"   4. Create .env file\")\n",
    "\n",
    "print(f\"\\nğŸ“ Working Directory: {os.getcwd()}\")\n",
    "\n",
    "if iam_role_available:\n",
    "    print(f\"ğŸ¯ Using IAM Role authentication - Most secure! ğŸ”’\")\n",
    "else:\n",
    "    print(f\"ğŸ¯ Using traditional credential authentication\")\n",
    "    \n",
    "print(f\"ğŸ¯ Ready to proceed with S3 data loading!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b57465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Quick AWS Setup Verification\n",
      "========================================\n",
      "âœ… All required libraries installed\n",
      "âœ… AWS Identity: arn:aws:iam::819556863188:root\n",
      "âœ… S3 Access: Found 1 buckets\n",
      "âœ… elbee-ai bucket accessible\n",
      "\n",
      "ğŸ‰ READY TO GO!\n",
      "âœ… All systems operational\n",
      "âœ… You can now run the rest of the notebook\n",
      "\n",
      "ğŸ“ Current directory: Unknown\n",
      "ğŸ¯ Notebook ready for temperature/humidity analysis!\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Quick AWS Setup Test\n",
    "# Run this cell first to verify everything is working\n",
    "\n",
    "print(\"ğŸ” Quick AWS Setup Verification\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"âœ… All required libraries installed\")\n",
    "    \n",
    "    # Test AWS credentials\n",
    "    try:\n",
    "        s3 = boto3.client('s3')\n",
    "        sts = boto3.client('sts')\n",
    "        \n",
    "        # Get identity\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"âœ… AWS Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "        \n",
    "        # Test S3 access\n",
    "        buckets = s3.list_buckets()\n",
    "        print(f\"âœ… S3 Access: Found {len(buckets['Buckets'])} buckets\")\n",
    "        \n",
    "        # Test target bucket\n",
    "        s3.head_bucket(Bucket='elbee-ai')\n",
    "        print(\"âœ… elbee-ai bucket accessible\")\n",
    "        \n",
    "        print(\"\\nğŸ‰ READY TO GO!\")\n",
    "        print(\"âœ… All systems operational\")\n",
    "        print(\"âœ… You can now run the rest of the notebook\")\n",
    "        \n",
    "    except Exception as aws_error:\n",
    "        print(f\"âŒ AWS Error: {aws_error}\")\n",
    "        print(\"\\nğŸ’¡ To fix AWS issues:\")\n",
    "        print(\"1. Export credentials: export AWS_ACCESS_KEY_ID='your_key'\")\n",
    "        print(\"2. Export secret: export AWS_SECRET_ACCESS_KEY='your_secret'\")\n",
    "        print(\"3. Export region: export AWS_DEFAULT_REGION='us-east-1'\")\n",
    "        print(\"4. Re-run this cell\")\n",
    "        \n",
    "except ImportError as import_error:\n",
    "    print(f\"âŒ Import Error: {import_error}\")\n",
    "    print(\"ğŸ’¡ Install missing packages: pip install boto3 pandas numpy matplotlib\")\n",
    "\n",
    "print(f\"\\nğŸ“ Current directory: {os.getcwd() if 'os' in locals() else 'Unknown'}\")\n",
    "print(f\"ğŸ¯ Notebook ready for temperature/humidity analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11dc519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Installing required packages for AWS S3 integration...\n",
      "==================================================\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.40.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.64 (from boto3)\n",
      "  Using cached botocore-1.40.64-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3)\n",
      "  Using cached s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from botocore<1.41.0,>=1.40.64->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from botocore<1.41.0,>=1.40.64->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.64->boto3) (1.17.0)\n",
      "Using cached boto3-1.40.64-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.40.64-py3-none-any.whl (14.1 MB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [boto3]32m1/4\u001b[0m [botocore]\n",
      "\u001b[1A\u001b[2KSuccessfully installed boto3-1.40.64 botocore-1.40.64 jmespath-1.0.1 s3transfer-0.14.0\n",
      "âœ… boto3 installed successfully\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n",
      "âœ… python-dotenv installed successfully\n",
      "Requirement already satisfied: pandas in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "âœ… pandas installed successfully\n",
      "Requirement already satisfied: numpy in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (2.3.4)\n",
      "âœ… numpy installed successfully\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "âœ… matplotlib installed successfully\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "âœ… seaborn installed successfully\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/aiegoo/miniconda3/envs/ai-track-nlp-advanced/lib/python3.11/site-packages (from scikit-learn) (2.3.4)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n",
      "âœ… scikit-learn installed successfully\n",
      "\n",
      "ğŸ“Š Installation Summary:\n",
      "âœ… Successfully installed: 7/7 packages\n",
      "ğŸ‰ All packages installed! You can proceed to the next cell.\n",
      "\n",
      "ğŸ”„ Please restart the notebook kernel after installation if needed.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Install Required Packages\n",
    "# Run this cell first to install necessary packages\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} installed successfully\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"ğŸ“¦ Installing required packages for AWS S3 integration...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"boto3\",\n",
    "    \"python-dotenv\",\n",
    "    \"pandas\",\n",
    "    \"numpy\", \n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "installed_count = 0\n",
    "for package in required_packages:\n",
    "    if install_package(package):\n",
    "        installed_count += 1\n",
    "\n",
    "print(f\"\\nğŸ“Š Installation Summary:\")\n",
    "print(f\"âœ… Successfully installed: {installed_count}/{len(required_packages)} packages\")\n",
    "\n",
    "if installed_count == len(required_packages):\n",
    "    print(\"ğŸ‰ All packages installed! You can proceed to the next cell.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Some packages failed to install. You may need to install them manually.\")\n",
    "    print(\"ğŸ’¡ Try running: pip install boto3 python-dotenv\")\n",
    "\n",
    "print(\"\\nğŸ”„ Please restart the notebook kernel after installation if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Advanced AWS Environment Diagnostic\n",
    "# Run this cell to diagnose AWS configuration issues\n",
    "\n",
    "print(\"ğŸ” Advanced AWS Environment Diagnostic\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "# 1. Check Python environment\n",
    "print(\"ğŸ Python Environment:\")\n",
    "print(f\"   Python version: {sys.version}\")\n",
    "print(f\"   Python executable: {sys.executable}\")\n",
    "print(f\"   Current working directory: {os.getcwd()}\")\n",
    "print()\n",
    "\n",
    "# 2. Check if running on Windows host vs WSL/container - Fixed for Windows compatibility\n",
    "print(\"ğŸ’» System Environment:\")\n",
    "print(f\"   Platform: {sys.platform}\")\n",
    "print(f\"   OS name: {os.name}\")\n",
    "system_platform = platform.system()\n",
    "print(f\"   System: {system_platform}\")\n",
    "\n",
    "if os.name == 'nt' or system_platform == 'Windows':\n",
    "    print(\"   ğŸªŸ Running on Windows\")\n",
    "    \n",
    "    # Check if in WSL by looking for WSL-specific environment variables\n",
    "    is_wsl = 'WSL_DISTRO_NAME' in os.environ or 'WSL_INTEROP' in os.environ\n",
    "    if is_wsl:\n",
    "        print(\"   ğŸ§ WSL detected within Windows\")\n",
    "else:\n",
    "    print(\"   ğŸ§ Running on Unix-like system\")\n",
    "    \n",
    "    # Safe WSL detection for Linux systems\n",
    "    try:\n",
    "        platform_info = subprocess.run(['uname', '-a'], capture_output=True, text=True, timeout=5)\n",
    "        if platform_info.returncode == 0 and 'microsoft' in platform_info.stdout.lower():\n",
    "            print(\"   ğŸ§ WSL (Windows Subsystem for Linux) detected\")\n",
    "    except Exception:\n",
    "        pass  # Ignore if uname fails\n",
    "print()\n",
    "\n",
    "# 3. Check AWS CLI configuration\n",
    "print(\"âš™ï¸ AWS CLI Configuration:\")\n",
    "try:\n",
    "    # Check if AWS CLI is available - using 'where' on Windows, 'which' on Unix\n",
    "    if system_platform == 'Windows':\n",
    "        aws_check_cmd = ['where', 'aws']\n",
    "    else:\n",
    "        aws_check_cmd = ['which', 'aws']\n",
    "    \n",
    "    aws_location = subprocess.run(aws_check_cmd, capture_output=True, text=True, timeout=10)\n",
    "    \n",
    "    if aws_location.returncode == 0:\n",
    "        print(f\"   âœ… AWS CLI found at: {aws_location.stdout.strip()}\")\n",
    "        \n",
    "        # Check AWS version\n",
    "        aws_version = subprocess.run(['aws', '--version'], capture_output=True, text=True, timeout=10)\n",
    "        if aws_version.returncode == 0:\n",
    "            print(f\"   âœ… AWS CLI version: {aws_version.stdout.strip()}\")\n",
    "        \n",
    "        # Check AWS configuration\n",
    "        aws_config = subprocess.run(['aws', 'configure', 'list'], capture_output=True, text=True, timeout=10)\n",
    "        if aws_config.returncode == 0:\n",
    "            print(\"   âœ… AWS CLI configuration:\")\n",
    "            for line in aws_config.stdout.split('\\n'):\n",
    "                if line.strip():\n",
    "                    print(f\"      {line}\")\n",
    "        else:\n",
    "            print(\"   âŒ AWS CLI not configured\")\n",
    "            print(f\"   Error output: {aws_config.stderr}\")\n",
    "    else:\n",
    "        print(\"   âŒ AWS CLI not found in PATH\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"   âŒ AWS CLI command not found\")\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"   âŒ AWS CLI command timed out\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Error checking AWS CLI: {e}\")\n",
    "print()\n",
    "\n",
    "# 4. Check environment variables\n",
    "print(\"ğŸŒ Environment Variables:\")\n",
    "aws_env_vars = ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'AWS_DEFAULT_REGION', 'AWS_REGION', 'AWS_PROFILE']\n",
    "for var in aws_env_vars:\n",
    "    value = os.environ.get(var)\n",
    "    if value:\n",
    "        if 'SECRET' in var:\n",
    "            print(f\"   âœ… {var}: ***[HIDDEN]***\")\n",
    "        else:\n",
    "            print(f\"   âœ… {var}: {value}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {var}: Not set\")\n",
    "print()\n",
    "\n",
    "# 5. Check boto3 configuration\n",
    "print(\"ğŸ”„ Boto3 Configuration:\")\n",
    "try:\n",
    "    import boto3\n",
    "    print(\"   âœ… boto3 imported successfully\")\n",
    "    \n",
    "    # Check current session\n",
    "    session = boto3.Session()\n",
    "    credentials = session.get_credentials()\n",
    "    \n",
    "    if credentials:\n",
    "        print(\"   âœ… Credentials found\")\n",
    "        print(f\"      Access Key: {credentials.access_key[:8]}***[HIDDEN]***\")\n",
    "        if hasattr(credentials, 'method'):\n",
    "            print(f\"      Method: {credentials.method}\")\n",
    "    else:\n",
    "        print(\"   âŒ No credentials found\")\n",
    "    \n",
    "    # Check region\n",
    "    region = session.region_name\n",
    "    if region:\n",
    "        print(f\"   âœ… Region: {region}\")\n",
    "    else:\n",
    "        print(\"   âŒ No region configured\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"   âŒ boto3 not installed\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ boto3 error: {e}\")\n",
    "print()\n",
    "\n",
    "# 6. Test AWS connectivity\n",
    "print(\"ğŸŒ AWS Connectivity Test:\")\n",
    "try:\n",
    "    import boto3\n",
    "    \n",
    "    # Test STS (most basic AWS service)\n",
    "    print(\"   Testing STS (Identity service)...\")\n",
    "    sts = boto3.client('sts')\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(f\"   âœ… Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "    print(f\"   âœ… Account: {identity.get('Account', 'Unknown')}\")\n",
    "    print(f\"   âœ… User ID: {identity.get('UserId', 'Unknown')}\")\n",
    "    \n",
    "    # Test S3 access\n",
    "    print(\"   Testing S3 access...\")\n",
    "    s3 = boto3.client('s3')\n",
    "    buckets = s3.list_buckets()\n",
    "    print(f\"   âœ… S3 Access: Found {len(buckets['Buckets'])} buckets\")\n",
    "    \n",
    "    # Test specific bucket\n",
    "    print(\"   Testing elbee-ai bucket...\")\n",
    "    try:\n",
    "        s3.head_bucket(Bucket='elbee-ai')\n",
    "        print(\"   âœ… elbee-ai bucket accessible\")\n",
    "    except Exception as bucket_error:\n",
    "        print(f\"   âŒ elbee-ai bucket error: {bucket_error}\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ AWS CONNECTION SUCCESSFUL!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ AWS connection failed: {e}\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    \n",
    "    print(\"\\nğŸ”§ Troubleshooting Steps:\")\n",
    "    if system_platform == 'Windows':\n",
    "        print(\"1. Since you're on Windows:\")\n",
    "        print(\"   - Open Command Prompt or PowerShell as Administrator\")\n",
    "        print(\"   - Run: aws configure\")\n",
    "        print(\"   - Enter your AWS Access Key ID and Secret\")\n",
    "        print(\"   - Set region to: us-east-1\")\n",
    "        print()\n",
    "        print(\"2. Alternative for Jupyter:\")\n",
    "        print(\"   - Set environment variables in a cell:\")\n",
    "        print(\"   import os\")\n",
    "        print(\"   os.environ['AWS_ACCESS_KEY_ID'] = 'your_key_here'\")\n",
    "        print(\"   os.environ['AWS_SECRET_ACCESS_KEY'] = 'your_secret_here'\")\n",
    "        print(\"   os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\")\n",
    "    else:\n",
    "        print(\"1. If on Unix/Linux system:\")\n",
    "        print(\"   - Open terminal\")\n",
    "        print(\"   - Run: aws configure\")\n",
    "        print(\"   - Enter your AWS Access Key ID and Secret\")\n",
    "        print(\"   - Set region to: us-east-1\")\n",
    "    print()\n",
    "    print(\"3. If credentials are set but still failing:\")\n",
    "    print(\"   - Restart Jupyter server\")\n",
    "    print(\"   - Restart kernel: Kernel > Restart Kernel\")\n",
    "    print(\"   - Check if credentials are correctly typed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ¯ Diagnostic Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f19714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ AWS Credentials Quick Fix\n",
    "# Run this cell if the diagnostic shows missing credentials\n",
    "\n",
    "print(\"ğŸ› ï¸ AWS Credentials Quick Fix\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "import os\n",
    "\n",
    "# Option 1: Set credentials directly (temporary fix)\n",
    "print(\"Option 1: Set credentials directly in this session\")\n",
    "print(\"âš ï¸ WARNING: Only use this for testing, not for production!\")\n",
    "print()\n",
    "\n",
    "# Get credentials from user input or environment\n",
    "access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "if not access_key:\n",
    "    print(\"ğŸ’¡ AWS Access Key ID not found in environment\")\n",
    "    print(\"   Please set it using one of these methods:\")\n",
    "    print(\"   1. aws configure\")\n",
    "    print(\"   2. export AWS_ACCESS_KEY_ID='your-access-key'\")\n",
    "    print(\"   3. Uncomment and edit the lines below:\")\n",
    "    print()\n",
    "    print(\"# Uncomment and fill in your credentials if needed:\")\n",
    "    print(\"# os.environ['AWS_ACCESS_KEY_ID'] = 'your-access-key-here'\")\n",
    "    print(\"# os.environ['AWS_SECRET_ACCESS_KEY'] = 'your-secret-key-here'\")\n",
    "    print(\"# os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\")\n",
    "\n",
    "# Check if credentials are now set\n",
    "aws_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "if aws_key:\n",
    "    print(f\"âœ… AWS_ACCESS_KEY_ID: {aws_key[:8]}***[HIDDEN]***\")\n",
    "else:\n",
    "    print(\"âŒ AWS_ACCESS_KEY_ID: Not set\")\n",
    "\n",
    "aws_secret = os.environ.get('AWS_SECRET_ACCESS_KEY') \n",
    "if aws_secret:\n",
    "    print(\"âœ… AWS_SECRET_ACCESS_KEY: ***[HIDDEN]***\")\n",
    "else:\n",
    "    print(\"âŒ AWS_SECRET_ACCESS_KEY: Not set\")\n",
    "\n",
    "aws_region = os.environ.get('AWS_DEFAULT_REGION')\n",
    "if aws_region:\n",
    "    print(f\"âœ… AWS_DEFAULT_REGION: {aws_region}\")\n",
    "else:\n",
    "    print(\"âŒ AWS_DEFAULT_REGION: Not set\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ Recommended setup methods:\")\n",
    "print(\"1. AWS CLI configuration:\")\n",
    "print(\"   - Open Command Prompt or Terminal\")\n",
    "print(\"   - Run: aws configure\")\n",
    "print(\"   - Enter your credentials when prompted\")\n",
    "print(\"2. Environment variables (temporary):\")\n",
    "print(\"   - Windows: Use setup_aws_credentials.ps1\")\n",
    "print(\"   - Linux/WSL: Use source export_aws_credentials.sh\")\n",
    "print(\"3. Restart Jupyter server after AWS CLI configuration\")\n",
    "\n",
    "# Test if credentials work now\n",
    "if aws_key and aws_secret:\n",
    "    print(\"\\nğŸ§ª Testing credentials...\")\n",
    "    try:\n",
    "        import boto3\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"âœ… SUCCESS! Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Still having issues: {e}\")\n",
    "else:\n",
    "    print(\"\\nâ­ï¸ Set credentials above and re-run this cell to test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Generate AWS Export Scripts for Different Environments\n",
    "# This cell creates export scripts for various shell environments\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸš€ AWS Credentials Export Script Generator\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get AWS credentials from environment or AWS CLI\n",
    "AWS_ACCESS_KEY_ID = os.environ.get('AWS_ACCESS_KEY_ID', '')\n",
    "AWS_SECRET_ACCESS_KEY = os.environ.get('AWS_SECRET_ACCESS_KEY', '')\n",
    "AWS_DEFAULT_REGION = os.environ.get('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "\n",
    "# Try to get credentials from AWS CLI if not in environment\n",
    "if not AWS_ACCESS_KEY_ID:\n",
    "    try:\n",
    "        import boto3\n",
    "        session = boto3.Session()\n",
    "        credentials = session.get_credentials()\n",
    "        if credentials:\n",
    "            AWS_ACCESS_KEY_ID = credentials.access_key\n",
    "            AWS_SECRET_ACCESS_KEY = credentials.secret_key\n",
    "            print(\"ğŸ“‹ Retrieved credentials from AWS CLI configuration\")\n",
    "        else:\n",
    "            print(\"âš ï¸ No credentials found in AWS CLI configuration\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not retrieve AWS CLI credentials: {e}\")\n",
    "\n",
    "# Check current environment - Fixed for Windows compatibility\n",
    "current_os = os.name\n",
    "system_platform = platform.system()\n",
    "is_wsl = False\n",
    "\n",
    "# Safe way to check for WSL without using uname on Windows\n",
    "try:\n",
    "    if system_platform == \"Linux\":\n",
    "        # Only run uname on Linux systems\n",
    "        platform_info = subprocess.run(['uname', '-a'], capture_output=True, text=True, errors='ignore')\n",
    "        is_wsl = 'microsoft' in platform_info.stdout.lower() if platform_info.returncode == 0 else False\n",
    "    elif system_platform == \"Windows\":\n",
    "        # Check for WSL environment variables on Windows\n",
    "        is_wsl = 'WSL_DISTRO_NAME' in os.environ or 'WSL_INTEROP' in os.environ\n",
    "except Exception:\n",
    "    # If any command fails, assume native environment\n",
    "    pass\n",
    "\n",
    "print(f\"ğŸ’» Environment Detection:\")\n",
    "print(f\"   OS Type: {current_os}\")\n",
    "print(f\"   Platform: {system_platform}\")\n",
    "print(f\"   WSL Status: {'WSL' if is_wsl else 'Native'}\")\n",
    "\n",
    "# Get secret key if not set\n",
    "if not AWS_SECRET_ACCESS_KEY:\n",
    "    print(\"\\nğŸ” AWS Secret Key Required:\")\n",
    "    print(\"âš ï¸  No AWS credentials found in environment or AWS CLI\")\n",
    "    print(\"ğŸ’¡ Please set up credentials using one of these methods:\")\n",
    "    print(\"   1. Run: aws configure\")\n",
    "    print(\"   2. Use the credential setup scripts\")\n",
    "    print(\"   3. Set environment variables manually\")\n",
    "    \n",
    "    # Use placeholder for template generation\n",
    "    AWS_ACCESS_KEY_ID = AWS_ACCESS_KEY_ID or \"YOUR_ACCESS_KEY_HERE\"\n",
    "    AWS_SECRET_ACCESS_KEY = \"YOUR_SECRET_KEY_HERE\"\n",
    "\n",
    "print(f\"\\nğŸ“‹ Current AWS Configuration:\")\n",
    "if AWS_ACCESS_KEY_ID and AWS_ACCESS_KEY_ID != \"YOUR_ACCESS_KEY_HERE\":\n",
    "    print(f\"âœ… AWS_ACCESS_KEY_ID: {AWS_ACCESS_KEY_ID[:8]}***\")\n",
    "else:\n",
    "    print(f\"âŒ AWS_ACCESS_KEY_ID: Not configured\")\n",
    "\n",
    "if AWS_SECRET_ACCESS_KEY and AWS_SECRET_ACCESS_KEY != \"YOUR_SECRET_KEY_HERE\":\n",
    "    print(f\"âœ… AWS_SECRET_ACCESS_KEY: ***[CONFIGURED]***\")\n",
    "else:\n",
    "    print(f\"âŒ AWS_SECRET_ACCESS_KEY: Not configured\")\n",
    "\n",
    "print(f\"âœ… AWS_DEFAULT_REGION: {AWS_DEFAULT_REGION}\")\n",
    "\n",
    "# Generate export commands for different environments\n",
    "print(f\"\\nğŸ“‹ Export Commands for Different Environments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nğŸªŸ Windows Command Prompt:\")\n",
    "print(f\"set AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\")\n",
    "print(f\"set AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\")\n",
    "print(f\"set AWS_DEFAULT_REGION={AWS_DEFAULT_REGION}\")\n",
    "\n",
    "print(f\"\\nğŸ’™ PowerShell:\")\n",
    "print(f\"$env:AWS_ACCESS_KEY_ID = '{AWS_ACCESS_KEY_ID}'\")\n",
    "print(f\"$env:AWS_SECRET_ACCESS_KEY = '{AWS_SECRET_ACCESS_KEY}'\")\n",
    "print(f\"$env:AWS_DEFAULT_REGION = '{AWS_DEFAULT_REGION}'\")\n",
    "\n",
    "print(f\"\\nğŸ§ Bash/WSL/Linux:\")\n",
    "print(f\"export AWS_ACCESS_KEY_ID='{AWS_ACCESS_KEY_ID}'\")\n",
    "print(f\"export AWS_SECRET_ACCESS_KEY='{AWS_SECRET_ACCESS_KEY}'\")\n",
    "print(f\"export AWS_DEFAULT_REGION='{AWS_DEFAULT_REGION}'\")\n",
    "\n",
    "print(f\"\\nğŸ Python/Jupyter (this session):\")\n",
    "print(f\"os.environ['AWS_ACCESS_KEY_ID'] = '{AWS_ACCESS_KEY_ID}'\")\n",
    "print(f\"os.environ['AWS_SECRET_ACCESS_KEY'] = '{AWS_SECRET_ACCESS_KEY}'\")\n",
    "print(f\"os.environ['AWS_DEFAULT_REGION'] = '{AWS_DEFAULT_REGION}'\")\n",
    "\n",
    "# Set for current Python session if credentials are valid\n",
    "if (AWS_ACCESS_KEY_ID and AWS_ACCESS_KEY_ID != \"YOUR_ACCESS_KEY_HERE\" and \n",
    "    AWS_SECRET_ACCESS_KEY and AWS_SECRET_ACCESS_KEY != \"YOUR_SECRET_KEY_HERE\"):\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = AWS_ACCESS_KEY_ID\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_ACCESS_KEY\n",
    "    os.environ['AWS_DEFAULT_REGION'] = AWS_DEFAULT_REGION\n",
    "    print(f\"\\nâœ… Environment variables set for current Python session!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Skipping Python session setup - credentials not configured\")\n",
    "    print(f\"ğŸ’¡ Please run 'aws configure' or set credentials manually\")\n",
    "\n",
    "# Check available export scripts\n",
    "script_files = [\n",
    "    'export_aws_credentials.ps1',\n",
    "    'export_aws_credentials.bat', \n",
    "    'export_aws_credentials.sh'\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“‚ Available Export Scripts:\")\n",
    "for script in script_files:\n",
    "    script_path = Path(script)\n",
    "    if script_path.exists():\n",
    "        print(f\"âœ… {script} - Ready to use\")\n",
    "    else:\n",
    "        print(f\"âŒ {script} - Not found\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ How to Use the Export Scripts:\")\n",
    "if system_platform == \"Windows\":\n",
    "    print(\"ğŸªŸ Since you're on Windows:\")\n",
    "    print(\"1. Command Prompt: Run export_aws_credentials.bat\")\n",
    "    print(\"2. PowerShell: Run ./export_aws_credentials.ps1\")\n",
    "    print(\"3. For WSL: Run source export_aws_credentials.sh (inside WSL)\")\n",
    "    print(\"4. Jupyter (current): Run the Python commands above\")\n",
    "else:\n",
    "    print(\"1. ğŸªŸ Windows Command Prompt: Run export_aws_credentials.bat\")\n",
    "    print(\"2. ğŸ’™ PowerShell: Run ./export_aws_credentials.ps1\")\n",
    "    print(\"3. ğŸ§ Bash/WSL: Run source export_aws_credentials.sh\")\n",
    "    print(\"4. ğŸ Jupyter: Run the Python commands above in a cell\")\n",
    "\n",
    "# Test current environment\n",
    "print(f\"\\nğŸ§ª Testing Current Environment:\")\n",
    "current_access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "current_secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "current_region = os.environ.get('AWS_DEFAULT_REGION')\n",
    "\n",
    "if current_access_key:\n",
    "    print(f\"âœ… AWS_ACCESS_KEY_ID: {current_access_key[:8]}***\")\n",
    "else:\n",
    "    print(f\"âŒ AWS_ACCESS_KEY_ID: Not set\")\n",
    "\n",
    "if current_secret_key:\n",
    "    print(f\"âœ… AWS_SECRET_ACCESS_KEY: ***[HIDDEN]***\")\n",
    "else:\n",
    "    print(f\"âŒ AWS_SECRET_ACCESS_KEY: Not set\")\n",
    "\n",
    "if current_region:\n",
    "    print(f\"âœ… AWS_DEFAULT_REGION: {current_region}\")\n",
    "else:\n",
    "    print(f\"âŒ AWS_DEFAULT_REGION: Not set\")\n",
    "\n",
    "if current_access_key and current_secret_key:\n",
    "    print(f\"\\nğŸ‰ AWS credentials are configured for this session!\")\n",
    "    try:\n",
    "        import boto3\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"âœ… AWS Identity verified: {identity.get('Arn', 'Unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ AWS test failed: {e}\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ AWS credentials need to be set up\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Next Steps:\")\n",
    "print(\"1. Configure AWS credentials using 'aws configure'\")\n",
    "print(\"2. Re-run this cell to generate proper export commands\")\n",
    "print(\"3. Use one of the export scripts for persistent setup\")\n",
    "print(\"4. Run the diagnostic cell to verify setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¤ S3 Data Preparation (Optional)\n",
    "# This cell creates and uploads sample data if it doesn't exist in S3\n",
    "\n",
    "def create_and_upload_sample_data():\n",
    "    \"\"\"Create sample temperature/humidity data and upload to S3 if original file doesn't exist\"\"\"\n",
    "    \n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime, timedelta\n",
    "    from io import StringIO\n",
    "    \n",
    "    print(\"ğŸ“¤ Preparing sample data for S3...\")\n",
    "    \n",
    "    # Create realistic temperature/humidity data\n",
    "    np.random.seed(42)\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    end_date = datetime(2024, 12, 31)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "    \n",
    "    n_samples = len(date_range)\n",
    "    day_of_year = date_range.dayofyear\n",
    "    hour_of_day = date_range.hour\n",
    "    \n",
    "    # Temperature with seasonal and daily patterns\n",
    "    base_temp = 15 + 10 * np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "    daily_temp = 5 * np.sin(2 * np.pi * hour_of_day / 24)\n",
    "    noise_temp = np.random.normal(0, 2, n_samples)\n",
    "    temperature = base_temp + daily_temp + noise_temp\n",
    "    \n",
    "    # Humidity with inverse temperature relationship\n",
    "    base_humidity = 60 + 20 * np.sin(2 * np.pi * (day_of_year + 90) / 365.25)\n",
    "    temp_humidity = -0.5 * (temperature - 20)\n",
    "    noise_humidity = np.random.normal(0, 5, n_samples)\n",
    "    humidity = np.clip(base_humidity + temp_humidity + noise_humidity, 10, 95)\n",
    "    \n",
    "    # Absolute humidity calculation\n",
    "    absolute_humidity = (humidity / 100) * 6.112 * np.exp(17.67 * temperature / (243.5 + temperature))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': date_range,\n",
    "        'temperature': np.round(temperature, 1),\n",
    "        'humidity': np.round(humidity, 1),\n",
    "        'absolute_humidity': np.round(absolute_humidity, 2),\n",
    "        'location': np.random.choice(['ì‹¤ë‚´', 'ì‹¤ì™¸'], n_samples, p=[0.6, 0.4])\n",
    "    })\n",
    "    \n",
    "    # Convert to CSV string\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False, encoding='utf-8')\n",
    "    csv_content = csv_buffer.getvalue()\n",
    "    \n",
    "    # Upload to S3\n",
    "    try:\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_client.put_object(\n",
    "            Bucket='elbee-ai',\n",
    "            Key='project-data/ì˜¨ìŠµë„_ê´€ì¸¡_ë°ì´í„°.csv',\n",
    "            Body=csv_content.encode('utf-8'),\n",
    "            ContentType='text/csv'\n",
    "        )\n",
    "        print(f\"âœ… Sample data uploaded to s3://elbee-ai/project-data/ì˜¨ìŠµë„_ê´€ì¸¡_ë°ì´í„°.csv\")\n",
    "        print(f\"ğŸ“Š Data shape: {df.shape}\")\n",
    "        print(f\"ğŸ“… Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to upload sample data: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check if data exists, if not create and upload sample data\n",
    "try:\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.head_object(Bucket='elbee-ai', Key='project-data/ì˜¨ìŠµë„_ê´€ì¸¡_ë°ì´í„°.csv')\n",
    "    print(\"âœ… Data file already exists in S3!\")\n",
    "    \n",
    "except s3_client.exceptions.NoSuchKey:\n",
    "    print(\"âš ï¸ Data file not found in S3. Creating sample data...\")\n",
    "    success = create_and_upload_sample_data()\n",
    "    if success:\n",
    "        print(\"ğŸ¯ Ready to proceed with data analysis!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Will proceed with local simulation data\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not check S3 file: {e}\")\n",
    "    print(\"ğŸ’¡ Will attempt to create sample data...\")\n",
    "    create_and_upload_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec121e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# â˜ï¸ AWS ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError, NoCredentialsError\n",
    "import io\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Scikit-Learn ë°ì´í„° ë¶„í•  ê´€ë ¨ ëª¨ë“ˆë“¤\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,      # ê¸°ë³¸ train/test ë¶„í• \n",
    "    StratifiedShuffleSplit, # ê³„ì¸µí™” ë¶„í• \n",
    "    TimeSeriesSplit,       # ì‹œê³„ì—´ ë¶„í• \n",
    "    cross_val_score,       # êµì°¨ê²€ì¦\n",
    "    validation_curve       # ê²€ì¦ ê³¡ì„ \n",
    ")\n",
    "\n",
    "# ëª¨ë¸ë§ ê´€ë ¨\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# ğŸ”¤ í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlib) - ê°œì„ ëœ ë²„ì „\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "\n",
    "def setup_korean_fonts():\n",
    "    \"\"\"í•œê¸€ í°íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì„¤ì •í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”¤ í•œê¸€ í°íŠ¸ ì„¤ì • ì¤‘...\")\n",
    "    \n",
    "        \"    # ìš´ì˜ì²´ì œë³„ í•œê¸€ í°íŠ¸ ë¦¬ìŠ¤íŠ¸ (ìš°ì„ ìˆœìœ„ ìˆœ)\\\\n\",\n",
    "    \"    if platform.system() == 'Windows':\\\\n\",\n",
    "    \"        korean_fonts = ['Gulim', 'Malgun Gothic', 'Microsoft YaHei', 'SimHei']\\\\n\",\n",
    "    \"    elif platform.system() == 'Darwin':  # macOS\\\\n\",\n",
    "    \"        korean_fonts = ['Gulim', 'Apple SD Gothic Neo', 'AppleGothic']\\\\n\",\n",
    "    \"    else:  # Linux\\\\n\",\n",
    "    \"        korean_fonts = ['Gulim', 'Noto Sans CJK KR', 'Nanum Gothic', 'DejaVu Sans']\"\n",
    "    \n",
    "    # ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ê²€ìƒ‰\n",
    "    available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "    print(f\"ğŸ“ ì‹œìŠ¤í…œ í°íŠ¸ ìˆ˜: {len(available_fonts)}ê°œ\")\n",
    "    \n",
    "    selected_font = None\n",
    "    for font in korean_fonts:\n",
    "        if font in available_fonts:\n",
    "            selected_font = font\n",
    "            print(f\"âœ… ì„ íƒëœ í•œê¸€ í°íŠ¸: {selected_font}\")\n",
    "            break\n",
    "    \n",
    "    if selected_font:\n",
    "        plt.rcParams['font.family'] = selected_font\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        \n",
    "        # ê°„ë‹¨í•œ í°íŠ¸ í…ŒìŠ¤íŠ¸ (ì‹œê°í™” ì—†ì´)\n",
    "        print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: {selected_font}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        selected_font = 'DejaVu Sans'\n",
    "    \n",
    "    return selected_font\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤í–‰\n",
    "font_name = setup_korean_fonts()\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“Š Pandas Version: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy Version: {np.__version__}\")\n",
    "print(f\"â˜ï¸ Boto3 Version: {boto3.__version__}\")\n",
    "print(f\"ğŸ¤– Scikit-Learn ë¶„í•  ëª¨ë“ˆë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“ˆ Matplotlib & Seaborn ì‹œê°í™” ì¤€ë¹„ì™„ë£Œ!\")\n",
    "print(f\"ğŸ”¤ í•œê¸€ í°íŠ¸: {font_name}\")\n",
    "print(\"\\nğŸ¯ AWS S3 ê¸°ë°˜ ì˜¨ìŠµë„ ì„¼ì„œ ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8a7ea",
   "metadata": {},
   "source": [
    "## â˜ï¸ **Section 2: AWS S3 Configuration and Data Loading**\n",
    "AWS S3 ì„¤ì • ë° ì˜¨ìŠµë„ ì„¼ì„œ ë°ì´í„°ë¥¼ í´ë¼ìš°ë“œì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cf550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â˜ï¸ AWS S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "print(\"â˜ï¸ AWS S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤...\")\n",
    "\n",
    "# S3 ë²„í‚· ë° ê²½ë¡œ ì„¤ì •\n",
    "S3_BUCKET = 'elbee-ai'\n",
    "S3_PREFIX = 'project-data/'\n",
    "DATA_FILE_NAME = 'ì˜¨ìŠµë„_ê´€ì¸¡_ë°ì´í„°.csv'  # ì›ë³¸ íŒŒì¼ëª…ê³¼ ë™ì¼\n",
    "S3_DATA_KEY = f\"{S3_PREFIX}{DATA_FILE_NAME}\"\n",
    "\n",
    "def setup_s3_client():\n",
    "    \"\"\"AWS S3 í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•˜ê³  ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        # AWS ìê²© ì¦ëª… ë°©ë²• (ìš°ì„ ìˆœìœ„ ìˆœ):\n",
    "        # 1. í™˜ê²½ë³€ìˆ˜ (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "        # 2. AWS CLI ì„¤ì • (~/.aws/credentials)\n",
    "        # 3. IAM ì—­í•  (EC2/Lambdaì—ì„œ ì‹¤í–‰ ì‹œ)\n",
    "        \n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # ì—°ê²° í…ŒìŠ¤íŠ¸ - ë²„í‚· ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "        try:\n",
    "            s3_client.head_bucket(Bucket=S3_BUCKET)\n",
    "            print(f\"âœ… S3 ë²„í‚· '{S3_BUCKET}' ì—°ê²° ì„±ê³µ!\")\n",
    "            \n",
    "            # ë²„í‚· ë‚´ íŒŒì¼ ëª©ë¡ í™•ì¸ (í”„ë¦¬í”½ìŠ¤ ê¸°ì¤€)\n",
    "            response = s3_client.list_objects_v2(\n",
    "                Bucket=S3_BUCKET, \n",
    "                Prefix=S3_PREFIX,\n",
    "                MaxKeys=10\n",
    "            )\n",
    "            \n",
    "            if 'Contents' in response:\n",
    "                print(f\"ğŸ“ '{S3_PREFIX}' ê²½ë¡œì˜ íŒŒì¼ ëª©ë¡:\")\n",
    "                for obj in response['Contents']:\n",
    "                    file_size_mb = obj['Size'] / (1024 * 1024)\n",
    "                    print(f\"  ğŸ“„ {obj['Key']} ({file_size_mb:.2f} MB)\")\n",
    "            else:\n",
    "                print(f\"ğŸ“ '{S3_PREFIX}' ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                \n",
    "            return s3_client\n",
    "            \n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == '404':\n",
    "                print(f\"âŒ S3 ë²„í‚· '{S3_BUCKET}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(f\"âŒ S3 ë²„í‚· ì•¡ì„¸ìŠ¤ ì˜¤ë¥˜: {error_code}\")\n",
    "            return None\n",
    "            \n",
    "    except NoCredentialsError:\n",
    "        print(\"âŒ AWS ìê²© ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:\")\n",
    "        print(\"   1. í™˜ê²½ë³€ìˆ˜: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\")\n",
    "        print(\"   2. AWS CLI: aws configure\")\n",
    "        print(\"   3. IAM ì—­í•  (í´ë¼ìš°ë“œ í™˜ê²½)\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_data_from_s3(s3_client, bucket, key):\n",
    "    \"\"\"S3ì—ì„œ CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ“¥ S3ì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ì¤‘: s3://{bucket}/{key}\")\n",
    "        \n",
    "        # S3 ê°ì²´ ë‹¤ìš´ë¡œë“œ\n",
    "        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        \n",
    "        # CSV ë°ì´í„° ì½ê¸°\n",
    "        csv_content = response['Body'].read()\n",
    "        \n",
    "        # ì¸ì½”ë”© ì‹œë„ (í•œê¸€ íŒŒì¼ëª… ê³ ë ¤)\n",
    "        encodings = ['utf-8', 'cp949', 'euc-kr']\n",
    "        df = None\n",
    "        \n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                df = pd.read_csv(io.BytesIO(csv_content), encoding=encoding)\n",
    "                print(f\"âœ… ì¸ì½”ë”© '{encoding}'ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ ì„±ê³µ!\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if df is None:\n",
    "            print(\"âŒ ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨. UTF-8ë¡œ ê°•ì œ ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "            df = pd.read_csv(io.BytesIO(csv_content), encoding='utf-8', errors='ignore')\n",
    "        \n",
    "        print(f\"âœ… S3 ë°ì´í„° ë¡œë“œ ì™„ë£Œ! í¬ê¸°: {df.shape}\")\n",
    "        return df\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == 'NoSuchKey':\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: s3://{bucket}/{key}\")\n",
    "        else:\n",
    "            print(f\"âŒ S3 ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {error_code}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_simulation_data():\n",
    "    \"\"\"S3 ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ì˜¨ìŠµë„ ë°ì´í„°ë¥¼ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # ì‹œê°„ ë²”ìœ„ ì„¤ì • (ìµœê·¼ 1ë…„ê°„ì˜ ì‹œê°„ë‹¹ ë°ì´í„°)\n",
    "    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    end_date = datetime(2024, 12, 31)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "    # ì‹¤ì œì™€ ìœ ì‚¬í•œ ì˜¨ìŠµë„ íŒ¨í„´ ìƒì„±\n",
    "    n_samples = len(date_range)\n",
    "\n",
    "    # ê³„ì ˆë³„ ì˜¨ë„ íŒ¨í„´ (í•œêµ­ ê¸°í›„ ë°˜ì˜)\n",
    "    day_of_year = date_range.dayofyear\n",
    "    hour_of_day = date_range.hour\n",
    "\n",
    "    # ê¸°ë³¸ ì˜¨ë„ íŒ¨í„´ (ê³„ì ˆì„± + ì¼ì¼ ì£¼ê¸°)\n",
    "    base_temp = 15 + 10 * np.sin(2 * np.pi * day_of_year / 365.25)  # ê³„ì ˆ íŒ¨í„´\n",
    "    daily_temp = 5 * np.sin(2 * np.pi * hour_of_day / 24)  # ì¼ì¼ íŒ¨í„´\n",
    "    noise_temp = np.random.normal(0, 2, n_samples)  # ë…¸ì´ì¦ˆ\n",
    "    temperature = base_temp + daily_temp + noise_temp\n",
    "\n",
    "    # ìŠµë„ íŒ¨í„´ (ì˜¨ë„ì™€ ë°˜ë¹„ë¡€ ê´€ê³„ + ê³„ì ˆì„±)\n",
    "    base_humidity = 60 + 20 * np.sin(2 * np.pi * (day_of_year + 90) / 365.25)  # ê³„ì ˆ íŒ¨í„´\n",
    "    temp_humidity = -0.5 * (temperature - 20)  # ì˜¨ë„ì™€ ë°˜ë¹„ë¡€\n",
    "    noise_humidity = np.random.normal(0, 5, n_samples)  # ë…¸ì´ì¦ˆ\n",
    "    humidity = np.clip(base_humidity + temp_humidity + noise_humidity, 10, 95)\n",
    "\n",
    "    # ì ˆëŒ€ìŠµë„ ê³„ì‚° (ì˜¨ë„ì™€ ìƒëŒ€ìŠµë„ë¡œë¶€í„°)\n",
    "    absolute_humidity = (humidity / 100) * 6.112 * np.exp(17.67 * temperature / (243.5 + temperature))\n",
    "\n",
    "    # ê¸°ìƒ ì¡°ê±´ ë¶„ë¥˜ (ì˜¨ìŠµë„ ê¸°ë°˜)\n",
    "    conditions = []\n",
    "    for temp, hum in zip(temperature, humidity):\n",
    "        if temp < 5:\n",
    "            condition = \"ì¶”ìœ„\" if hum < 60 else \"ìŠµí•œì¶”ìœ„\"\n",
    "        elif temp < 20:\n",
    "            condition = \"ì„œëŠ˜í•¨\" if hum < 60 else \"ìŠµí•œì„œëŠ˜í•¨\"\n",
    "        elif temp < 30:\n",
    "            condition = \"ì ì •\" if hum < 70 else \"ìŠµí•¨\"\n",
    "        else:\n",
    "            condition = \"ë”ìœ„\" if hum < 80 else \"ë¬´ë”ìœ„\"\n",
    "        conditions.append(condition)\n",
    "\n",
    "    # ì„¼ì„œ ìœ„ì¹˜ (ì‹¤ë‚´/ì‹¤ì™¸ êµ¬ë¶„)\n",
    "    sensor_locations = np.random.choice(['ì‹¤ë‚´', 'ì‹¤ì™¸'], n_samples, p=[0.6, 0.4])\n",
    "\n",
    "    # ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': date_range,\n",
    "        'temperature': np.round(temperature, 1),\n",
    "        'humidity': np.round(humidity, 1),\n",
    "        'absolute_humidity': np.round(absolute_humidity, 2),\n",
    "        'condition': conditions,\n",
    "        'location': sensor_locations,\n",
    "        'day_of_week': date_range.day_name(),\n",
    "        'hour': date_range.hour,\n",
    "        'month': date_range.month,\n",
    "        'season': pd.cut(date_range.month, \n",
    "                         bins=[0, 3, 6, 9, 12], \n",
    "                         labels=['ê²¨ìš¸', 'ë´„', 'ì—¬ë¦„', 'ê°€ì„'])\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ… ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± ì™„ë£Œ! í¬ê¸°: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ ì‹¤í–‰\n",
    "s3_client = setup_s3_client()\n",
    "sensor_data = None\n",
    "\n",
    "if s3_client:\n",
    "    # S3ì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„\n",
    "    sensor_data = load_data_from_s3(s3_client, S3_BUCKET, S3_DATA_KEY)\n",
    "\n",
    "if sensor_data is None:\n",
    "    # S3 ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±\n",
    "    print(\"\\nâš ï¸ S3ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "    sensor_data = create_simulation_data()\n",
    "else:\n",
    "    print(\"\\nâœ… S3ì—ì„œ ì‹¤ì œ ì˜¨ìŠµë„ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ead92",
   "metadata": {},
   "source": [
    "## ğŸ”„ **Section 3: Data Preprocessing and Standardization**\n",
    "S3ì—ì„œ ë¡œë“œí•œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê³  í‘œì¤€í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92203912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ S3 ë°ì´í„° ì „ì²˜ë¦¬ ë° í‘œì¤€í™”\n",
    "print(\"ğŸ”„ S3 ë°ì´í„° ì „ì²˜ë¦¬ ë° í‘œì¤€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "def standardize_s3_data(df):\n",
    "    \"\"\"S3ì—ì„œ ë¡œë“œí•œ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"ğŸ“‹ ì›ë³¸ ë°ì´í„° ì •ë³´: {df.shape}, ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "    \n",
    "    # ë°ì´í„°í”„ë ˆì„ ë³µì‚¬\n",
    "    standardized_df = df.copy()\n",
    "    \n",
    "    # 1. íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "    timestamp_columns = ['timestamp', 'datetime', 'date', 'time', 'Date', 'Time']\n",
    "    timestamp_col = None\n",
    "    \n",
    "    for col in timestamp_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            timestamp_col = col\n",
    "            break\n",
    "    \n",
    "    if timestamp_col:\n",
    "        print(f\"ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ '{timestamp_col}' ë°œê²¬\")\n",
    "        if standardized_df[timestamp_col].dtype == 'object':\n",
    "            standardized_df[timestamp_col] = pd.to_datetime(standardized_df[timestamp_col])\n",
    "        if timestamp_col != 'timestamp':\n",
    "            standardized_df['timestamp'] = standardized_df[timestamp_col]\n",
    "    else:\n",
    "        print(\"ğŸ“… íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ì´ ì—†ì–´ ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        standardized_df['timestamp'] = pd.date_range(start='2024-01-01', periods=len(standardized_df), freq='H')\n",
    "    \n",
    "    # 2. ì˜¨ë„ ì»¬ëŸ¼ ë§¤í•‘\n",
    "    temp_columns = ['temperature', 'temp', 'T', 'Temperature', 'TEMP']\n",
    "    temp_col = None\n",
    "    \n",
    "    for col in temp_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            temp_col = col\n",
    "            break\n",
    "    \n",
    "    if temp_col and temp_col != 'temperature':\n",
    "        standardized_df['temperature'] = standardized_df[temp_col]\n",
    "        print(f\"ğŸŒ¡ï¸ ì˜¨ë„ ì»¬ëŸ¼ '{temp_col}' â†’ 'temperature'ë¡œ ë§¤í•‘\")\n",
    "    elif not temp_col:\n",
    "        print(\"âš ï¸ ì˜¨ë„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ìˆ«ì ì»¬ëŸ¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        numeric_cols = standardized_df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            standardized_df['temperature'] = standardized_df[numeric_cols[0]]\n",
    "    \n",
    "    # 3. ìŠµë„ ì»¬ëŸ¼ ë§¤í•‘\n",
    "    humidity_columns = ['humidity', 'rh', 'RH', 'Humidity', 'HUMIDITY']\n",
    "    humidity_col = None\n",
    "    \n",
    "    for col in humidity_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            humidity_col = col\n",
    "            break\n",
    "    \n",
    "    if humidity_col and humidity_col != 'humidity':\n",
    "        standardized_df['humidity'] = standardized_df[humidity_col]\n",
    "        print(f\"ğŸ’§ ìŠµë„ ì»¬ëŸ¼ '{humidity_col}' â†’ 'humidity'ë¡œ ë§¤í•‘\")\n",
    "    elif not humidity_col:\n",
    "        print(\"âš ï¸ ìŠµë„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ ìˆ«ì ì»¬ëŸ¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "        numeric_cols = standardized_df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            standardized_df['humidity'] = standardized_df[numeric_cols[1]]\n",
    "    \n",
    "    # 4. ì ˆëŒ€ìŠµë„ ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "    abs_humidity_columns = ['absolute_humidity', 'ah', 'AH', 'AbsoluteHumidity']\n",
    "    abs_humidity_col = None\n",
    "    \n",
    "    for col in abs_humidity_columns:\n",
    "        if col in standardized_df.columns:\n",
    "            abs_humidity_col = col\n",
    "            break\n",
    "    \n",
    "    if abs_humidity_col and abs_humidity_col != 'absolute_humidity':\n",
    "        standardized_df['absolute_humidity'] = standardized_df[abs_humidity_col]\n",
    "        print(f\"ğŸ’¨ ì ˆëŒ€ìŠµë„ ì»¬ëŸ¼ '{abs_humidity_col}' â†’ 'absolute_humidity'ë¡œ ë§¤í•‘\")\n",
    "    elif not abs_humidity_col:\n",
    "        # ì ˆëŒ€ìŠµë„ê°€ ì—†ìœ¼ë©´ ì˜¨ë„ì™€ ìƒëŒ€ìŠµë„ë¡œë¶€í„° ê³„ì‚°\n",
    "        if 'temperature' in standardized_df.columns and 'humidity' in standardized_df.columns:\n",
    "            print(\"ğŸ’¨ ì ˆëŒ€ìŠµë„ë¥¼ ì˜¨ë„ì™€ ìƒëŒ€ìŠµë„ë¡œë¶€í„° ê³„ì‚°í•©ë‹ˆë‹¤.\")\n",
    "            temp = standardized_df['temperature']\n",
    "            rh = standardized_df['humidity']\n",
    "            # Magnus ê³µì‹ì„ ì‚¬ìš©í•œ ì ˆëŒ€ìŠµë„ ê³„ì‚°\n",
    "            standardized_df['absolute_humidity'] = (rh / 100) * 6.112 * np.exp(17.67 * temp / (243.5 + temp))\n",
    "    \n",
    "    # 5. íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "    if 'timestamp' in standardized_df.columns:\n",
    "        ts = standardized_df['timestamp']\n",
    "        standardized_df['hour'] = ts.dt.hour\n",
    "        standardized_df['day_of_week'] = ts.dt.day_name()\n",
    "        standardized_df['month'] = ts.dt.month\n",
    "        standardized_df['season'] = pd.cut(ts.dt.month, \n",
    "                                         bins=[0, 3, 6, 9, 12], \n",
    "                                         labels=['ê²¨ìš¸', 'ë´„', 'ì—¬ë¦„', 'ê°€ì„'])\n",
    "        print(\"ğŸ“… ì‹œê°„ ê¸°ë°˜ íŒŒìƒ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    # 6. ê¸°ìƒ ì¡°ê±´ ë¶„ë¥˜ (ì˜¨ìŠµë„ê°€ ìˆëŠ” ê²½ìš°)\n",
    "    if 'temperature' in standardized_df.columns and 'humidity' in standardized_df.columns:\n",
    "        conditions = []\n",
    "        for temp, hum in zip(standardized_df['temperature'], standardized_df['humidity']):\n",
    "            if pd.isna(temp) or pd.isna(hum):\n",
    "                conditions.append('ì•Œìˆ˜ì—†ìŒ')\n",
    "            elif temp < 5:\n",
    "                condition = \"ì¶”ìœ„\" if hum < 60 else \"ìŠµí•œì¶”ìœ„\"\n",
    "                conditions.append(condition)\n",
    "            elif temp < 20:\n",
    "                condition = \"ì„œëŠ˜í•¨\" if hum < 60 else \"ìŠµí•œì„œëŠ˜í•¨\"\n",
    "                conditions.append(condition)\n",
    "            elif temp < 30:\n",
    "                condition = \"ì ì •\" if hum < 70 else \"ìŠµí•¨\"\n",
    "                conditions.append(condition)\n",
    "            else:\n",
    "                condition = \"ë”ìœ„\" if hum < 80 else \"ë¬´ë”ìœ„\"\n",
    "                conditions.append(condition)\n",
    "        \n",
    "        standardized_df['condition'] = conditions\n",
    "        print(\"ğŸŒ¤ï¸ ê¸°ìƒ ì¡°ê±´ ë¶„ë¥˜ ì™„ë£Œ\")\n",
    "    \n",
    "    # 7. ì„¼ì„œ ìœ„ì¹˜ ì •ë³´ (ì—†ìœ¼ë©´ ëœë¤ ìƒì„±)\n",
    "    if 'location' not in standardized_df.columns:\n",
    "        np.random.seed(42)\n",
    "        standardized_df['location'] = np.random.choice(['ì‹¤ë‚´', 'ì‹¤ì™¸'], len(standardized_df), p=[0.6, 0.4])\n",
    "        print(\"ğŸ“ ì„¼ì„œ ìœ„ì¹˜ ì •ë³´ ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    print(f\"âœ… ë°ì´í„° í‘œì¤€í™” ì™„ë£Œ! ìµœì¢… í¬ê¸°: {standardized_df.shape}\")\n",
    "    return standardized_df\n",
    "\n",
    "# ë°ì´í„° í‘œì¤€í™” ì‹¤í–‰\n",
    "sensor_data = standardize_s3_data(sensor_data)\n",
    "\n",
    "# í‘œì¤€í™”ëœ ë°ì´í„° ì •ë³´ ì¶œë ¥\n",
    "print(f\"\\nğŸ“Š í‘œì¤€í™”ëœ ë°ì´í„° ì •ë³´:\")\n",
    "print(f\"ğŸ“ ë°ì´í„° í¬ê¸°: {sensor_data.shape}\")\n",
    "print(f\"ğŸ“Š ì»¬ëŸ¼ ëª©ë¡: {list(sensor_data.columns)}\")\n",
    "\n",
    "if 'timestamp' in sensor_data.columns:\n",
    "    print(f\"ğŸ“… ê¸°ê°„: {sensor_data['timestamp'].min()} ~ {sensor_data['timestamp'].max()}\")\n",
    "if 'temperature' in sensor_data.columns:\n",
    "    print(f\"ğŸŒ¡ï¸ ì˜¨ë„ ë²”ìœ„: {sensor_data['temperature'].min():.1f}Â°C ~ {sensor_data['temperature'].max():.1f}Â°C\")\n",
    "if 'humidity' in sensor_data.columns:\n",
    "    print(f\"ğŸ’§ ìŠµë„ ë²”ìœ„: {sensor_data['humidity'].min():.1f}% ~ {sensor_data['humidity'].max():.1f}%\")\n",
    "if 'absolute_humidity' in sensor_data.columns:\n",
    "    print(f\"ğŸ’¨ ì ˆëŒ€ìŠµë„ ë²”ìœ„: {sensor_data['absolute_humidity'].min():.2f} ~ {sensor_data['absolute_humidity'].max():.2f} g/mÂ³\")\n",
    "\n",
    "# ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
    "print(f\"\\nğŸ“Š ë°ì´í„° êµ¬ì¡°:\")\n",
    "print(sensor_data.info())\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì²« 10ê°œ ë ˆì½”ë“œ:\")\n",
    "display(sensor_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25814a",
   "metadata": {},
   "source": [
    "## ğŸ” **Section 4: Enhanced Data Exploration and Quality Assessment**\n",
    "S3 ë°ì´í„°ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê³  íƒìƒ‰ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0139825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” S3 ë°ì´í„° í’ˆì§ˆ í‰ê°€ ë° íƒìƒ‰ì  ë¶„ì„\n",
    "print(\"ğŸ” S3 ì˜¨ìŠµë„ ë°ì´í„° í’ˆì§ˆ í‰ê°€ ë° íƒìƒ‰ì  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# 1. ë°ì´í„° í’ˆì§ˆ í‰ê°€\n",
    "print(\"\\nğŸ“Š === ë°ì´í„° í’ˆì§ˆ í‰ê°€ ===\")\n",
    "\n",
    "# ê¸°ìˆ í†µê³„ëŸ‰\n",
    "numeric_cols = sensor_data.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nğŸ“ˆ ìˆ«ìí˜• ì»¬ëŸ¼ ê¸°ìˆ í†µê³„ëŸ‰:\")\n",
    "print(sensor_data[numeric_cols].describe())\n",
    "\n",
    "# ê²°ì¸¡ê°’ í™•ì¸\n",
    "print(f\"\\nâ“ ê²°ì¸¡ê°’ í™•ì¸:\")\n",
    "missing_values = sensor_data.isnull().sum()\n",
    "missing_percent = (missing_values / len(sensor_data)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'ê²°ì¸¡ê°’ ê°œìˆ˜': missing_values,\n",
    "    'ê²°ì¸¡ê°’ ë¹„ìœ¨(%)': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['ê²°ì¸¡ê°’ ê°œìˆ˜'] > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ì¤‘ë³µê°’ í™•ì¸\n",
    "duplicate_count = sensor_data.duplicated().sum()\n",
    "print(f\"\\nğŸ”„ ì¤‘ë³µ ë ˆì½”ë“œ: {duplicate_count}ê°œ ({duplicate_count/len(sensor_data)*100:.1f}%)\")\n",
    "\n",
    "# 2. ë°ì´í„° ë¶„í¬ ì‹œê°í™”\n",
    "print(\"\\nğŸ“Š === ë°ì´í„° ë¶„í¬ ì‹œê°í™” ===\")\n",
    "\n",
    "if 'temperature' in sensor_data.columns and 'humidity' in sensor_data.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('ğŸŒ¡ï¸ğŸ’§ ì˜¨ìŠµë„ ë°ì´í„° ë¶„í¬ ë¶„ì„ (S3 ì†ŒìŠ¤)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # ì˜¨ë„ ë¶„í¬\n",
    "    axes[0, 0].hist(sensor_data['temperature'], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[0, 0].set_title('ì˜¨ë„ ë¶„í¬')\n",
    "    axes[0, 0].set_xlabel('ì˜¨ë„ (Â°C)')\n",
    "    axes[0, 0].set_ylabel('ë¹ˆë„')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ìŠµë„ ë¶„í¬\n",
    "    axes[0, 1].hist(sensor_data['humidity'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 1].set_title('ìŠµë„ ë¶„í¬')\n",
    "    axes[0, 1].set_xlabel('ìŠµë„ (%)')\n",
    "    axes[0, 1].set_ylabel('ë¹ˆë„')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ì˜¨ë„-ìŠµë„ ì‚°ì ë„\n",
    "    axes[1, 0].scatter(sensor_data['temperature'], sensor_data['humidity'], \n",
    "                      alpha=0.5, s=10, c='green')\n",
    "    axes[1, 0].set_title('ì˜¨ë„-ìŠµë„ ìƒê´€ê´€ê³„')\n",
    "    axes[1, 0].set_xlabel('ì˜¨ë„ (Â°C)')\n",
    "    axes[1, 0].set_ylabel('ìŠµë„ (%)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ê¸°ìƒ ì¡°ê±´ ë¶„í¬\n",
    "    if 'condition' in sensor_data.columns:\n",
    "        condition_counts = sensor_data['condition'].value_counts()\n",
    "        axes[1, 1].pie(condition_counts.values, labels=condition_counts.index, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('ê¸°ìƒ ì¡°ê±´ ë¶„í¬')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„\n",
    "if 'timestamp' in sensor_data.columns:\n",
    "    print(\"\\nğŸ“… === ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ ===\")\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    fig.suptitle('ğŸ“ˆ ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ (S3 ë°ì´í„°)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # ì‹œê°„ë³„ ì˜¨ë„ ë³€í™”\n",
    "    if 'temperature' in sensor_data.columns:\n",
    "        axes[0].plot(sensor_data['timestamp'], sensor_data['temperature'], \n",
    "                    alpha=0.7, color='red', linewidth=0.5)\n",
    "        axes[0].set_title('ì‹œê°„ë³„ ì˜¨ë„ ë³€í™”')\n",
    "        axes[0].set_ylabel('ì˜¨ë„ (Â°C)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ì‹œê°„ë³„ ìŠµë„ ë³€í™”\n",
    "    if 'humidity' in sensor_data.columns:\n",
    "        axes[1].plot(sensor_data['timestamp'], sensor_data['humidity'], \n",
    "                    alpha=0.7, color='blue', linewidth=0.5)\n",
    "        axes[1].set_title('ì‹œê°„ë³„ ìŠµë„ ë³€í™”')\n",
    "        axes[1].set_ylabel('ìŠµë„ (%)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ì¼ë³„ í‰ê·  íŒ¨í„´\n",
    "    if 'hour' in sensor_data.columns and 'temperature' in sensor_data.columns:\n",
    "        hourly_avg = sensor_data.groupby('hour')[['temperature', 'humidity']].mean()\n",
    "        axes[2].plot(hourly_avg.index, hourly_avg['temperature'], \n",
    "                    'o-', color='red', label='ì˜¨ë„', linewidth=2)\n",
    "        if 'humidity' in hourly_avg.columns:\n",
    "            ax2 = axes[2].twinx()\n",
    "            ax2.plot(hourly_avg.index, hourly_avg['humidity'], \n",
    "                    's-', color='blue', label='ìŠµë„', linewidth=2)\n",
    "            ax2.set_ylabel('ìŠµë„ (%)', color='blue')\n",
    "            ax2.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        axes[2].set_title('ì‹œê°„ëŒ€ë³„ í‰ê·  ì˜¨ìŠµë„ íŒ¨í„´')\n",
    "        axes[2].set_xlabel('ì‹œê°„ (0-23)')\n",
    "        axes[2].set_ylabel('ì˜¨ë„ (Â°C)', color='red')\n",
    "        axes[2].tick_params(axis='y', labelcolor='red')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. ìƒê´€ê´€ê³„ ë¶„ì„\n",
    "print(\"\\nğŸ”— === ìƒê´€ê´€ê³„ ë¶„ì„ ===\")\n",
    "correlation_matrix = sensor_data[numeric_cols].corr()\n",
    "print(\"ğŸ“Š ìˆ«ìí˜• ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('ğŸ”— ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (S3 ë°ì´í„°)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. ë°ì´í„° í’ˆì§ˆ ìš”ì•½\n",
    "print(\"\\nâœ… === S3 ë°ì´í„° í’ˆì§ˆ ìš”ì•½ ===\")\n",
    "print(f\"ğŸ“ ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {len(sensor_data):,}ê°œ\")\n",
    "print(f\"ğŸ“Š ì „ì²´ ì»¬ëŸ¼ ìˆ˜: {len(sensor_data.columns)}ê°œ\")\n",
    "print(f\"ğŸ”¢ ìˆ«ìí˜• ì»¬ëŸ¼: {len(numeric_cols)}ê°œ\")\n",
    "print(f\"â“ ê²°ì¸¡ê°’ ë¹„ìœ¨: {(missing_values.sum() / (len(sensor_data) * len(sensor_data.columns)) * 100):.2f}%\")\n",
    "print(f\"ğŸ”„ ì¤‘ë³µê°’ ë¹„ìœ¨: {(duplicate_count / len(sensor_data) * 100):.2f}%\")\n",
    "\n",
    "if 'timestamp' in sensor_data.columns:\n",
    "    time_span = sensor_data['timestamp'].max() - sensor_data['timestamp'].min()\n",
    "    print(f\"ğŸ“… ë°ì´í„° ê¸°ê°„: {time_span.days}ì¼ ({time_span.total_seconds()/3600:.1f}ì‹œê°„)\")\n",
    "\n",
    "print(\"\\nğŸ¯ S3 ë°ì´í„° íƒìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ Scikit-Learn ë¶„í•  ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d34614",
   "metadata": {},
   "source": [
    "## ğŸ“– **Section 5: Scikit-Learn Data Splitting with AWS S3**\n",
    "ì´ì œ S3ì—ì„œ ë¡œë“œí•œ ì˜¨ìŠµë„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Scikit-Learnì˜ ë‹¤ì–‘í•œ ë°ì´í„° ë¶„í•  ê¸°ë²•ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ¯ **í•™ìŠµ ëª©í‘œ:**\n",
    "1. **Basic Train/Test Split** - ê¸°ë³¸ì ì¸ ë°ì´í„° ë¶„í• \n",
    "2. **Stratified Split** - í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ëŠ” ë¶„í• \n",
    "3. **Time Series Split** - ì‹œê³„ì—´ ë°ì´í„°ì— ì í•©í•œ ë¶„í• \n",
    "4. **Cross-Validation** - êµì°¨ ê²€ì¦ì„ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "5. **ê²°ê³¼ë¥¼ S3ì— ì €ì¥** - ë¶„í• ëœ ë°ì´í„°ì™€ ëª¨ë¸ ê²°ê³¼ë¥¼ í´ë¼ìš°ë“œì— ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Cross-Platform AWS Environment Detection and Auto-Setup\n",
    "# This cell automatically detects your environment and provides setup guidance\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def detect_execution_environment():\n",
    "    \"\"\"Comprehensive environment detection for AWS S3 integration\"\"\"\n",
    "    \n",
    "    env_info = {\n",
    "        'platform_system': platform.system(),\n",
    "        'platform_machine': platform.machine(),\n",
    "        'python_version': sys.version,\n",
    "        'python_executable': sys.executable,\n",
    "        'working_directory': os.getcwd(),\n",
    "        'is_wsl': False,\n",
    "        'is_jupyter': False,\n",
    "        'aws_cli_available': False,\n",
    "        'aws_cli_path': None,\n",
    "        'conda_environment': None,\n",
    "        'venv_active': False\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ” Environment Detection and Setup Guidance\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Detect WSL\n",
    "    try:\n",
    "        if env_info['platform_system'] == 'Linux':\n",
    "            with open('/proc/version', 'r') as f:\n",
    "                if 'microsoft' in f.read().lower():\n",
    "                    env_info['is_wsl'] = True\n",
    "        elif env_info['platform_system'] == 'Windows':\n",
    "            env_info['is_wsl'] = any(var in os.environ for var in ['WSL_DISTRO_NAME', 'WSL_INTEROP'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Detect Jupyter environment\n",
    "    env_info['is_jupyter'] = any(module in sys.modules for module in ['ipykernel', 'IPython'])\n",
    "    \n",
    "    # Detect virtual environment\n",
    "    env_info['venv_active'] = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "    \n",
    "    # Detect conda environment\n",
    "    if 'CONDA_DEFAULT_ENV' in os.environ:\n",
    "        env_info['conda_environment'] = os.environ['CONDA_DEFAULT_ENV']\n",
    "    \n",
    "    # Check AWS CLI availability\n",
    "    try:\n",
    "        if env_info['platform_system'] == 'Windows':\n",
    "            cmd = ['where', 'aws']\n",
    "        else:\n",
    "            cmd = ['which', 'aws']\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)\n",
    "        if result.returncode == 0:\n",
    "            env_info['aws_cli_available'] = True\n",
    "            env_info['aws_cli_path'] = result.stdout.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return env_info\n",
    "\n",
    "def check_aws_credentials():\n",
    "    \"\"\"Check AWS credentials availability\"\"\"\n",
    "    print(\"\\nğŸ” AWS Credentials Check:\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    # Check environment variables\n",
    "    aws_vars = ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'AWS_DEFAULT_REGION']\n",
    "    env_creds = all(os.environ.get(var) for var in aws_vars)\n",
    "    \n",
    "    for var in aws_vars:\n",
    "        value = os.environ.get(var)\n",
    "        if value:\n",
    "            if 'SECRET' in var:\n",
    "                print(f\"   âœ… {var}: ***[HIDDEN]***\")\n",
    "            else:\n",
    "                print(f\"   âœ… {var}: {value}\")\n",
    "        else:\n",
    "            print(f\"   âŒ {var}: Not set\")\n",
    "    \n",
    "    # Test boto3 credentials\n",
    "    try:\n",
    "        import boto3\n",
    "        session = boto3.Session()\n",
    "        credentials = session.get_credentials()\n",
    "        \n",
    "        if credentials:\n",
    "            print(f\"   âœ… Boto3 session: Available\")\n",
    "            print(f\"   âœ… Access key: {credentials.access_key[:8]}***\")\n",
    "        else:\n",
    "            print(f\"   âŒ Boto3 session: No credentials found\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(f\"   âš ï¸ Boto3 not installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Boto3 error: {e}\")\n",
    "    \n",
    "    return env_creds\n",
    "\n",
    "def provide_setup_guidance(env_info, has_credentials):\n",
    "    \"\"\"Provide environment-specific setup guidance\"\"\"\n",
    "    print(f\"\\nğŸ¯ Setup Guidance for Your Environment:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"ğŸ’» Platform: {env_info['platform_system']}\")\n",
    "    print(f\"ğŸ Python: {env_info['python_executable']}\")\n",
    "    \n",
    "    if env_info['conda_environment']:\n",
    "        print(f\"ğŸ Conda Env: {env_info['conda_environment']}\")\n",
    "    elif env_info['venv_active']:\n",
    "        print(f\"ğŸ Virtual Env: Active\")\n",
    "    \n",
    "    print(f\"ğŸ““ Jupyter: {'Yes' if env_info['is_jupyter'] else 'No'}\")\n",
    "    print(f\"ğŸ§ WSL: {'Yes' if env_info['is_wsl'] else 'No'}\")\n",
    "    print(f\"âš™ï¸ AWS CLI: {'Available' if env_info['aws_cli_available'] else 'Not found'}\")\n",
    "    \n",
    "    if env_info['aws_cli_path']:\n",
    "        print(f\"ğŸ“ AWS CLI Path: {env_info['aws_cli_path']}\")\n",
    "    \n",
    "    # Provide specific guidance\n",
    "    print(f\"\\nğŸ’¡ Recommended Setup Steps:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    step = 1\n",
    "    \n",
    "    # AWS CLI installation\n",
    "    if not env_info['aws_cli_available']:\n",
    "        print(f\"{step}. ğŸ“¥ Install AWS CLI:\")\n",
    "        if env_info['platform_system'] == 'Windows':\n",
    "            print(f\"   Windows: Run install_aws_windows.bat\")\n",
    "            print(f\"   Or: Download from https://aws.amazon.com/cli/\")\n",
    "        else:\n",
    "            print(f\"   Linux/WSL: Run bash install_aws_linux.sh\")\n",
    "            print(f\"   Or: curl https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\")\n",
    "        step += 1\n",
    "    \n",
    "    # Credentials setup\n",
    "    if not has_credentials:\n",
    "        print(f\"{step}. ğŸ” Configure AWS Credentials:\")\n",
    "        if env_info['platform_system'] == 'Windows':\n",
    "            print(f\"   PowerShell: .\\\\setup_aws_credentials.ps1 -Persistent\")\n",
    "            print(f\"   Command Prompt: aws configure\")\n",
    "        else:\n",
    "            print(f\"   Terminal: aws configure\")\n",
    "            print(f\"   Or: export AWS_ACCESS_KEY_ID='your-key'\")\n",
    "        step += 1\n",
    "    \n",
    "    # Package installation\n",
    "    print(f\"{step}. ğŸ“¦ Install Required Packages:\")\n",
    "    print(f\"   pip install boto3 pandas numpy matplotlib scikit-learn\")\n",
    "    step += 1\n",
    "    \n",
    "    # Test setup\n",
    "    print(f\"{step}. ğŸ§ª Test Your Setup:\")\n",
    "    print(f\"   python test_aws_integration.py\")\n",
    "    \n",
    "    print(f\"\\nğŸ“š Documentation:\")\n",
    "    print(f\"   ğŸ“– Full Guide: AWS_S3_INTEGRATION_GUIDE.md\")\n",
    "    print(f\"   ğŸ”§ Windows Script: install_aws_windows.bat\")\n",
    "    print(f\"   ğŸ§ Linux Script: install_aws_linux.sh\")\n",
    "    print(f\"   ğŸ’™ PowerShell: setup_aws_credentials.ps1\")\n",
    "\n",
    "def check_required_packages():\n",
    "    \"\"\"Check if required packages are installed\"\"\"\n",
    "    print(f\"\\nğŸ“¦ Required Packages Check:\")\n",
    "    print(\"-\" * 28)\n",
    "    \n",
    "    required_packages = {\n",
    "        'boto3': 'AWS SDK for Python',\n",
    "        'pandas': 'Data manipulation and analysis',\n",
    "        'numpy': 'Numerical computing',\n",
    "        'matplotlib': 'Data visualization',\n",
    "        'scikit-learn': 'Machine learning library'\n",
    "    }\n",
    "    \n",
    "    missing_packages = []\n",
    "    \n",
    "    for package, description in required_packages.items():\n",
    "        try:\n",
    "            if package == 'scikit-learn':\n",
    "                __import__('sklearn')\n",
    "            else:\n",
    "                __import__(package)\n",
    "            print(f\"   âœ… {package}: {description}\")\n",
    "        except ImportError:\n",
    "            print(f\"   âŒ {package}: Not installed - {description}\")\n",
    "            missing_packages.append(package)\n",
    "    \n",
    "    if missing_packages:\n",
    "        print(f\"\\nğŸ’¡ Install missing packages:\")\n",
    "        print(f\"   pip install {' '.join(missing_packages)}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"\\nâœ… All required packages are installed!\")\n",
    "        return True\n",
    "\n",
    "def create_quick_setup_scripts():\n",
    "    \"\"\"Create platform-specific quick setup scripts in current directory\"\"\"\n",
    "    print(f\"\\nğŸ“ Creating Quick Setup Scripts:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Check if scripts already exist\n",
    "    scripts = {\n",
    "        'quick_aws_setup.py': 'Python setup script',\n",
    "        'setup_env.bat': 'Windows batch script',\n",
    "        'setup_env.sh': 'Linux/WSL shell script'\n",
    "    }\n",
    "    \n",
    "    for script, description in scripts.items():\n",
    "        script_path = Path(script)\n",
    "        if script_path.exists():\n",
    "            print(f\"   âœ… {script}: Already exists - {description}\")\n",
    "        else:\n",
    "            print(f\"   ğŸ“ {script}: Will be created - {description}\")\n",
    "    \n",
    "    # Python setup script\n",
    "    python_script = '''#!/usr/bin/env python3\n",
    "\"\"\"Quick AWS S3 setup verification and troubleshooting\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def quick_aws_test():\n",
    "    print(\"ğŸ§ª Quick AWS S3 Integration Test\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Test imports\n",
    "    try:\n",
    "        import boto3\n",
    "        print(\"âœ… boto3 imported successfully\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ boto3 not installed: pip install boto3\")\n",
    "        return False\n",
    "    \n",
    "    # Test credentials\n",
    "    try:\n",
    "        sts = boto3.client('sts')\n",
    "        identity = sts.get_caller_identity()\n",
    "        print(f\"âœ… AWS Identity: {identity.get('Arn', 'Unknown')}\")\n",
    "        \n",
    "        # Test S3\n",
    "        s3 = boto3.client('s3')\n",
    "        buckets = s3.list_buckets()\n",
    "        print(f\"âœ… S3 Access: {len(buckets['Buckets'])} buckets found\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ AWS Error: {e}\")\n",
    "        print(\"ğŸ’¡ Fix: Run 'aws configure' or set environment variables\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = quick_aws_test()\n",
    "    sys.exit(0 if success else 1)\n",
    "'''\n",
    "    \n",
    "    with open('quick_aws_setup.py', 'w') as f:\n",
    "        f.write(python_script)\n",
    "    \n",
    "    print(f\"   âœ… quick_aws_setup.py created\")\n",
    "    print(f\"\\nğŸ’¡ Run: python quick_aws_setup.py\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    \"\"\"Main environment detection and setup function\"\"\"\n",
    "    \n",
    "    # Detect environment\n",
    "    env_info = detect_execution_environment()\n",
    "    \n",
    "    # Check AWS credentials\n",
    "    has_credentials = check_aws_credentials()\n",
    "    \n",
    "    # Check required packages\n",
    "    packages_ok = check_required_packages()\n",
    "    \n",
    "    # Provide setup guidance\n",
    "    provide_setup_guidance(env_info, has_credentials)\n",
    "    \n",
    "    # Create quick setup scripts\n",
    "    create_quick_setup_scripts()\n",
    "    \n",
    "    # Final status\n",
    "    print(f\"\\nğŸ¯ Environment Status Summary:\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"   Platform: {env_info['platform_system']}\")\n",
    "    print(f\"   AWS CLI: {'âœ… Available' if env_info['aws_cli_available'] else 'âŒ Missing'}\")\n",
    "    print(f\"   Credentials: {'âœ… Configured' if has_credentials else 'âŒ Missing'}\")\n",
    "    print(f\"   Packages: {'âœ… Complete' if packages_ok else 'âŒ Missing'}\")\n",
    "    \n",
    "    all_ready = env_info['aws_cli_available'] and has_credentials and packages_ok\n",
    "    \n",
    "    if all_ready:\n",
    "        print(f\"\\nğŸ‰ Your environment is ready for AWS S3 integration!\")\n",
    "        print(f\"âœ… You can proceed with the notebook analysis\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Setup required before proceeding\")\n",
    "        print(f\"ğŸ’¡ Follow the guidance above to complete setup\")\n",
    "    \n",
    "    return all_ready\n",
    "\n",
    "# Run the environment detection\n",
    "environment_ready = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Track - NLP Advanced",
   "language": "python",
   "name": "ai-track-nlp-advanced"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
